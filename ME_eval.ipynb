{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/aloui/miniconda3/envs/vilbert-mt/lib/python3.6/site-packages/tensorpack/callbacks/hooks.py:17: The name tf.train.SessionRunHook is deprecated. Please use tf.estimator.SessionRunHook instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/aloui/miniconda3/envs/vilbert-mt/lib/python3.6/site-packages/tensorpack/tfutils/optimizer.py:18: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/aloui/miniconda3/envs/vilbert-mt/lib/python3.6/site-packages/tensorpack/tfutils/sesscreate.py:20: The name tf.train.SessionCreator is deprecated. Please use tf.compat.v1.train.SessionCreator instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import json\n",
    "import logging\n",
    "import os\n",
    "import random\n",
    "from io import open\n",
    "import numpy as np\n",
    "\n",
    "from tensorboardX import SummaryWriter\n",
    "from tqdm import tqdm\n",
    "from bisect import bisect\n",
    "import yaml\n",
    "from easydict import EasyDict as edict\n",
    "import sys\n",
    "import pdb\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "\n",
    "from vilbert.task_utils import (\n",
    "    LoadDatasetEval,\n",
    "    LoadLosses,\n",
    "    ForwardModelsTrain,\n",
    "    ForwardModelsVal,\n",
    "    EvaluatingModel,\n",
    ")\n",
    "\n",
    "import vilbert.utils as utils\n",
    "import torch.distributed as dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(\n",
    "    args,\n",
    "    task_dataloader_val,\n",
    "    task_stop_controller,\n",
    "    task_cfg,\n",
    "    device,\n",
    "    task_id,\n",
    "    model,\n",
    "    task_losses,\n",
    "    epochId,\n",
    "    default_gpu,\n",
    "    tbLogger,\n",
    "):\n",
    "\n",
    "    model.eval()\n",
    "    for i, batch in enumerate(task_dataloader_val[task_id]):\n",
    "        loss, score, batch_size = ForwardModelsVal(\n",
    "            args, task_cfg, device, task_id, batch, model, task_losses\n",
    "        )\n",
    "        tbLogger.step_val(\n",
    "            epochId, float(loss), float(score), task_id, batch_size, \"val\"\n",
    "        )\n",
    "        if default_gpu:\n",
    "            sys.stdout.write(\"%d/%d\\r\" % (i, len(task_dataloader_val[task_id])))\n",
    "            sys.stdout.flush()\n",
    "\n",
    "    # update the multi-task scheduler.\n",
    "    task_stop_controller[task_id].step(tbLogger.getValScore(task_id))\n",
    "    score = tbLogger.showLossVal(task_id, task_stop_controller)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(\n",
    "    format=\"%(asctime)s - %(levelname)s - %(name)s -   %(message)s\",\n",
    "    datefmt=\"%m/%d/%Y %H:%M:%S\",\n",
    "    level=logging.INFO,\n",
    ")\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "parser.add_argument(\n",
    "    \"--bert_model\",\n",
    "    default=\"bert-base-uncased\",\n",
    "    type=str,\n",
    "    help=\"Bert pre-trained model selected in the list: bert-base-uncased, \"\n",
    "    \"bert-large-uncased, bert-base-cased, bert-base-multilingual, bert-base-chinese.\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--from_pretrained\",\n",
    "    default=\"bert-base-uncased\",\n",
    "    type=str,\n",
    "    help=\"Bert pre-trained model selected in the list: bert-base-uncased, \"\n",
    "    \"bert-large-uncased, bert-base-cased, bert-base-multilingual, bert-base-chinese.\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--output_dir\",\n",
    "    default=\"results\",\n",
    "    type=str,\n",
    "    help=\"The output directory where the model checkpoints will be written.\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--config_file\",\n",
    "    default=\"config/bert_config.json\",\n",
    "    type=str,\n",
    "    help=\"The config file which specified the model details.\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--no_cuda\", action=\"store_true\", help=\"Whether not to use CUDA when available\"\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--do_lower_case\",\n",
    "    default=True,\n",
    "    type=bool,\n",
    "    help=\"Whether to lower case the input text. True for uncased models, False for cased models.\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--local_rank\",\n",
    "    type=int,\n",
    "    default=-1,\n",
    "    help=\"local_rank for distributed training on gpus\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--seed\", type=int, default=42, help=\"random seed for initialization\"\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--fp16\",\n",
    "    action=\"store_true\",\n",
    "    help=\"Whether to use 16-bit float precision instead of 32-bit\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--loss_scale\",\n",
    "    type=float,\n",
    "    default=0,\n",
    "    help=\"Loss scaling to improve fp16 numeric stability. Only used when fp16 set to True.\\n\"\n",
    "    \"0 (default value): dynamic loss scaling.\\n\"\n",
    "    \"Positive power of 2: static loss scaling value.\\n\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--num_workers\",\n",
    "    type=int,\n",
    "    default=16,\n",
    "    help=\"Number of workers in the dataloader.\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--save_name\", default=\"\", type=str, help=\"save name for training.\"\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--use_chunk\",\n",
    "    default=0,\n",
    "    type=float,\n",
    "    help=\"whether use chunck for parallel training.\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--batch_size\", default=30, type=int, help=\"what is the batch size?\"\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--tasks\", default=\"\", type=str, help=\"1-2-3... training task separate by -\"\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--in_memory\",\n",
    "    default=False,\n",
    "    type=bool,\n",
    "    help=\"whether use chunck for parallel training.\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--baseline\", action=\"store_true\", help=\"whether use single stream baseline.\"\n",
    ")\n",
    "parser.add_argument(\"--split\", default=\"\", type=str, help=\"which split to use.\")\n",
    "parser.add_argument(\n",
    "    \"--dynamic_attention\",\n",
    "    action=\"store_true\",\n",
    "    help=\"whether use dynamic attention.\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--clean_train_sets\",\n",
    "    default=True,\n",
    "    type=bool,\n",
    "    help=\"whether clean train sets for multitask data.\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--visual_target\",\n",
    "    default=0,\n",
    "    type=int,\n",
    "    help=\"which target to use for visual branch. \\\n",
    "    0: soft label, \\\n",
    "    1: regress the feature, \\\n",
    "    2: NCE loss.\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--task_specific_tokens\",\n",
    "    action=\"store_true\",\n",
    "    help=\"whether to use task specific tokens for the multi-task learning.\",\n",
    ")\n",
    "\n",
    "args = parser.parse_args(['--bert_model', 'bert-base-uncased',\n",
    "                          '--from_pretrained', 'save/VQA_bert_base_6layer_6conect-finetune_from_multi_task_model/pytorch_model_19.bin',\n",
    "                          '--config_file', 'config/bert_base_6layer_6conect.json',\n",
    "                          '--tasks', '19',\n",
    "                          '--split', 'test',\n",
    "                          '--save_name', 'task-19',\n",
    "                          '--task_specific_tokens',\n",
    "                          '--batch_size', '2000'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Namespace(baseline=False, batch_size=30, bert_model='bert-base-uncased', clean_train_sets=True, config_file='config/bert_base_6layer_6conect.json', do_lower_case=True, dynamic_attention=False, fp16=False, from_pretrained='save/VQA_bert_base_6layer_6conect-finetune_from_multi_task_model/pytorch_model_19.bin', in_memory=False, local_rank=-1, loss_scale=0, no_cuda=False, num_workers=16, output_dir='results', save_name='task-19', seed=42, split='test', task_specific_tokens=True, tasks='19', use_chunk=0, visual_target=0)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "08/05/2020 13:42:04 - INFO - __main__ -   device: cuda n_gpu: 1, distributed training: False, 16-bits training: False\n",
      "08/05/2020 13:42:05 - INFO - pytorch_transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/aloui/.cache/torch/pytorch_transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
      "08/05/2020 13:42:05 - INFO - vilbert.task_utils -   Loading ME Dataset with batch size 2000\n",
      "08/05/2020 13:42:05 - INFO - vilbert.datasets.me_dataset -   Loading from datasets/ME/cache/ME_test_23_cleaned.pkl\n",
      "08/05/2020 13:42:05 - INFO - vilbert.utils -   logging file at: pytorch_model_19.bin-task-19\n"
     ]
    }
   ],
   "source": [
    "with open(\"vilbert_tasks.yml\", \"r\") as f:\n",
    "    task_cfg = edict(yaml.safe_load(f))\n",
    "\n",
    "random.seed(args.seed)\n",
    "np.random.seed(args.seed)\n",
    "torch.manual_seed(args.seed)\n",
    "\n",
    "if args.baseline:\n",
    "    from pytorch_transformers.modeling_bert import BertConfig\n",
    "    from vilbert.basebert import BaseBertForVLTasks\n",
    "else:\n",
    "    from vilbert.vilbert import BertConfig\n",
    "    from vilbert.vilbert import VILBertForVLTasks\n",
    "\n",
    "task_names = []\n",
    "for i, task_id in enumerate(args.tasks.split(\"-\")):\n",
    "    task = \"TASK\" + task_id\n",
    "    name = task_cfg[task][\"name\"]\n",
    "    task_names.append(name)\n",
    "\n",
    "# timeStamp = '-'.join(task_names) + '_' + args.config_file.split('/')[1].split('.')[0]\n",
    "timeStamp = args.from_pretrained.split(\"/\")[-1] + \"-\" + args.save_name\n",
    "savePath = os.path.join(args.output_dir, timeStamp)\n",
    "config = BertConfig.from_json_file(args.config_file)\n",
    "\n",
    "if args.task_specific_tokens:\n",
    "    config.task_specific_tokens = True\n",
    "\n",
    "if args.local_rank == -1 or args.no_cuda:\n",
    "    device = torch.device(\n",
    "        \"cuda\" if torch.cuda.is_available() and not args.no_cuda else \"cpu\"\n",
    "    )\n",
    "    n_gpu = torch.cuda.device_count()\n",
    "else:\n",
    "    torch.cuda.set_device(args.local_rank)\n",
    "    device = torch.device(\"cuda\", args.local_rank)\n",
    "    n_gpu = 1\n",
    "    # Initializes the distributed backend which will take care of sychronizing nodes/GPUs\n",
    "    torch.distributed.init_process_group(backend=\"nccl\")\n",
    "\n",
    "logger.info(\n",
    "    \"device: {} n_gpu: {}, distributed training: {}, 16-bits training: {}\".format(\n",
    "        device, n_gpu, bool(args.local_rank != -1), args.fp16\n",
    "    )\n",
    ")\n",
    "\n",
    "default_gpu = False\n",
    "if dist.is_available() and args.local_rank != -1:\n",
    "    rank = dist.get_rank()\n",
    "    if rank == 0:\n",
    "        default_gpu = True\n",
    "else:\n",
    "    default_gpu = True\n",
    "\n",
    "if default_gpu and not os.path.exists(savePath):\n",
    "    os.makedirs(savePath)\n",
    "\n",
    "task_batch_size, task_num_iters, task_ids, task_datasets_val, task_dataloader_val = LoadDatasetEval(\n",
    "    args, task_cfg, args.tasks.split(\"-\")\n",
    ")\n",
    "\n",
    "tbLogger = utils.tbLogger(\n",
    "    timeStamp,\n",
    "    savePath,\n",
    "    task_names,\n",
    "    task_ids,\n",
    "    task_num_iters,\n",
    "    1,\n",
    "    save_logger=False,\n",
    "    txt_name=\"eval.txt\",\n",
    ")\n",
    "# num_labels = max([dataset.num_labels for dataset in task_datasets_val.values()])\n",
    "\n",
    "if args.dynamic_attention:\n",
    "    config.dynamic_attention = True\n",
    "if \"roberta\" in args.bert_model:\n",
    "    config.model = \"roberta\"\n",
    "\n",
    "if args.visual_target == 0:\n",
    "    config.v_target_size = 1601\n",
    "    config.visual_target = args.visual_target\n",
    "else:\n",
    "    config.v_target_size = 2048\n",
    "    config.visual_target = args.visual_target\n",
    "\n",
    "if args.task_specific_tokens:\n",
    "    config.task_specific_tokens = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable              Type                          Data/Info\n",
      "-------------------------------------------------------------\n",
      "BertConfig            type                          <class 'vilbert.vilbert.BertConfig'>\n",
      "EvaluatingModel       function                      <function EvaluatingModel at 0x7f6474fde268>\n",
      "F                     module                        <module 'torch.nn.functio<...>/torch/nn/functional.py'>\n",
      "ForwardModelsTrain    function                      <function ForwardModelsTrain at 0x7f6474fd8f28>\n",
      "ForwardModelsVal      function                      <function ForwardModelsVal at 0x7f6474fd8ea0>\n",
      "LoadDatasetEval       function                      <function LoadDatasetEval at 0x7f6474fde158>\n",
      "LoadLosses            function                      <function LoadLosses at 0x7f6474fde048>\n",
      "SummaryWriter         type                          <class 'tensorboardX.writer.SummaryWriter'>\n",
      "VILBertForVLTasks     type                          <class 'vilbert.vilbert.VILBertForVLTasks'>\n",
      "argparse              module                        <module 'argparse' from '<...>b/python3.6/argparse.py'>\n",
      "args                  Namespace                     Namespace(baseline=False,<...>chunk=0, visual_target=0)\n",
      "bisect                builtin_function_or_method    <built-in function bisect>\n",
      "config                BertConfig                    {\\n  \"attention_probs_dro<...>h_coattention\": true\\n}\\n\n",
      "default_gpu           bool                          True\n",
      "device                device                        cuda\n",
      "dist                  module                        <module 'torch.distribute<...>distributed/__init__.py'>\n",
      "edict                 type                          <class 'easydict.EasyDict'>\n",
      "evaluate              function                      <function evaluate at 0x7f6474ff4158>\n",
      "f                     TextIOWrapper                 <_io.TextIOWrapper name='<...>ncoding='ANSI_X3.4-1968'>\n",
      "i                     int                           0\n",
      "json                  module                        <module 'json' from '/hom<...>hon3.6/json/__init__.py'>\n",
      "logger                Logger                        <Logger __main__ (INFO)>\n",
      "logging               module                        <module 'logging' from '/<...>3.6/logging/__init__.py'>\n",
      "n_gpu                 int                           1\n",
      "name                  str                           ME\n",
      "nn                    module                        <module 'torch.nn' from '<...>es/torch/nn/__init__.py'>\n",
      "np                    module                        <module 'numpy' from '/ho<...>kages/numpy/__init__.py'>\n",
      "open                  builtin_function_or_method    <built-in function open>\n",
      "os                    module                        <module 'os' from '/home/<...>-mt/lib/python3.6/os.py'>\n",
      "parser                ArgumentParser                ArgumentParser(prog='ipyk<...>r='error', add_help=True)\n",
      "pdb                   module                        <module 'pdb' from '/home<...>mt/lib/python3.6/pdb.py'>\n",
      "random                module                        <module 'random' from '/h<...>lib/python3.6/random.py'>\n",
      "savePath              str                           results/pytorch_model_19.bin-task-19\n",
      "sys                   module                        <module 'sys' (built-in)>\n",
      "task                  str                           TASK19\n",
      "task_batch_size       dict                          n=1\n",
      "task_cfg              EasyDict                      {'TASK1': {'name': 'VQA',<...> 4e-05, 'num_epoch': 20}}\n",
      "task_dataloader_val   dict                          n=1\n",
      "task_datasets_val     dict                          n=1\n",
      "task_id               str                           19\n",
      "task_ids              list                          n=1\n",
      "task_names            list                          n=1\n",
      "task_num_iters        dict                          n=1\n",
      "tbLogger              tbLogger                      <vilbert.utils.tbLogger object at 0x7f6523817630>\n",
      "timeStamp             str                           pytorch_model_19.bin-task-19\n",
      "torch                 module                        <module 'torch' from '/ho<...>kages/torch/__init__.py'>\n",
      "tqdm                  type                          <class 'tqdm._tqdm.tqdm'>\n",
      "utils                 module                        <module 'vilbert.utils' f<...>i-task/vilbert/utils.py'>\n",
      "yaml                  module                        <module 'yaml' from '/hom<...>ckages/yaml/__init__.py'>\n"
     ]
    }
   ],
   "source": [
    "%whos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'TASK19': 2000},\n",
       " {'TASK19': 1},\n",
       " ['TASK19'],\n",
       " {'TASK19': <vilbert.datasets.me_dataset.MERegressionDataset at 0x7f64659a32e8>},\n",
       " {'TASK19': <torch.utils.data.dataloader.DataLoader at 0x7f65203dbcc0>})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task_batch_size, task_num_iters, task_ids, task_datasets_val, task_dataloader_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "08/05/2020 13:59:19 - INFO - vilbert.utils -   loading weights file save/VQA_bert_base_6layer_6conect-finetune_from_multi_task_model/pytorch_model_19.bin\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 11.91 GiB total capacity; 532.23 MiB already allocated; 16.50 MiB free; 572.00 MiB reserved in total by PyTorch)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-877216bb84cf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mtask_losses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLoadLosses\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask_cfg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"-\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocal_rank\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/vilbert-mt/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    423\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 425\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_backward_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/vilbert-mt/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/vilbert-mt/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/vilbert-mt/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/vilbert-mt/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/vilbert-mt/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/vilbert-mt/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/vilbert-mt/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/vilbert-mt/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    221\u001b[0m                 \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m                     \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m                 \u001b[0mshould_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/vilbert-mt/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 423\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    424\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 11.91 GiB total capacity; 532.23 MiB already allocated; 16.50 MiB free; 572.00 MiB reserved in total by PyTorch)"
     ]
    }
   ],
   "source": [
    "num_labels = 0\n",
    "\n",
    "if args.baseline:\n",
    "    model = BaseBertForVLTasks.from_pretrained(\n",
    "        args.from_pretrained,\n",
    "        config=config,\n",
    "        num_labels=num_labels,\n",
    "        default_gpu=default_gpu,\n",
    "    )\n",
    "else:\n",
    "    model = VILBertForVLTasks.from_pretrained(\n",
    "        args.from_pretrained,\n",
    "        config=config,\n",
    "        num_labels=num_labels,\n",
    "        default_gpu=default_gpu,\n",
    "    )\n",
    "\n",
    "task_losses = LoadLosses(args, task_cfg, args.tasks.split(\"-\"))\n",
    "model.to(device)\n",
    "if args.local_rank != -1:\n",
    "    try:\n",
    "        from apex.parallel import DistributedDataParallel as DDP\n",
    "    except ImportError:\n",
    "        raise ImportError(\n",
    "            \"Please install apex from https://www.github.com/nvidia/apex to use distributed and fp16 training.\"\n",
    "        )\n",
    "    model = DDP(model, delay_allreduce=True)\n",
    "\n",
    "elif n_gpu > 1:\n",
    "    model = nn.DataParallel(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"***** Running evaluation *****\")\n",
    "print(\"  Num Iters: \", task_num_iters)\n",
    "print(\"  Batch size: \", task_batch_size)\n",
    "\n",
    "model.eval()\n",
    "# when run evaluate, we run each task sequentially.\n",
    "for task_id in task_ids:\n",
    "    results = []\n",
    "    others = []\n",
    "    for i, batch in enumerate(task_dataloader_val[task_id]):\n",
    "        loss, score, batch_size, results, others = EvaluatingModel(\n",
    "            args,\n",
    "            task_cfg,\n",
    "            device,\n",
    "            task_id,\n",
    "            batch,\n",
    "            model,\n",
    "            task_dataloader_val,\n",
    "            task_losses,\n",
    "            results,\n",
    "            others,\n",
    "        )\n",
    "\n",
    "        tbLogger.step_val(0, float(loss), float(score), task_id, batch_size, \"val\")\n",
    "        sys.stdout.write(\"%d/%d\\r\" % (i, len(task_dataloader_val[task_id])))\n",
    "        sys.stdout.flush()\n",
    "    # save the result or evaluate the result.\n",
    "    ave_score = tbLogger.showLossVal(task_id)\n",
    "\n",
    "    if args.split:\n",
    "        json_path = os.path.join(savePath, args.split)\n",
    "    else:\n",
    "        json_path = os.path.join(savePath, task_cfg[task_id][\"val_split\"])\n",
    "\n",
    "    json.dump(results, open(json_path + \"_result.json\", \"w\"))\n",
    "    json.dump(others, open(json_path + \"_others.json\", \"w\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
