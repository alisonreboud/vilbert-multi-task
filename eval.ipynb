{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/aloui/miniconda3/envs/vilbert-mt/lib/python3.6/site-packages/tensorpack/callbacks/hooks.py:17: The name tf.train.SessionRunHook is deprecated. Please use tf.estimator.SessionRunHook instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/aloui/miniconda3/envs/vilbert-mt/lib/python3.6/site-packages/tensorpack/tfutils/optimizer.py:18: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/aloui/miniconda3/envs/vilbert-mt/lib/python3.6/site-packages/tensorpack/tfutils/sesscreate.py:20: The name tf.train.SessionCreator is deprecated. Please use tf.compat.v1.train.SessionCreator instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import json\n",
    "import logging\n",
    "import os\n",
    "import random\n",
    "from io import open\n",
    "import numpy as np\n",
    "\n",
    "from tensorboardX import SummaryWriter\n",
    "from tqdm import tqdm\n",
    "from bisect import bisect\n",
    "import yaml\n",
    "from easydict import EasyDict as edict\n",
    "import sys\n",
    "import pdb\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "\n",
    "from vilbert.task_utils import (\n",
    "    LoadDatasetEval,\n",
    "    LoadLosses,\n",
    "    ForwardModelsTrain,\n",
    "    ForwardModelsVal,\n",
    "    EvaluatingModel,\n",
    ")\n",
    "\n",
    "import vilbert.utils as utils\n",
    "import torch.distributed as dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(\n",
    "    format=\"%(asctime)s - %(levelname)s - %(name)s -   %(message)s\",\n",
    "    datefmt=\"%m/%d/%Y %H:%M:%S\",\n",
    "    level=logging.INFO,\n",
    ")\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "08/05/2020 11:42:41 - INFO - __main__ -   device: cuda n_gpu: 1, distributed training: False, 16-bits training: False\n",
      "08/05/2020 11:42:42 - INFO - pytorch_transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/aloui/.cache/torch/pytorch_transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
      "08/05/2020 11:42:42 - INFO - vilbert.task_utils -   Loading VQA Dataset with batch size 30\n",
      "08/05/2020 11:42:42 - INFO - vilbert.datasets.vqa_dataset -   Loading from datasets/VQA/cache/VQA_minval_23_cleaned.pkl\n",
      "08/05/2020 11:42:43 - INFO - vilbert.utils -   logging file at: pytorch_model_19.bin-jupyter-test\n",
      "08/05/2020 11:42:43 - INFO - vilbert.utils -   loading weights file save/VQA_bert_base_6layer_6conect-finetune_from_multi_task_model/pytorch_model_19.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Running evaluation *****\n",
      "  Num Iters:  {'TASK1': 100}\n",
      "  Batch size:  {'TASK1': 30}\n",
      "99/100\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "08/05/2020 11:43:11 - INFO - vilbert.utils -   Eval task TASK1 on iteration 0 \n",
      "08/05/2020 11:43:11 - INFO - vilbert.utils -   Validation [VQA]: loss 3.511 score 70.157 \n"
     ]
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "parser.add_argument(\n",
    "    \"--bert_model\",\n",
    "    default=\"bert-base-uncased\",\n",
    "    type=str,\n",
    "    help=\"Bert pre-trained model selected in the list: bert-base-uncased, \"\n",
    "    \"bert-large-uncased, bert-base-cased, bert-base-multilingual, bert-base-chinese.\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--from_pretrained\",\n",
    "    default=\"bert-base-uncased\",\n",
    "    type=str,\n",
    "    help=\"Bert pre-trained model selected in the list: bert-base-uncased, \"\n",
    "    \"bert-large-uncased, bert-base-cased, bert-base-multilingual, bert-base-chinese.\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--output_dir\",\n",
    "    default=\"results\",\n",
    "    type=str,\n",
    "    help=\"The output directory where the model checkpoints will be written.\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--config_file\",\n",
    "    default=\"config/bert_config.json\",\n",
    "    type=str,\n",
    "    help=\"The config file which specified the model details.\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--no_cuda\", action=\"store_true\", help=\"Whether not to use CUDA when available\"\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--do_lower_case\",\n",
    "    default=True,\n",
    "    type=bool,\n",
    "    help=\"Whether to lower case the input text. True for uncased models, False for cased models.\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--local_rank\",\n",
    "    type=int,\n",
    "    default=-1,\n",
    "    help=\"local_rank for distributed training on gpus\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--seed\", type=int, default=42, help=\"random seed for initialization\"\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--fp16\",\n",
    "    action=\"store_true\",\n",
    "    help=\"Whether to use 16-bit float precision instead of 32-bit\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--loss_scale\",\n",
    "    type=float,\n",
    "    default=0,\n",
    "    help=\"Loss scaling to improve fp16 numeric stability. Only used when fp16 set to True.\\n\"\n",
    "    \"0 (default value): dynamic loss scaling.\\n\"\n",
    "    \"Positive power of 2: static loss scaling value.\\n\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--num_workers\",\n",
    "    type=int,\n",
    "    default=16,\n",
    "    help=\"Number of workers in the dataloader.\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--save_name\", default=\"\", type=str, help=\"save name for training.\"\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--use_chunk\",\n",
    "    default=0,\n",
    "    type=float,\n",
    "    help=\"whether use chunck for parallel training.\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--batch_size\", default=30, type=int, help=\"what is the batch size?\"\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--tasks\", default=\"\", type=str, help=\"1-2-3... training task separate by -\"\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--in_memory\",\n",
    "    default=False,\n",
    "    type=bool,\n",
    "    help=\"whether use chunck for parallel training.\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--baseline\", action=\"store_true\", help=\"whether use single stream baseline.\"\n",
    ")\n",
    "parser.add_argument(\"--split\", default=\"\", type=str, help=\"which split to use.\")\n",
    "parser.add_argument(\n",
    "    \"--dynamic_attention\",\n",
    "    action=\"store_true\",\n",
    "    help=\"whether use dynamic attention.\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--clean_train_sets\",\n",
    "    default=True,\n",
    "    type=bool,\n",
    "    help=\"whether clean train sets for multitask data.\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--visual_target\",\n",
    "    default=0,\n",
    "    type=int,\n",
    "    help=\"which target to use for visual branch. \\\n",
    "    0: soft label, \\\n",
    "    1: regress the feature, \\\n",
    "    2: NCE loss.\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--task_specific_tokens\",\n",
    "    action=\"store_true\",\n",
    "    help=\"whether to use task specific tokens for the multi-task learning.\",\n",
    ")\n",
    "\n",
    "#args = parser.parse_args()\n",
    "args = parser.parse_args(['--bert_model', 'bert-base-uncased',\n",
    "                          '--from_pretrained', 'save/VQA_bert_base_6layer_6conect-finetune_from_multi_task_model/pytorch_model_19.bin',\n",
    "                          '--config_file', 'config/bert_base_6layer_6conect.json',\n",
    "                          '--tasks', '1',\n",
    "                          '--split', 'minval',\n",
    "                          '--save_name', 'jupyter-test',\n",
    "                          '--task_specific_tokens'])\n",
    "\n",
    "\n",
    "with open(\"vilbert_tasks.yml\", \"r\") as f:\n",
    "    task_cfg = edict(yaml.safe_load(f))\n",
    "\n",
    "random.seed(args.seed)\n",
    "np.random.seed(args.seed)\n",
    "torch.manual_seed(args.seed)\n",
    "\n",
    "if args.baseline:\n",
    "    from pytorch_transformers.modeling_bert import BertConfig\n",
    "    from vilbert.basebert import BaseBertForVLTasks\n",
    "else:\n",
    "    from vilbert.vilbert import BertConfig\n",
    "    from vilbert.vilbert import VILBertForVLTasks\n",
    "\n",
    "task_names = []\n",
    "for i, task_id in enumerate(args.tasks.split(\"-\")):\n",
    "    task = \"TASK\" + task_id\n",
    "    name = task_cfg[task][\"name\"]\n",
    "    task_names.append(name)\n",
    "\n",
    "# timeStamp = '-'.join(task_names) + '_' + args.config_file.split('/')[1].split('.')[0]\n",
    "timeStamp = args.from_pretrained.split(\"/\")[-1] + \"-\" + args.save_name\n",
    "savePath = os.path.join(args.output_dir, timeStamp)\n",
    "config = BertConfig.from_json_file(args.config_file)\n",
    "\n",
    "if args.task_specific_tokens:\n",
    "    config.task_specific_tokens = True\n",
    "\n",
    "if args.local_rank == -1 or args.no_cuda:\n",
    "    device = torch.device(\n",
    "        \"cuda\" if torch.cuda.is_available() and not args.no_cuda else \"cpu\"\n",
    "    )\n",
    "    n_gpu = torch.cuda.device_count()\n",
    "else:\n",
    "    torch.cuda.set_device(args.local_rank)\n",
    "    device = torch.device(\"cuda\", args.local_rank)\n",
    "    n_gpu = 1\n",
    "    # Initializes the distributed backend which will take care of sychronizing nodes/GPUs\n",
    "    torch.distributed.init_process_group(backend=\"nccl\")\n",
    "\n",
    "logger.info(\n",
    "    \"device: {} n_gpu: {}, distributed training: {}, 16-bits training: {}\".format(\n",
    "        device, n_gpu, bool(args.local_rank != -1), args.fp16\n",
    "    )\n",
    ")\n",
    "\n",
    "default_gpu = False\n",
    "if dist.is_available() and args.local_rank != -1:\n",
    "    rank = dist.get_rank()\n",
    "    if rank == 0:\n",
    "        default_gpu = True\n",
    "else:\n",
    "    default_gpu = True\n",
    "\n",
    "if default_gpu and not os.path.exists(savePath):\n",
    "    os.makedirs(savePath)\n",
    "\n",
    "task_batch_size, task_num_iters, task_ids, task_datasets_val, task_dataloader_val = LoadDatasetEval(\n",
    "    args, task_cfg, args.tasks.split(\"-\")\n",
    ")\n",
    "\n",
    "tbLogger = utils.tbLogger(\n",
    "    timeStamp,\n",
    "    savePath,\n",
    "    task_names,\n",
    "    task_ids,\n",
    "    task_num_iters,\n",
    "    1,\n",
    "    save_logger=False,\n",
    "    txt_name=\"eval.txt\",\n",
    ")\n",
    "num_labels = max([dataset.num_labels for dataset in task_datasets_val.values()])\n",
    "\n",
    "if args.dynamic_attention:\n",
    "    config.dynamic_attention = True\n",
    "if \"roberta\" in args.bert_model:\n",
    "    config.model = \"roberta\"\n",
    "\n",
    "if args.visual_target == 0:\n",
    "    config.v_target_size = 1601\n",
    "    config.visual_target = args.visual_target\n",
    "else:\n",
    "    config.v_target_size = 2048\n",
    "    config.visual_target = args.visual_target\n",
    "\n",
    "if args.task_specific_tokens:\n",
    "    config.task_specific_tokens = True\n",
    "\n",
    "if args.baseline:\n",
    "    model = BaseBertForVLTasks.from_pretrained(\n",
    "        args.from_pretrained,\n",
    "        config=config,\n",
    "        num_labels=num_labels,\n",
    "        default_gpu=default_gpu,\n",
    "    )\n",
    "else:\n",
    "    model = VILBertForVLTasks.from_pretrained(\n",
    "        args.from_pretrained,\n",
    "        config=config,\n",
    "        num_labels=num_labels,\n",
    "        default_gpu=default_gpu,\n",
    "    )\n",
    "\n",
    "task_losses = LoadLosses(args, task_cfg, args.tasks.split(\"-\"))\n",
    "model.to(device)\n",
    "if args.local_rank != -1:\n",
    "    try:\n",
    "        from apex.parallel import DistributedDataParallel as DDP\n",
    "    except ImportError:\n",
    "        raise ImportError(\n",
    "            \"Please install apex from https://www.github.com/nvidia/apex to use distributed and fp16 training.\"\n",
    "        )\n",
    "    model = DDP(model, delay_allreduce=True)\n",
    "\n",
    "elif n_gpu > 1:\n",
    "    model = nn.DataParallel(model)\n",
    "\n",
    "print(\"***** Running evaluation *****\")\n",
    "print(\"  Num Iters: \", task_num_iters)\n",
    "print(\"  Batch size: \", task_batch_size)\n",
    "\n",
    "model.eval()\n",
    "# when run evaluate, we run each task sequentially.\n",
    "for task_id in task_ids:\n",
    "    results = []\n",
    "    others = []\n",
    "    \n",
    "    for i, batch in enumerate(task_dataloader_val[task_id]):\n",
    "        loss, score, batch_size, results, others = EvaluatingModel(\n",
    "            args,\n",
    "            task_cfg,\n",
    "            device,\n",
    "            task_id,\n",
    "            batch,\n",
    "            model,\n",
    "            task_dataloader_val,\n",
    "            task_losses,\n",
    "            results,\n",
    "            others,\n",
    "        )\n",
    "\n",
    "        tbLogger.step_val(0, float(loss), float(score), task_id, batch_size, \"val\")\n",
    "        sys.stdout.write(\"%d/%d\\r\" % (i, len(task_dataloader_val[task_id])))\n",
    "        sys.stdout.flush()\n",
    "    # save the result or evaluate the result.\n",
    "    ave_score = tbLogger.showLossVal(task_id)\n",
    "\n",
    "    if args.split:\n",
    "        json_path = os.path.join(savePath, args.split)\n",
    "    else:\n",
    "        json_path = os.path.join(savePath, task_cfg[task_id][\"val_split\"])\n",
    "\n",
    "    json.dump(results, open(json_path + \"_result.json\", \"w\"))\n",
    "    json.dump(others, open(json_path + \"_others.json\", \"w\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable              Type                          Data/Info\n",
      "-------------------------------------------------------------\n",
      "BertConfig            type                          <class 'vilbert.vilbert.BertConfig'>\n",
      "EvaluatingModel       function                      <function EvaluatingModel at 0x7eff0aff5158>\n",
      "F                     module                        <module 'torch.nn.functio<...>/torch/nn/functional.py'>\n",
      "ForwardModelsTrain    function                      <function ForwardModelsTrain at 0x7eff0afefe18>\n",
      "ForwardModelsVal      function                      <function ForwardModelsVal at 0x7eff0afefd90>\n",
      "LoadDatasetEval       function                      <function LoadDatasetEval at 0x7eff0aff5048>\n",
      "LoadLosses            function                      <function LoadLosses at 0x7eff0afefea0>\n",
      "SummaryWriter         type                          <class 'tensorboardX.writer.SummaryWriter'>\n",
      "VILBertForVLTasks     type                          <class 'vilbert.vilbert.VILBertForVLTasks'>\n",
      "argparse              module                        <module 'argparse' from '<...>b/python3.6/argparse.py'>\n",
      "args                  Namespace                     Namespace(baseline=False,<...>chunk=0, visual_target=0)\n",
      "ave_score             float                         0.7015666596094767\n",
      "batch                 list                          n=9\n",
      "batch_size            int                           30\n",
      "bisect                builtin_function_or_method    <built-in function bisect>\n",
      "config                BertConfig                    {\\n  \"attention_probs_dro<...>h_coattention\": true\\n}\\n\n",
      "default_gpu           bool                          True\n",
      "device                device                        cuda\n",
      "dist                  module                        <module 'torch.distribute<...>distributed/__init__.py'>\n",
      "edict                 type                          <class 'easydict.EasyDict'>\n",
      "f                     TextIOWrapper                 <_io.TextIOWrapper name='<...>ncoding='ANSI_X3.4-1968'>\n",
      "i                     int                           99\n",
      "json                  module                        <module 'json' from '/hom<...>hon3.6/json/__init__.py'>\n",
      "json_path             str                           results/pytorch_model_19.bin-jupyter-test/minval\n",
      "logger                Logger                        <Logger __main__ (INFO)>\n",
      "logging               module                        <module 'logging' from '/<...>3.6/logging/__init__.py'>\n",
      "loss                  float                         2.875596761703491\n",
      "model                 VILBertForVLTasks             VILBertForVLTasks(\\n  (be<...>features=1, bias=True)\\n)\n",
      "n_gpu                 int                           1\n",
      "name                  str                           VQA\n",
      "nn                    module                        <module 'torch.nn' from '<...>es/torch/nn/__init__.py'>\n",
      "np                    module                        <module 'numpy' from '/ho<...>kages/numpy/__init__.py'>\n",
      "num_labels            int                           3129\n",
      "open                  builtin_function_or_method    <built-in function open>\n",
      "os                    module                        <module 'os' from '/home/<...>-mt/lib/python3.6/os.py'>\n",
      "others                list                          n=0\n",
      "parser                ArgumentParser                ArgumentParser(prog='ipyk<...>r='error', add_help=True)\n",
      "pdb                   module                        <module 'pdb' from '/home<...>mt/lib/python3.6/pdb.py'>\n",
      "random                module                        <module 'random' from '/h<...>lib/python3.6/random.py'>\n",
      "results               list                          n=3000\n",
      "savePath              str                           results/pytorch_model_19.bin-jupyter-test\n",
      "score                 float                         21.099998474121094\n",
      "sys                   module                        <module 'sys' (built-in)>\n",
      "task                  str                           TASK1\n",
      "task_batch_size       dict                          n=1\n",
      "task_cfg              EasyDict                      {'TASK1': {'name': 'VQA',<...> 4e-05, 'num_epoch': 20}}\n",
      "task_dataloader_val   dict                          n=1\n",
      "task_datasets_val     dict                          n=1\n",
      "task_id               str                           TASK1\n",
      "task_ids              list                          n=1\n",
      "task_losses           dict                          n=1\n",
      "task_names            list                          n=1\n",
      "task_num_iters        dict                          n=1\n",
      "tbLogger              tbLogger                      <vilbert.utils.tbLogger object at 0x7eff47c30dd8>\n",
      "timeStamp             str                           pytorch_model_19.bin-jupyter-test\n",
      "torch                 module                        <module 'torch' from '/ho<...>kages/torch/__init__.py'>\n",
      "tqdm                  type                          <class 'tqdm._tqdm.tqdm'>\n",
      "utils                 module                        <module 'vilbert.utils' f<...>i-task/vilbert/utils.py'>\n",
      "yaml                  module                        <module 'yaml' from '/hom<...>ckages/yaml/__init__.py'>\n"
     ]
    }
   ],
   "source": [
    "%whos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Namespace(baseline=False, batch_size=30, bert_model='bert-base-uncased', clean_train_sets=True, config_file='config/bert_base_6layer_6conect.json', do_lower_case=True, dynamic_attention=False, fp16=False, from_pretrained='save/VQA_bert_base_6layer_6conect-finetune_from_multi_task_model/pytorch_model_19.bin', in_memory=False, local_rank=-1, loss_scale=0, no_cuda=False, num_workers=16, output_dir='results', save_name='jupyter-test', seed=42, split='minval', task_specific_tokens=True, tasks='1', use_chunk=0, visual_target=0)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = tuple(t.cuda(device=device, non_blocking=True) for t in batch)\n",
    "\n",
    "features, spatials, image_mask, question, target, input_mask, segment_ids, co_attention_mask, question_id = (\n",
    "    batch\n",
    ")\n",
    "\n",
    "task_tokens = question.new().resize_(question.size(0), 1).fill_(int(task_id[4:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "vil_prediction, vil_prediction_gqa, vil_logit, vil_binary_prediction, vil_tri_prediction, vision_prediction, vision_logit, linguisic_prediction, linguisic_logit, _ = model(\n",
    "    question, \n",
    "    features, \n",
    "    spatials, \n",
    "    segment_ids, \n",
    "    input_mask, \n",
    "    image_mask, \n",
    "    co_attention_mask, \n",
    "    task_tokens,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = torch.max(vil_prediction, 1)[1].data  # argmax\n",
    "one_hots = torch.zeros(*target.size()).cuda()\n",
    "one_hots.scatter_(1, logits.view(-1, 1), 1)\n",
    "scores = one_hots * target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.7033, device='cuda:0')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores.sum() / features.size(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/aloui/vilbert-multi-task/vilbert/vilbert.py:1333: TracerWarning: resize_ can't be represented in the JIT at the moment, so we won't connect any uses of this value with its current trace. If you happen to use it again, it will show up as a constant in the graph.\n",
      "  mask_tokens = input_txt.new().resize_(input_txt.size(0), 1).fill_(1)\n",
      "/aloui/vilbert-multi-task/vilbert/vilbert.py:1686: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if pooled_output.size(0) % 2 == 0:\n",
      "/home/aloui/miniconda3/envs/vilbert-mt/lib/python3.6/site-packages/torch/tensor.py:461: RuntimeWarning: Iterating over a tensor might cause the trace to be incorrect. Passing a tensor of different shape won't change the number of iterations executed (and might lead to errors or silently give incorrect results).\n",
      "  'incorrect results).', category=RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tracer cannot infer type of (tensor([[-23.9768, -17.3129, -18.0523,  ..., -18.6565, -18.3060, -14.8244],\n",
      "        [-26.2138, -18.8952, -17.7499,  ..., -17.4112, -15.3365, -17.8206],\n",
      "        [-24.8113, -16.7020, -11.6527,  ..., -15.2050, -14.3076, -10.0045],\n",
      "        ...,\n",
      "        [-27.0051, -15.3371, -20.5083,  ..., -19.9755, -16.9174, -17.5259],\n",
      "        [-21.7966, -14.3504, -19.0064,  ..., -13.6335, -11.8910, -26.7599],\n",
      "        [-23.3009, -11.6584, -19.6952,  ..., -18.6055, -13.8711, -18.0167]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>), tensor([[-11.6474, -10.8408,  -8.1201,  ..., -13.7666, -13.3638, -14.8178],\n",
      "        [-14.1130,  -8.2416, -11.8985,  ..., -15.3526, -14.5676, -16.1072],\n",
      "        [-10.0281,  -8.5481, -12.1849,  ...,  -9.9922, -13.6915, -11.6269],\n",
      "        ...,\n",
      "        [-20.1335, -18.3920, -17.5234,  ..., -20.9741, -23.5247, -22.5615],\n",
      "        [ -6.5798,  -8.0710,  -7.1975,  ...,  -9.0155,  -8.8422, -10.2870],\n",
      "        [-18.6119, -14.4927, -17.6004,  ..., -18.2182, -18.8035, -19.1235]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>), tensor([[-0.6393],\n",
      "        [-0.1429],\n",
      "        [-2.1546],\n",
      "        [-5.1147],\n",
      "        [-1.6715],\n",
      "        [ 0.3507],\n",
      "        [-4.3397],\n",
      "        [ 2.2866],\n",
      "        [-1.4691],\n",
      "        [ 1.4585],\n",
      "        [-0.2973],\n",
      "        [ 0.7474],\n",
      "        [ 2.5556],\n",
      "        [-2.9994],\n",
      "        [-0.9246],\n",
      "        [-1.2214],\n",
      "        [ 0.3344],\n",
      "        [ 2.2141],\n",
      "        [-0.7545],\n",
      "        [ 2.4200],\n",
      "        [-0.0531],\n",
      "        [ 3.1947],\n",
      "        [-0.2689],\n",
      "        [ 0.4529],\n",
      "        [-0.3984],\n",
      "        [-0.2024],\n",
      "        [ 1.1264],\n",
      "        [ 1.3671],\n",
      "        [-3.4349],\n",
      "        [-0.3805]], device='cuda:0', grad_fn=<AddmmBackward>), tensor([[ -1.8382,   2.1890],\n",
      "        [  9.7137,  -9.1303],\n",
      "        [  1.1245,  -0.7504],\n",
      "        [ -8.7560,   9.4857],\n",
      "        [-12.7439,  12.7932],\n",
      "        [-12.3451,  12.5709],\n",
      "        [ -1.1877,   0.6844],\n",
      "        [ -4.0932,   4.0128],\n",
      "        [ -4.8093,   5.3705],\n",
      "        [ -3.7177,   3.9173],\n",
      "        [-12.6056,  12.4244],\n",
      "        [ 10.6988, -10.2227],\n",
      "        [  2.8526,  -2.8399],\n",
      "        [ -7.0294,   7.1356],\n",
      "        [-10.3483,   9.9678]], device='cuda:0', grad_fn=<AddmmBackward>), tensor([[-1.3022, -1.1211, -3.1991],\n",
      "        [-0.0492, -0.8463, -3.6581],\n",
      "        [-0.1244, -1.9052, -2.7197],\n",
      "        [-1.2288,  0.7291, -5.5015],\n",
      "        [-0.3299, -2.6304, -0.9506],\n",
      "        [-1.6865, -1.4229, -2.1603],\n",
      "        [ 0.4084, -1.3018, -4.3268],\n",
      "        [-3.0534, -1.7261,  0.4608],\n",
      "        [ 0.6957, -1.7683, -3.7300],\n",
      "        [-2.5832, -0.6753, -0.2382],\n",
      "        [-0.4761, -1.3521, -2.6981],\n",
      "        [-2.4724, -0.0574, -2.8649],\n",
      "        [-3.2873,  0.2401, -0.6161],\n",
      "        [ 2.8250, -3.0116, -5.6009],\n",
      "        [ 0.4068,  0.0392, -5.6889],\n",
      "        [ 0.2833, -1.2190, -3.7594],\n",
      "        [-1.5270, -1.1284, -2.1290],\n",
      "        [-2.2854, -2.1912,  0.3826],\n",
      "        [-0.8855, -0.2406, -2.5146],\n",
      "        [-2.2929, -1.9686,  0.3879],\n",
      "        [-0.9590, -0.1366, -3.1811],\n",
      "        [-3.6603, -1.3946,  1.0387],\n",
      "        [-2.8627,  0.4189, -2.4454],\n",
      "        [-0.9705, -0.0349, -1.1119],\n",
      "        [-1.2466, -2.2507, -3.0363],\n",
      "        [-0.8483, -2.6603, -3.1504],\n",
      "        [-2.7211, -2.8056, -0.4124],\n",
      "        [-0.7093, -1.7536, -2.3936],\n",
      "        [-1.6274,  0.5352, -3.8358],\n",
      "        [-2.8041, -0.9302, -1.3755]], device='cuda:0', grad_fn=<AddmmBackward>), tensor([[[  8.1071,  -5.0885,  -3.7664,  ...,  -1.4273,  -0.9021,  -4.1969],\n",
      "         [  3.8177,  -4.5532,  -2.8071,  ...,  -1.3409,  -1.7692,  -2.2690],\n",
      "         [  7.0173,  -5.5335,  -4.4290,  ...,  -1.3300,   0.1980,  -3.6034],\n",
      "         ...,\n",
      "         [  7.1785,  -6.1633,  -3.6649,  ...,  -1.6600,  -1.7262,  -5.0354],\n",
      "         [  6.9941,  -5.3046,  -2.6913,  ...,  -3.1742,  -2.2862,  -3.5778],\n",
      "         [  7.5086,  -5.9734,  -2.9408,  ...,  -3.7117,  -2.2481,  -3.2648]],\n",
      "\n",
      "        [[  7.4254,  -6.7579,  -4.9328,  ...,  -3.9803,  -2.2647,  -2.4394],\n",
      "         [  7.2897,  -5.9018,  -5.5442,  ...,  -1.9450,  -1.7594,  -4.7357],\n",
      "         [  5.6920,  -5.7744,  -4.4779,  ...,  -3.6136,  -1.5126,  -1.5384],\n",
      "         ...,\n",
      "         [  6.6963,  -6.7992,  -6.3011,  ...,  -3.5846,  -2.3700,  -3.7784],\n",
      "         [  7.2653,  -5.9123,  -5.5892,  ...,  -1.9841,  -1.7899,  -4.7843],\n",
      "         [  7.7138,  -5.0347,  -4.6088,  ...,  -3.1614,  -3.4179,  -4.0131]],\n",
      "\n",
      "        [[  5.2152,  -8.8324,  -3.6273,  ...,  -6.6085,  -4.7241,  -6.8234],\n",
      "         [  4.8676,  -4.3746,  -2.4917,  ...,  -3.3825,  -0.8355,  -2.7390],\n",
      "         [  4.8747,  -7.0232,  -4.1367,  ...,  -4.1859,  -2.7916,  -3.0367],\n",
      "         ...,\n",
      "         [  5.6844, -10.0907,  -4.7995,  ...,  -5.5661,  -3.4763,  -6.9165],\n",
      "         [  3.8252,  -4.4261,  -1.5736,  ...,  -3.6205,  -0.7457,  -2.6781],\n",
      "         [  5.5476,  -8.0797,  -5.3136,  ...,  -5.9175,  -4.6428,  -6.6182]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[  6.2329,  -5.6986,  -4.4003,  ...,  -4.9978,  -5.4505,  -6.0065],\n",
      "         [  4.5816,  -3.0084,  -4.3789,  ...,  -3.6890,  -0.4907,  -4.3853],\n",
      "         [  4.2864,  -4.2727,  -3.4970,  ...,  -3.9741,  -3.0780,  -6.3296],\n",
      "         ...,\n",
      "         [  6.5369,  -4.8309,  -2.7178,  ...,  -5.2795,  -4.7246,  -5.6874],\n",
      "         [  7.1938,  -2.4227,  -3.5248,  ...,  -4.8716,  -4.8112,  -6.5379],\n",
      "         [  6.7999,  -4.8870,  -0.2368,  ...,  -5.6579,  -5.1136,  -3.9159]],\n",
      "\n",
      "        [[  4.2967,  -6.3247,  -5.5420,  ...,  -4.6959,  -4.1590,  -5.7608],\n",
      "         [  5.8049,  -3.6484,  -4.5866,  ...,  -3.8342,  -1.8794,  -5.5023],\n",
      "         [  5.3276,  -3.8784,  -3.4268,  ...,  -3.0494,  -3.3516,  -5.3999],\n",
      "         ...,\n",
      "         [  4.5262,  -5.7328,  -4.5576,  ...,  -5.2571,  -4.0224,  -4.7971],\n",
      "         [  6.1058,  -2.9771,  -4.3419,  ...,  -3.4850,  -3.5584,  -6.0711],\n",
      "         [  6.0065,  -6.8486,  -2.9187,  ...,  -5.1517,  -3.8328,  -5.4005]],\n",
      "\n",
      "        [[  6.7952,  -5.9581,  -3.8170,  ...,  -6.1306,  -3.8980,  -5.2182],\n",
      "         [  4.7843,  -4.3625,  -3.4503,  ...,  -3.0429,  -1.0069,  -5.0160],\n",
      "         [  4.7423,  -4.0734,  -2.0026,  ...,  -3.3397,  -1.5319,  -5.5408],\n",
      "         ...,\n",
      "         [  5.9233,  -6.7720,  -3.2585,  ...,  -5.0303,  -3.6403,  -6.4752],\n",
      "         [  6.4932,  -3.8687,  -2.0943,  ...,  -4.3999,  -3.3642,  -6.5363],\n",
      "         [  7.4559,  -5.1406,   0.5284,  ...,  -4.9604,  -4.5710,  -5.3826]]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>), tensor([[[-1.0254],\n",
      "         [ 0.5791],\n",
      "         [-0.6458],\n",
      "         ...,\n",
      "         [-1.2198],\n",
      "         [-2.7965],\n",
      "         [-1.1531]],\n",
      "\n",
      "        [[-1.1604],\n",
      "         [-0.9972],\n",
      "         [-2.1179],\n",
      "         ...,\n",
      "         [-0.9099],\n",
      "         [-1.0286],\n",
      "         [-3.0328]],\n",
      "\n",
      "        [[-5.0549],\n",
      "         [-3.8171],\n",
      "         [-1.7807],\n",
      "         ...,\n",
      "         [-5.8512],\n",
      "         [-3.3489],\n",
      "         [-4.7341]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-1.6947],\n",
      "         [-0.4835],\n",
      "         [-4.9195],\n",
      "         ...,\n",
      "         [-3.5398],\n",
      "         [-3.4552],\n",
      "         [-3.4297]],\n",
      "\n",
      "        [[ 0.4876],\n",
      "         [-2.0698],\n",
      "         [-3.0662],\n",
      "         ...,\n",
      "         [-1.2132],\n",
      "         [-1.7824],\n",
      "         [-0.7635]],\n",
      "\n",
      "        [[ 0.7829],\n",
      "         [ 0.2189],\n",
      "         [-2.1548],\n",
      "         ...,\n",
      "         [-1.7861],\n",
      "         [-2.7979],\n",
      "         [-1.9784]]], device='cuda:0', grad_fn=<AddBackward0>), tensor([[[-3.6498, -3.4908, -3.6187,  ..., -3.5289, -3.8178, -3.6744],\n",
      "         [-3.2804, -3.1006, -3.1543,  ..., -3.0870, -3.3823, -3.2175],\n",
      "         [-3.5100, -3.3237, -3.3740,  ..., -3.3072, -3.5707, -3.4169],\n",
      "         ...,\n",
      "         [-4.1081, -4.0421, -4.0378,  ..., -3.9809, -4.1430, -4.1447],\n",
      "         [-4.1650, -4.0987, -4.1115,  ..., -4.0453, -4.2243, -4.2235],\n",
      "         [-4.1392, -4.0736, -4.0614,  ..., -3.9937, -4.1944, -4.1707]],\n",
      "\n",
      "        [[-2.3112, -2.3721, -2.2133,  ..., -2.6004, -2.6427, -2.4511],\n",
      "         [-3.4823, -3.5827, -3.4849,  ..., -3.5824, -3.7505, -3.5713],\n",
      "         [-3.5046, -3.6621, -3.5683,  ..., -3.6990, -3.8633, -3.6441],\n",
      "         ...,\n",
      "         [-3.8630, -3.8739, -3.7105,  ..., -4.0762, -4.0627, -3.8866],\n",
      "         [-3.8149, -3.8647, -3.6870,  ..., -4.0637, -4.0323, -3.8605],\n",
      "         [-4.1886, -4.2119, -4.0773,  ..., -4.4352, -4.3988, -4.2430]],\n",
      "\n",
      "        [[-1.9862, -1.7931, -1.7450,  ..., -1.8751, -2.1345, -2.0390],\n",
      "         [-1.5100, -1.3702, -1.2807,  ..., -1.4770, -1.6623, -1.6035],\n",
      "         [-1.5638, -1.4044, -1.3180,  ..., -1.5494, -1.7191, -1.6515],\n",
      "         ...,\n",
      "         [-1.8217, -1.6298, -1.5178,  ..., -1.8839, -1.9941, -1.8687],\n",
      "         [-2.0018, -1.8120, -1.7015,  ..., -2.0700, -2.1824, -2.0502],\n",
      "         [-1.9469, -1.7752, -1.6727,  ..., -2.0368, -2.1384, -1.9946]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.7459, -0.2746, -0.5147,  ..., -0.6378, -0.9469, -0.7759],\n",
      "         [-0.9958, -0.5589, -0.7966,  ..., -0.9018, -1.2208, -1.0370],\n",
      "         [-1.0953, -0.6611, -0.8872,  ..., -0.9099, -1.3346, -1.0890],\n",
      "         ...,\n",
      "         [-1.7204, -1.1448, -1.5489,  ..., -1.9175, -1.9201, -1.9237],\n",
      "         [-1.1636, -0.6134, -0.9931,  ..., -1.3438, -1.3703, -1.3533],\n",
      "         [-1.0375, -0.4929, -0.8435,  ..., -1.2396, -1.2365, -1.2116]],\n",
      "\n",
      "        [[-2.3704, -2.1079, -2.2421,  ..., -2.4508, -2.8402, -2.6562],\n",
      "         [-3.5595, -3.2445, -3.5233,  ..., -3.5955, -3.9896, -3.7924],\n",
      "         [-4.2090, -3.8361, -4.1596,  ..., -4.1861, -4.6080, -4.4536],\n",
      "         ...,\n",
      "         [-2.9149, -2.6139, -2.8405,  ..., -3.0460, -3.2139, -3.1900],\n",
      "         [-2.9831, -2.6284, -2.8564,  ..., -3.0792, -3.2402, -3.2508],\n",
      "         [-2.7952, -2.4774, -2.7095,  ..., -2.9133, -3.0668, -3.0817]],\n",
      "\n",
      "        [[-2.1046, -1.7263, -1.9545,  ..., -2.2074, -2.3714, -2.0817],\n",
      "         [-2.8306, -2.4761, -2.6339,  ..., -2.8985, -3.0506, -2.7840],\n",
      "         [-2.7562, -2.3964, -2.5503,  ..., -2.8107, -2.9543, -2.6950],\n",
      "         ...,\n",
      "         [-2.1971, -1.8356, -2.0023,  ..., -2.3088, -2.3486, -2.1684],\n",
      "         [-2.1272, -1.7860, -1.9482,  ..., -2.2151, -2.2926, -2.0856],\n",
      "         [-1.8418, -1.4547, -1.6640,  ..., -1.9770, -1.9930, -1.8990]]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>), tensor([[[ 5.4066e-02],\n",
      "         [ 6.5631e-02],\n",
      "         [ 7.8555e-02],\n",
      "         [ 8.2301e-02],\n",
      "         [ 5.5858e-02],\n",
      "         [ 1.7058e-02],\n",
      "         [ 5.6861e-02],\n",
      "         [ 4.3544e-02],\n",
      "         [ 5.9106e-02],\n",
      "         [ 1.0269e-01],\n",
      "         [ 6.7681e-02],\n",
      "         [ 5.7432e-02],\n",
      "         [ 4.9514e-02],\n",
      "         [ 4.2039e-02],\n",
      "         [ 4.9348e-02],\n",
      "         [ 9.6293e-02],\n",
      "         [ 2.2876e-02],\n",
      "         [ 5.0893e-02],\n",
      "         [ 5.4959e-02],\n",
      "         [ 3.7836e-02],\n",
      "         [ 5.6841e-02],\n",
      "         [ 5.0191e-02],\n",
      "         [ 6.1113e-02],\n",
      "         [ 9.0875e-02]],\n",
      "\n",
      "        [[-6.7664e-02],\n",
      "         [-1.6427e-01],\n",
      "         [-1.6623e-01],\n",
      "         [-1.2173e-01],\n",
      "         [-1.8003e-01],\n",
      "         [-1.6219e-01],\n",
      "         [-1.0723e-02],\n",
      "         [-1.5421e-01],\n",
      "         [-4.9339e-02],\n",
      "         [-3.8281e-02],\n",
      "         [-1.8616e-01],\n",
      "         [ 2.1373e-01],\n",
      "         [-8.6579e-02],\n",
      "         [-9.1772e-02],\n",
      "         [-1.0777e-01],\n",
      "         [-1.2135e-01],\n",
      "         [-8.8904e-02],\n",
      "         [-1.5278e-01],\n",
      "         [-1.2438e-01],\n",
      "         [-1.0036e-01],\n",
      "         [-1.1380e-01],\n",
      "         [-9.2139e-02],\n",
      "         [-8.9316e-02],\n",
      "         [-1.1768e-01]],\n",
      "\n",
      "        [[ 6.5625e-02],\n",
      "         [ 6.0019e-02],\n",
      "         [ 5.6963e-02],\n",
      "         [ 4.7871e-02],\n",
      "         [ 1.7319e-02],\n",
      "         [ 4.6699e-02],\n",
      "         [-1.6525e-01],\n",
      "         [ 6.3119e-02],\n",
      "         [-1.7403e-02],\n",
      "         [ 8.5018e-02],\n",
      "         [ 1.1315e-01],\n",
      "         [ 1.1513e-01],\n",
      "         [ 1.0047e-01],\n",
      "         [ 9.8939e-02],\n",
      "         [ 7.9134e-02],\n",
      "         [ 1.0424e-01],\n",
      "         [ 9.2704e-02],\n",
      "         [ 1.2133e-01],\n",
      "         [ 9.9248e-02],\n",
      "         [ 4.4340e-02],\n",
      "         [ 8.7588e-02],\n",
      "         [ 1.3086e-01],\n",
      "         [ 1.1863e-01],\n",
      "         [ 9.6424e-02]],\n",
      "\n",
      "        [[ 5.2794e-02],\n",
      "         [ 1.0923e-01],\n",
      "         [ 1.1409e-01],\n",
      "         [ 7.6880e-02],\n",
      "         [ 5.6569e-02],\n",
      "         [ 6.6162e-02],\n",
      "         [ 1.1882e-01],\n",
      "         [-7.2202e-02],\n",
      "         [ 9.9407e-02],\n",
      "         [ 1.9248e-01],\n",
      "         [ 1.1154e-01],\n",
      "         [ 1.1839e-01],\n",
      "         [ 1.3504e-01],\n",
      "         [ 1.4178e-01],\n",
      "         [ 1.5760e-01],\n",
      "         [ 1.1420e-01],\n",
      "         [ 1.0585e-01],\n",
      "         [ 1.4212e-01],\n",
      "         [ 1.2363e-01],\n",
      "         [ 7.6701e-02],\n",
      "         [ 1.2803e-01],\n",
      "         [ 1.4405e-01],\n",
      "         [ 1.5990e-01],\n",
      "         [ 1.7584e-01]],\n",
      "\n",
      "        [[-1.7807e-01],\n",
      "         [-2.6471e-01],\n",
      "         [-2.6448e-01],\n",
      "         [-2.6246e-01],\n",
      "         [-1.7450e-01],\n",
      "         [-1.4318e-01],\n",
      "         [-2.0536e-01],\n",
      "         [-2.7054e-01],\n",
      "         [-2.6496e-01],\n",
      "         [ 2.3996e-02],\n",
      "         [-1.9643e-01],\n",
      "         [-1.8517e-01],\n",
      "         [-1.5990e-01],\n",
      "         [-1.4904e-01],\n",
      "         [-1.7138e-01],\n",
      "         [-1.4573e-01],\n",
      "         [-1.5216e-01],\n",
      "         [-1.3528e-01],\n",
      "         [-1.4958e-01],\n",
      "         [-1.6462e-01],\n",
      "         [-1.6598e-01],\n",
      "         [-2.1219e-01],\n",
      "         [-2.1703e-01],\n",
      "         [-1.9016e-01]],\n",
      "\n",
      "        [[-8.1026e-02],\n",
      "         [ 1.5849e-02],\n",
      "         [ 4.3204e-02],\n",
      "         [ 4.3463e-02],\n",
      "         [-9.3584e-03],\n",
      "         [ 5.5187e-03],\n",
      "         [ 3.1684e-02],\n",
      "         [ 3.5463e-02],\n",
      "         [ 3.6369e-02],\n",
      "         [ 1.6242e-02],\n",
      "         [ 2.1057e-01],\n",
      "         [ 6.2618e-02],\n",
      "         [ 4.8180e-02],\n",
      "         [ 1.1223e-01],\n",
      "         [ 8.8505e-02],\n",
      "         [ 9.5567e-02],\n",
      "         [ 6.4552e-02],\n",
      "         [ 3.1516e-02],\n",
      "         [ 1.1724e-01],\n",
      "         [ 7.3821e-02],\n",
      "         [ 4.7713e-02],\n",
      "         [ 6.2399e-02],\n",
      "         [ 7.8784e-02],\n",
      "         [ 7.6747e-02]],\n",
      "\n",
      "        [[-1.1578e-01],\n",
      "         [-1.4448e-01],\n",
      "         [-1.2108e-01],\n",
      "         [-1.1716e-01],\n",
      "         [-1.3413e-01],\n",
      "         [-6.0049e-02],\n",
      "         [-1.0755e-01],\n",
      "         [-1.5272e-01],\n",
      "         [-1.4546e-01],\n",
      "         [-2.6533e-01],\n",
      "         [-1.5269e-01],\n",
      "         [ 1.7279e-01],\n",
      "         [-1.9391e-01],\n",
      "         [-8.6409e-02],\n",
      "         [-1.7555e-01],\n",
      "         [-1.7146e-01],\n",
      "         [-1.5573e-01],\n",
      "         [-1.4953e-01],\n",
      "         [-2.7697e-02],\n",
      "         [-1.7865e-01],\n",
      "         [-1.1629e-01],\n",
      "         [-6.9994e-02],\n",
      "         [-9.2495e-02],\n",
      "         [-1.9928e-01]],\n",
      "\n",
      "        [[ 3.9459e-02],\n",
      "         [-5.4832e-02],\n",
      "         [-6.4811e-02],\n",
      "         [-8.4612e-02],\n",
      "         [-2.3616e-02],\n",
      "         [-5.4199e-02],\n",
      "         [-7.1516e-02],\n",
      "         [-4.1795e-02],\n",
      "         [-6.5328e-02],\n",
      "         [ 2.9066e-01],\n",
      "         [ 1.4585e-01],\n",
      "         [ 1.6468e-01],\n",
      "         [ 1.3082e-01],\n",
      "         [ 1.3881e-01],\n",
      "         [ 1.1905e-01],\n",
      "         [ 1.1631e-01],\n",
      "         [ 1.1235e-01],\n",
      "         [ 9.4683e-02],\n",
      "         [ 1.6876e-01],\n",
      "         [ 1.5931e-01],\n",
      "         [ 1.6417e-01],\n",
      "         [ 1.6234e-01],\n",
      "         [ 1.1294e-01],\n",
      "         [ 1.8581e-01]],\n",
      "\n",
      "        [[-6.7158e-02],\n",
      "         [-6.1223e-02],\n",
      "         [-8.2407e-02],\n",
      "         [-6.6869e-02],\n",
      "         [-5.5211e-02],\n",
      "         [ 1.2791e-02],\n",
      "         [-6.7059e-02],\n",
      "         [ 1.9043e-01],\n",
      "         [ 1.2470e-01],\n",
      "         [ 1.0622e-01],\n",
      "         [ 1.1262e-01],\n",
      "         [ 1.1784e-01],\n",
      "         [ 1.2425e-01],\n",
      "         [ 1.4761e-01],\n",
      "         [ 1.1366e-01],\n",
      "         [ 1.2769e-01],\n",
      "         [ 1.8647e-01],\n",
      "         [ 1.6956e-01],\n",
      "         [ 1.0577e-01],\n",
      "         [ 1.8000e-01],\n",
      "         [ 1.7869e-01],\n",
      "         [ 1.5395e-01],\n",
      "         [ 1.2786e-01],\n",
      "         [ 1.0609e-01]],\n",
      "\n",
      "        [[-8.6342e-02],\n",
      "         [-1.2166e-01],\n",
      "         [-2.7074e-01],\n",
      "         [-1.4543e-01],\n",
      "         [-1.5476e-01],\n",
      "         [-1.1159e-01],\n",
      "         [-8.4526e-02],\n",
      "         [-2.3460e-02],\n",
      "         [-5.5933e-02],\n",
      "         [-3.3472e-02],\n",
      "         [-1.7022e-03],\n",
      "         [-6.1379e-02],\n",
      "         [-4.8252e-02],\n",
      "         [-3.3536e-02],\n",
      "         [-4.7247e-02],\n",
      "         [ 6.0844e-02],\n",
      "         [ 3.9172e-02],\n",
      "         [-1.0941e-01],\n",
      "         [ 3.3746e-02],\n",
      "         [ 4.2120e-02],\n",
      "         [ 7.4103e-02],\n",
      "         [ 6.7480e-02],\n",
      "         [-3.9778e-02],\n",
      "         [ 4.6653e-02]],\n",
      "\n",
      "        [[ 1.1761e-04],\n",
      "         [-3.2319e-02],\n",
      "         [-8.2931e-02],\n",
      "         [-6.2712e-02],\n",
      "         [-5.5349e-02],\n",
      "         [-1.6789e-01],\n",
      "         [-5.7528e-02],\n",
      "         [-3.3631e-02],\n",
      "         [-8.9793e-02],\n",
      "         [-4.4528e-02],\n",
      "         [ 1.9845e-01],\n",
      "         [ 4.1326e-02],\n",
      "         [ 6.2142e-02],\n",
      "         [ 5.2120e-02],\n",
      "         [ 4.5284e-02],\n",
      "         [ 5.3875e-03],\n",
      "         [ 2.3621e-02],\n",
      "         [ 4.3163e-02],\n",
      "         [ 2.7918e-02],\n",
      "         [-2.7312e-03],\n",
      "         [ 2.5573e-02],\n",
      "         [ 2.2228e-02],\n",
      "         [ 2.3738e-02],\n",
      "         [ 4.5626e-02]],\n",
      "\n",
      "        [[ 1.1152e-01],\n",
      "         [ 1.1857e-01],\n",
      "         [ 1.2849e-01],\n",
      "         [ 1.0917e-01],\n",
      "         [ 9.5948e-02],\n",
      "         [ 5.3384e-02],\n",
      "         [ 1.0204e-03],\n",
      "         [ 1.0989e-01],\n",
      "         [ 6.0001e-02],\n",
      "         [ 1.5550e-01],\n",
      "         [ 1.5263e-01],\n",
      "         [ 1.9080e-01],\n",
      "         [ 1.5649e-01],\n",
      "         [ 1.7876e-01],\n",
      "         [ 1.4794e-01],\n",
      "         [ 1.8362e-01],\n",
      "         [ 3.1785e-01],\n",
      "         [ 1.4816e-01],\n",
      "         [ 1.9398e-01],\n",
      "         [ 2.9620e-01],\n",
      "         [ 1.6768e-01],\n",
      "         [ 2.6444e-01],\n",
      "         [ 1.7876e-01],\n",
      "         [ 1.6529e-01]],\n",
      "\n",
      "        [[-3.2135e-01],\n",
      "         [-2.7609e-01],\n",
      "         [-2.2708e-01],\n",
      "         [-2.7871e-01],\n",
      "         [-1.5976e-01],\n",
      "         [-1.0789e-01],\n",
      "         [-2.6115e-01],\n",
      "         [ 2.4042e-01],\n",
      "         [ 1.7649e-01],\n",
      "         [ 1.0470e-01],\n",
      "         [ 7.6834e-02],\n",
      "         [ 1.1821e-01],\n",
      "         [ 9.2225e-02],\n",
      "         [ 1.8485e-01],\n",
      "         [ 1.6472e-01],\n",
      "         [ 1.1662e-01],\n",
      "         [ 1.3644e-01],\n",
      "         [ 1.0456e-01],\n",
      "         [ 1.4690e-01],\n",
      "         [ 1.0390e-01],\n",
      "         [ 1.6453e-01],\n",
      "         [ 1.6165e-01],\n",
      "         [ 1.5546e-01],\n",
      "         [ 1.7893e-01]],\n",
      "\n",
      "        [[ 2.2485e-01],\n",
      "         [ 1.5733e-01],\n",
      "         [ 1.8498e-01],\n",
      "         [ 1.1078e-01],\n",
      "         [ 2.0727e-01],\n",
      "         [ 1.8171e-01],\n",
      "         [ 4.9812e-02],\n",
      "         [ 1.6734e-02],\n",
      "         [ 1.8851e-01],\n",
      "         [ 2.8564e-01],\n",
      "         [ 2.0382e-01],\n",
      "         [ 1.7996e-01],\n",
      "         [ 1.8341e-01],\n",
      "         [ 1.6929e-01],\n",
      "         [ 1.5521e-01],\n",
      "         [ 1.3484e-01],\n",
      "         [ 1.5028e-01],\n",
      "         [ 1.4007e-01],\n",
      "         [ 9.8987e-02],\n",
      "         [ 1.9394e-01],\n",
      "         [ 2.3100e-01],\n",
      "         [ 2.1777e-01],\n",
      "         [ 1.4207e-01],\n",
      "         [ 3.0390e-01]],\n",
      "\n",
      "        [[-2.8275e-01],\n",
      "         [-1.7993e-01],\n",
      "         [-1.3902e-01],\n",
      "         [-1.6490e-01],\n",
      "         [-1.0496e-01],\n",
      "         [-2.0422e-01],\n",
      "         [-1.8531e-01],\n",
      "         [-1.7398e-01],\n",
      "         [-2.2590e-01],\n",
      "         [-1.9143e-01],\n",
      "         [ 3.7845e-01],\n",
      "         [-1.4968e-01],\n",
      "         [-1.7335e-01],\n",
      "         [-2.0042e-01],\n",
      "         [-1.4693e-01],\n",
      "         [-1.1373e-01],\n",
      "         [-4.5550e-02],\n",
      "         [-1.5862e-01],\n",
      "         [-1.9468e-01],\n",
      "         [-9.1910e-02],\n",
      "         [-2.0067e-01],\n",
      "         [-1.8242e-01],\n",
      "         [-2.3379e-01],\n",
      "         [-2.4639e-01]],\n",
      "\n",
      "        [[ 3.5746e-02],\n",
      "         [ 1.1198e-01],\n",
      "         [ 1.5230e-01],\n",
      "         [ 2.2968e-01],\n",
      "         [ 1.2334e-01],\n",
      "         [ 7.9760e-02],\n",
      "         [ 2.4281e-02],\n",
      "         [-1.0909e-02],\n",
      "         [ 1.1329e-01],\n",
      "         [ 2.1473e-01],\n",
      "         [ 1.6258e-01],\n",
      "         [ 1.7210e-01],\n",
      "         [ 1.3568e-01],\n",
      "         [ 9.7467e-02],\n",
      "         [ 8.7748e-02],\n",
      "         [ 1.7078e-01],\n",
      "         [ 1.8598e-01],\n",
      "         [ 8.9025e-02],\n",
      "         [ 1.1402e-01],\n",
      "         [ 1.6093e-01],\n",
      "         [ 2.7516e-01],\n",
      "         [ 1.6528e-01],\n",
      "         [ 1.5849e-01],\n",
      "         [ 1.4951e-01]],\n",
      "\n",
      "        [[-6.7726e-02],\n",
      "         [-2.6111e-02],\n",
      "         [-3.7656e-02],\n",
      "         [-3.9180e-02],\n",
      "         [-2.5971e-02],\n",
      "         [-1.4467e-01],\n",
      "         [-1.0697e-02],\n",
      "         [-1.7789e-02],\n",
      "         [-8.8801e-02],\n",
      "         [-1.5108e-01],\n",
      "         [-3.3329e-02],\n",
      "         [ 2.3654e-01],\n",
      "         [ 2.0878e-02],\n",
      "         [ 2.2508e-02],\n",
      "         [ 2.8622e-02],\n",
      "         [-1.1708e-02],\n",
      "         [-4.0135e-02],\n",
      "         [ 2.9418e-02],\n",
      "         [-9.4731e-03],\n",
      "         [-2.9228e-03],\n",
      "         [-2.7782e-02],\n",
      "         [ 2.2871e-02],\n",
      "         [ 1.7818e-02],\n",
      "         [ 2.9181e-02]],\n",
      "\n",
      "        [[ 4.7783e-02],\n",
      "         [ 8.7086e-02],\n",
      "         [ 7.9555e-02],\n",
      "         [ 6.4638e-02],\n",
      "         [ 1.0188e-02],\n",
      "         [-7.4722e-03],\n",
      "         [ 7.2756e-02],\n",
      "         [ 7.3916e-02],\n",
      "         [ 7.0337e-02],\n",
      "         [ 1.6638e-01],\n",
      "         [ 9.5175e-02],\n",
      "         [ 8.1817e-02],\n",
      "         [ 1.5183e-01],\n",
      "         [ 7.3419e-02],\n",
      "         [ 1.0479e-01],\n",
      "         [ 8.2887e-02],\n",
      "         [ 6.3357e-02],\n",
      "         [ 1.0268e-01],\n",
      "         [ 1.0171e-01],\n",
      "         [ 7.6174e-02],\n",
      "         [ 8.9681e-02],\n",
      "         [ 9.0263e-02],\n",
      "         [ 7.2253e-02],\n",
      "         [ 4.0903e-02]],\n",
      "\n",
      "        [[-1.8114e-02],\n",
      "         [-3.1521e-02],\n",
      "         [-3.0011e-02],\n",
      "         [-3.3700e-02],\n",
      "         [-3.9190e-02],\n",
      "         [-7.1181e-02],\n",
      "         [-1.3108e-01],\n",
      "         [-2.4210e-02],\n",
      "         [-3.9979e-02],\n",
      "         [-5.0791e-02],\n",
      "         [-7.0238e-03],\n",
      "         [-4.6672e-02],\n",
      "         [ 3.8189e-01],\n",
      "         [-3.8349e-02],\n",
      "         [-8.6204e-02],\n",
      "         [-3.9688e-02],\n",
      "         [ 1.9305e-02],\n",
      "         [-6.7339e-02],\n",
      "         [-3.3100e-02],\n",
      "         [ 5.0904e-03],\n",
      "         [-1.5047e-02],\n",
      "         [-4.9961e-04],\n",
      "         [-1.9295e-02],\n",
      "         [-1.3981e-02]],\n",
      "\n",
      "        [[ 1.4099e-02],\n",
      "         [ 6.8466e-02],\n",
      "         [ 7.5729e-02],\n",
      "         [ 6.5672e-02],\n",
      "         [ 5.7519e-02],\n",
      "         [ 1.3579e-03],\n",
      "         [ 9.5770e-04],\n",
      "         [ 1.6213e-02],\n",
      "         [ 1.4458e-02],\n",
      "         [ 9.2938e-04],\n",
      "         [ 7.3183e-04],\n",
      "         [ 2.2929e-02],\n",
      "         [ 1.6425e-01],\n",
      "         [ 1.3149e-01],\n",
      "         [ 1.3060e-01],\n",
      "         [ 1.2997e-01],\n",
      "         [ 1.4727e-01],\n",
      "         [ 1.5043e-01],\n",
      "         [ 1.4297e-01],\n",
      "         [ 1.5185e-01],\n",
      "         [ 1.2384e-01],\n",
      "         [ 1.8071e-01],\n",
      "         [ 9.4006e-02],\n",
      "         [ 1.1730e-01]],\n",
      "\n",
      "        [[-2.9610e-01],\n",
      "         [-2.3449e-01],\n",
      "         [-2.2987e-01],\n",
      "         [-2.7641e-01],\n",
      "         [-2.4688e-01],\n",
      "         [-3.2661e-01],\n",
      "         [-2.6682e-01],\n",
      "         [-2.5042e-01],\n",
      "         [-3.3929e-01],\n",
      "         [-4.5027e-01],\n",
      "         [-2.1687e-01],\n",
      "         [-2.9021e-01],\n",
      "         [-2.4233e-01],\n",
      "         [ 2.8537e-01],\n",
      "         [-2.8036e-01],\n",
      "         [-2.9515e-01],\n",
      "         [-3.0914e-01],\n",
      "         [-3.1012e-01],\n",
      "         [-3.1859e-01],\n",
      "         [-3.0750e-01],\n",
      "         [-3.0444e-01],\n",
      "         [-2.5483e-01],\n",
      "         [-2.9749e-01],\n",
      "         [-2.7640e-01]],\n",
      "\n",
      "        [[-5.2741e-01],\n",
      "         [-4.1537e-01],\n",
      "         [-3.7248e-01],\n",
      "         [-3.3458e-01],\n",
      "         [-2.7509e-01],\n",
      "         [-3.5539e-01],\n",
      "         [-4.7727e-01],\n",
      "         [-7.2280e-01],\n",
      "         [-6.3663e-01],\n",
      "         [-6.8911e-01],\n",
      "         [-5.5427e-01],\n",
      "         [-3.6727e-01],\n",
      "         [ 1.5880e-01],\n",
      "         [-5.3511e-01],\n",
      "         [-5.0268e-01],\n",
      "         [-5.0363e-01],\n",
      "         [-3.7419e-01],\n",
      "         [-3.0913e-01],\n",
      "         [-5.0107e-01],\n",
      "         [-3.5062e-01],\n",
      "         [-5.1421e-01],\n",
      "         [-5.7398e-01],\n",
      "         [-7.1038e-01],\n",
      "         [-5.1138e-01]],\n",
      "\n",
      "        [[-4.6731e-01],\n",
      "         [-4.7546e-01],\n",
      "         [-4.7340e-01],\n",
      "         [-5.3868e-01],\n",
      "         [-4.6113e-01],\n",
      "         [-4.7867e-01],\n",
      "         [-5.9746e-01],\n",
      "         [-5.4122e-01],\n",
      "         [-5.6321e-01],\n",
      "         [-4.7033e-01],\n",
      "         [-4.6819e-01],\n",
      "         [ 7.6297e-02],\n",
      "         [-4.5826e-01],\n",
      "         [-4.3651e-01],\n",
      "         [-4.4497e-01],\n",
      "         [-4.8697e-01],\n",
      "         [-4.5469e-01],\n",
      "         [-4.2812e-01],\n",
      "         [-4.5190e-01],\n",
      "         [-4.4646e-01],\n",
      "         [-4.7458e-01],\n",
      "         [-4.2964e-01],\n",
      "         [-4.4461e-01],\n",
      "         [-4.3520e-01]],\n",
      "\n",
      "        [[ 2.3901e-02],\n",
      "         [-8.3929e-02],\n",
      "         [-5.9767e-02],\n",
      "         [-7.8982e-02],\n",
      "         [-9.1446e-02],\n",
      "         [-7.5392e-02],\n",
      "         [-8.0575e-02],\n",
      "         [-1.6147e-01],\n",
      "         [-1.3367e-01],\n",
      "         [-1.0356e-01],\n",
      "         [ 2.7246e-01],\n",
      "         [-6.2741e-02],\n",
      "         [-8.1526e-02],\n",
      "         [-8.0032e-02],\n",
      "         [-1.0672e-01],\n",
      "         [-1.1291e-01],\n",
      "         [-1.1773e-01],\n",
      "         [-1.0829e-01],\n",
      "         [-9.8497e-02],\n",
      "         [-8.1571e-02],\n",
      "         [-8.9528e-02],\n",
      "         [-5.8892e-02],\n",
      "         [-6.5702e-02],\n",
      "         [-6.0051e-02]],\n",
      "\n",
      "        [[ 4.3231e-01],\n",
      "         [ 3.1132e-01],\n",
      "         [ 3.0673e-01],\n",
      "         [ 3.0883e-01],\n",
      "         [ 3.2686e-01],\n",
      "         [ 4.0427e-01],\n",
      "         [ 2.9928e-01],\n",
      "         [ 2.4772e-01],\n",
      "         [ 2.8525e-01],\n",
      "         [ 2.3264e-01],\n",
      "         [ 3.2084e-01],\n",
      "         [ 4.6697e-01],\n",
      "         [ 3.0005e-01],\n",
      "         [ 3.2966e-01],\n",
      "         [ 3.1251e-01],\n",
      "         [ 2.9748e-01],\n",
      "         [ 2.9741e-01],\n",
      "         [ 3.1698e-01],\n",
      "         [ 3.3682e-01],\n",
      "         [ 3.0614e-01],\n",
      "         [ 2.9851e-01],\n",
      "         [ 3.3857e-01],\n",
      "         [ 3.3640e-01],\n",
      "         [ 3.2906e-01]],\n",
      "\n",
      "        [[ 3.7814e-01],\n",
      "         [ 2.7629e-01],\n",
      "         [ 2.7702e-01],\n",
      "         [ 2.7938e-01],\n",
      "         [ 3.0291e-01],\n",
      "         [ 4.2052e-01],\n",
      "         [ 3.9039e-01],\n",
      "         [ 2.7374e-01],\n",
      "         [ 2.7679e-01],\n",
      "         [ 2.8592e-01],\n",
      "         [ 3.5162e-01],\n",
      "         [ 3.4790e-01],\n",
      "         [ 3.0891e-01],\n",
      "         [ 3.0513e-01],\n",
      "         [ 3.5150e-01],\n",
      "         [ 3.5958e-01],\n",
      "         [ 4.0797e-01],\n",
      "         [ 3.0780e-01],\n",
      "         [ 3.3473e-01],\n",
      "         [ 4.5103e-01],\n",
      "         [ 3.3080e-01],\n",
      "         [ 3.7032e-01],\n",
      "         [ 3.1657e-01],\n",
      "         [ 3.1476e-01]],\n",
      "\n",
      "        [[ 2.6813e-01],\n",
      "         [ 2.0210e-01],\n",
      "         [ 2.1139e-01],\n",
      "         [ 1.7551e-01],\n",
      "         [ 1.8097e-01],\n",
      "         [ 1.8400e-01],\n",
      "         [ 1.7217e-01],\n",
      "         [ 1.8994e-01],\n",
      "         [ 4.3222e-01],\n",
      "         [ 2.5479e-01],\n",
      "         [ 2.0056e-01],\n",
      "         [ 2.4933e-01],\n",
      "         [ 2.1955e-01],\n",
      "         [ 2.4208e-01],\n",
      "         [ 1.8911e-01],\n",
      "         [ 1.9604e-01],\n",
      "         [ 1.7348e-01],\n",
      "         [ 2.9323e-01],\n",
      "         [ 2.9433e-01],\n",
      "         [ 2.2136e-01],\n",
      "         [ 3.0027e-01],\n",
      "         [ 3.0404e-01],\n",
      "         [ 3.4177e-01],\n",
      "         [ 3.1198e-01]],\n",
      "\n",
      "        [[ 3.2656e-01],\n",
      "         [ 2.8771e-01],\n",
      "         [ 2.9052e-01],\n",
      "         [ 2.7728e-01],\n",
      "         [ 4.5873e-01],\n",
      "         [ 2.4484e-01],\n",
      "         [ 2.7377e-01],\n",
      "         [ 4.9087e-01],\n",
      "         [ 3.1983e-01],\n",
      "         [ 2.7421e-01],\n",
      "         [ 2.1840e-01],\n",
      "         [ 3.6485e-01],\n",
      "         [ 5.9517e-01],\n",
      "         [ 4.3731e-01],\n",
      "         [ 5.3635e-01],\n",
      "         [ 4.7069e-01],\n",
      "         [ 4.1696e-01],\n",
      "         [ 6.4639e-01],\n",
      "         [ 4.2241e-01],\n",
      "         [ 3.5925e-01],\n",
      "         [ 3.2833e-01],\n",
      "         [ 3.7496e-01],\n",
      "         [ 3.5311e-01],\n",
      "         [ 3.7080e-01]],\n",
      "\n",
      "        [[ 8.1766e-02],\n",
      "         [-9.9239e-02],\n",
      "         [-1.4638e-01],\n",
      "         [-1.2569e-01],\n",
      "         [-3.8941e-02],\n",
      "         [-2.0013e-01],\n",
      "         [-1.3408e-01],\n",
      "         [-5.5633e-02],\n",
      "         [-7.6402e-02],\n",
      "         [-1.7483e-02],\n",
      "         [-7.9198e-02],\n",
      "         [-5.4625e-02],\n",
      "         [ 1.6237e-01],\n",
      "         [-1.0378e-01],\n",
      "         [-1.0815e-01],\n",
      "         [-9.4098e-02],\n",
      "         [-1.6403e-01],\n",
      "         [-1.1638e-01],\n",
      "         [-1.1846e-01],\n",
      "         [-1.6589e-01],\n",
      "         [-1.4727e-01],\n",
      "         [-1.1786e-01],\n",
      "         [-1.2803e-01],\n",
      "         [-9.5555e-02]],\n",
      "\n",
      "        [[ 6.6414e-01],\n",
      "         [ 6.5246e-01],\n",
      "         [ 6.4179e-01],\n",
      "         [ 5.2887e-01],\n",
      "         [ 6.3609e-01],\n",
      "         [ 6.3148e-01],\n",
      "         [ 5.5823e-01],\n",
      "         [ 6.4409e-01],\n",
      "         [ 8.3820e-02],\n",
      "         [ 5.5487e-01],\n",
      "         [ 5.5256e-01],\n",
      "         [ 5.9509e-01],\n",
      "         [ 5.1239e-01],\n",
      "         [ 5.3664e-01],\n",
      "         [ 5.0079e-01],\n",
      "         [ 5.6930e-01],\n",
      "         [ 5.5542e-01],\n",
      "         [ 5.2900e-01],\n",
      "         [ 5.4712e-01],\n",
      "         [ 5.9712e-01],\n",
      "         [ 5.5663e-01],\n",
      "         [ 6.3237e-01],\n",
      "         [ 6.4783e-01],\n",
      "         [ 5.5444e-01]]], device='cuda:0', grad_fn=<AddBackward0>), ([], [], []))\n",
      ":List trace inputs must have elements (toTypeInferredIValue at /opt/conda/conda-bld/pytorch_1579027003190/work/torch/csrc/jit/pybind_utils.h:293)\n",
      "frame #0: c10::Error::Error(c10::SourceLocation, std::string const&) + 0x47 (0x7eff980b3627 in /home/aloui/miniconda3/envs/vilbert-mt/lib/python3.6/site-packages/torch/lib/libc10.so)\n",
      "frame #1: <unknown function> + 0x6e4c9f (0x7eff8c4efc9f in /home/aloui/miniconda3/envs/vilbert-mt/lib/python3.6/site-packages/torch/lib/libtorch_python.so)\n",
      "frame #2: <unknown function> + 0x769f4b (0x7eff8c574f4b in /home/aloui/miniconda3/envs/vilbert-mt/lib/python3.6/site-packages/torch/lib/libtorch_python.so)\n",
      "frame #3: torch::jit::tracer::trace(std::vector<c10::IValue, std::allocator<c10::IValue> >, std::function<std::vector<c10::IValue, std::allocator<c10::IValue> > (std::vector<c10::IValue, std::allocator<c10::IValue> >)> const&, std::function<std::string (at::Tensor const&)>, bool, torch::jit::script::Module*) + 0x4e6 (0x7eff60d96e26 in /home/aloui/miniconda3/envs/vilbert-mt/lib/python3.6/site-packages/torch/lib/libtorch.so)\n",
      "frame #4: <unknown function> + 0x7660e1 (0x7eff8c5710e1 in /home/aloui/miniconda3/envs/vilbert-mt/lib/python3.6/site-packages/torch/lib/libtorch_python.so)\n",
      "frame #5: <unknown function> + 0x77ffb1 (0x7eff8c58afb1 in /home/aloui/miniconda3/envs/vilbert-mt/lib/python3.6/site-packages/torch/lib/libtorch_python.so)\n",
      "frame #6: <unknown function> + 0x28c076 (0x7eff8c097076 in /home/aloui/miniconda3/envs/vilbert-mt/lib/python3.6/site-packages/torch/lib/libtorch_python.so)\n",
      "frame #7: _PyCFunction_FastCallDict + 0x154 (0x55cc9ec18304 in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\n",
      "frame #8: <unknown function> + 0x199c5e (0x55cc9ec9fc5e in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\n",
      "frame #9: _PyEval_EvalFrameDefault + 0x30a (0x55cc9ecc281a in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\n",
      "frame #10: <unknown function> + 0x19335e (0x55cc9ec9935e in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\n",
      "frame #11: <unknown function> + 0x193f31 (0x55cc9ec99f31 in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\n",
      "frame #12: <unknown function> + 0x199be5 (0x55cc9ec9fbe5 in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\n",
      "frame #13: _PyEval_EvalFrameDefault + 0x30a (0x55cc9ecc281a in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\n",
      "frame #14: <unknown function> + 0x192f26 (0x55cc9ec98f26 in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\n",
      "frame #15: <unknown function> + 0x193f31 (0x55cc9ec99f31 in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\n",
      "frame #16: <unknown function> + 0x199be5 (0x55cc9ec9fbe5 in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\n",
      "frame #17: _PyEval_EvalFrameDefault + 0x30a (0x55cc9ecc281a in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\n",
      "frame #18: <unknown function> + 0x192f26 (0x55cc9ec98f26 in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\n",
      "frame #19: <unknown function> + 0x193f31 (0x55cc9ec99f31 in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\n",
      "frame #20: <unknown function> + 0x199be5 (0x55cc9ec9fbe5 in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\n",
      "frame #21: _PyEval_EvalFrameDefault + 0x30a (0x55cc9ecc281a in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\n",
      "frame #22: <unknown function> + 0x192f26 (0x55cc9ec98f26 in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\n",
      "frame #23: <unknown function> + 0x193f31 (0x55cc9ec99f31 in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\n",
      "frame #24: <unknown function> + 0x199be5 (0x55cc9ec9fbe5 in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\n",
      "frame #25: _PyEval_EvalFrameDefault + 0x10c9 (0x55cc9ecc35d9 in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\n",
      "frame #26: PyEval_EvalCodeEx + 0x329 (0x55cc9ec9aa49 in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\n",
      "frame #27: PyEval_EvalCode + 0x1c (0x55cc9ec9b7ec in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\n",
      "frame #28: <unknown function> + 0x1ba227 (0x55cc9ecc0227 in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\n",
      "frame #29: _PyCFunction_FastCallDict + 0x91 (0x55cc9ec18241 in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\n",
      "frame #30: <unknown function> + 0x199b0c (0x55cc9ec9fb0c in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\n",
      "frame #31: _PyEval_EvalFrameDefault + 0x30a (0x55cc9ecc281a in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\n",
      "frame #32: _PyGen_Send + 0x256 (0x55cc9eca2bc6 in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\n",
      "frame #33: _PyEval_EvalFrameDefault + 0x1445 (0x55cc9ecc3955 in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\n",
      "frame #34: _PyGen_Send + 0x256 (0x55cc9eca2bc6 in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\n",
      "frame #35: _PyEval_EvalFrameDefault + 0x1445 (0x55cc9ecc3955 in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\n",
      "frame #36: _PyGen_Send + 0x256 (0x55cc9eca2bc6 in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\n",
      "frame #37: _PyCFunction_FastCallDict + 0x115 (0x55cc9ec182c5 in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\n",
      "frame #38: <unknown function> + 0x199b0c (0x55cc9ec9fb0c in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\n",
      "frame #39: _PyEval_EvalFrameDefault + 0x30a (0x55cc9ecc281a in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\n",
      "frame #40: <unknown function> + 0x193cfb (0x55cc9ec99cfb in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\n",
      "frame #41: <unknown function> + 0x199be5 (0x55cc9ec9fbe5 in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\n",
      "frame #42: _PyEval_EvalFrameDefault + 0x30a (0x55cc9ecc281a in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\n",
      "frame #43: <unknown function> + 0x193cfb (0x55cc9ec99cfb in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\n",
      "frame #44: <unknown function> + 0x199be5 (0x55cc9ec9fbe5 in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\n",
      "frame #45: _PyEval_EvalFrameDefault + 0x30a (0x55cc9ecc281a in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\n",
      "frame #46: <unknown function> + 0x192f26 (0x55cc9ec98f26 in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\n",
      "frame #47: _PyFunction_FastCallDict + 0x3d8 (0x55cc9ec9a628 in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\n",
      "frame #48: _PyObject_FastCallDict + 0x26f (0x55cc9ec186cf in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\n",
      "frame #49: _PyObject_Call_Prepend + 0x63 (0x55cc9ec1d143 in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\n",
      "frame #50: PyObject_Call + 0x3e (0x55cc9ec1810e in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\n",
      "frame #51: _PyEval_EvalFrameDefault + 0x1aaf (0x55cc9ecc3fbf in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\n",
      "frame #52: <unknown function> + 0x1931f6 (0x55cc9ec991f6 in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\n",
      "frame #53: <unknown function> + 0x193f31 (0x55cc9ec99f31 in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\n",
      "frame #54: <unknown function> + 0x199be5 (0x55cc9ec9fbe5 in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\n",
      "frame #55: _PyEval_EvalFrameDefault + 0x10c9 (0x55cc9ecc35d9 in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\n",
      "frame #56: <unknown function> + 0x19c744 (0x55cc9eca2744 in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\n",
      "frame #57: _PyCFunction_FastCallDict + 0x91 (0x55cc9ec18241 in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\n",
      "frame #58: <unknown function> + 0x199b0c (0x55cc9ec9fb0c in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\n",
      "frame #59: _PyEval_EvalFrameDefault + 0x30a (0x55cc9ecc281a in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\n",
      "frame #60: <unknown function> + 0x1931f6 (0x55cc9ec991f6 in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\n",
      "frame #61: <unknown function> + 0x193f31 (0x55cc9ec99f31 in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\n",
      "frame #62: <unknown function> + 0x199be5 (0x55cc9ec9fbe5 in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\n",
      "frame #63: _PyEval_EvalFrameDefault + 0x30a (0x55cc9ecc281a in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\n",
      "\n",
      "Error occurs, No graph saved\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Tracer cannot infer type of (tensor([[-23.9768, -17.3129, -18.0523,  ..., -18.6565, -18.3060, -14.8244],\n        [-26.2138, -18.8952, -17.7499,  ..., -17.4112, -15.3365, -17.8206],\n        [-24.8113, -16.7020, -11.6527,  ..., -15.2050, -14.3076, -10.0045],\n        ...,\n        [-27.0051, -15.3371, -20.5083,  ..., -19.9755, -16.9174, -17.5259],\n        [-21.7966, -14.3504, -19.0064,  ..., -13.6335, -11.8910, -26.7599],\n        [-23.3009, -11.6584, -19.6952,  ..., -18.6055, -13.8711, -18.0167]],\n       device='cuda:0', grad_fn=<AddmmBackward>), tensor([[-11.6474, -10.8408,  -8.1201,  ..., -13.7666, -13.3638, -14.8178],\n        [-14.1130,  -8.2416, -11.8985,  ..., -15.3526, -14.5676, -16.1072],\n        [-10.0281,  -8.5481, -12.1849,  ...,  -9.9922, -13.6915, -11.6269],\n        ...,\n        [-20.1335, -18.3920, -17.5234,  ..., -20.9741, -23.5247, -22.5615],\n        [ -6.5798,  -8.0710,  -7.1975,  ...,  -9.0155,  -8.8422, -10.2870],\n        [-18.6119, -14.4927, -17.6004,  ..., -18.2182, -18.8035, -19.1235]],\n       device='cuda:0', grad_fn=<AddmmBackward>), tensor([[-0.6393],\n        [-0.1429],\n        [-2.1546],\n        [-5.1147],\n        [-1.6715],\n        [ 0.3507],\n        [-4.3397],\n        [ 2.2866],\n        [-1.4691],\n        [ 1.4585],\n        [-0.2973],\n        [ 0.7474],\n        [ 2.5556],\n        [-2.9994],\n        [-0.9246],\n        [-1.2214],\n        [ 0.3344],\n        [ 2.2141],\n        [-0.7545],\n        [ 2.4200],\n        [-0.0531],\n        [ 3.1947],\n        [-0.2689],\n        [ 0.4529],\n        [-0.3984],\n        [-0.2024],\n        [ 1.1264],\n        [ 1.3671],\n        [-3.4349],\n        [-0.3805]], device='cuda:0', grad_fn=<AddmmBackward>), tensor([[ -1.8382,   2.1890],\n        [  9.7137,  -9.1303],\n        [  1.1245,  -0.7504],\n        [ -8.7560,   9.4857],\n        [-12.7439,  12.7932],\n        [-12.3451,  12.5709],\n        [ -1.1877,   0.6844],\n        [ -4.0932,   4.0128],\n        [ -4.8093,   5.3705],\n        [ -3.7177,   3.9173],\n        [-12.6056,  12.4244],\n        [ 10.6988, -10.2227],\n        [  2.8526,  -2.8399],\n        [ -7.0294,   7.1356],\n        [-10.3483,   9.9678]], device='cuda:0', grad_fn=<AddmmBackward>), tensor([[-1.3022, -1.1211, -3.1991],\n        [-0.0492, -0.8463, -3.6581],\n        [-0.1244, -1.9052, -2.7197],\n        [-1.2288,  0.7291, -5.5015],\n        [-0.3299, -2.6304, -0.9506],\n        [-1.6865, -1.4229, -2.1603],\n        [ 0.4084, -1.3018, -4.3268],\n        [-3.0534, -1.7261,  0.4608],\n        [ 0.6957, -1.7683, -3.7300],\n        [-2.5832, -0.6753, -0.2382],\n        [-0.4761, -1.3521, -2.6981],\n        [-2.4724, -0.0574, -2.8649],\n        [-3.2873,  0.2401, -0.6161],\n        [ 2.8250, -3.0116, -5.6009],\n        [ 0.4068,  0.0392, -5.6889],\n        [ 0.2833, -1.2190, -3.7594],\n        [-1.5270, -1.1284, -2.1290],\n        [-2.2854, -2.1912,  0.3826],\n        [-0.8855, -0.2406, -2.5146],\n        [-2.2929, -1.9686,  0.3879],\n        [-0.9590, -0.1366, -3.1811],\n        [-3.6603, -1.3946,  1.0387],\n        [-2.8627,  0.4189, -2.4454],\n        [-0.9705, -0.0349, -1.1119],\n        [-1.2466, -2.2507, -3.0363],\n        [-0.8483, -2.6603, -3.1504],\n        [-2.7211, -2.8056, -0.4124],\n        [-0.7093, -1.7536, -2.3936],\n        [-1.6274,  0.5352, -3.8358],\n        [-2.8041, -0.9302, -1.3755]], device='cuda:0', grad_fn=<AddmmBackward>), tensor([[[  8.1071,  -5.0885,  -3.7664,  ...,  -1.4273,  -0.9021,  -4.1969],\n         [  3.8177,  -4.5532,  -2.8071,  ...,  -1.3409,  -1.7692,  -2.2690],\n         [  7.0173,  -5.5335,  -4.4290,  ...,  -1.3300,   0.1980,  -3.6034],\n         ...,\n         [  7.1785,  -6.1633,  -3.6649,  ...,  -1.6600,  -1.7262,  -5.0354],\n         [  6.9941,  -5.3046,  -2.6913,  ...,  -3.1742,  -2.2862,  -3.5778],\n         [  7.5086,  -5.9734,  -2.9408,  ...,  -3.7117,  -2.2481,  -3.2648]],\n\n        [[  7.4254,  -6.7579,  -4.9328,  ...,  -3.9803,  -2.2647,  -2.4394],\n         [  7.2897,  -5.9018,  -5.5442,  ...,  -1.9450,  -1.7594,  -4.7357],\n         [  5.6920,  -5.7744,  -4.4779,  ...,  -3.6136,  -1.5126,  -1.5384],\n         ...,\n         [  6.6963,  -6.7992,  -6.3011,  ...,  -3.5846,  -2.3700,  -3.7784],\n         [  7.2653,  -5.9123,  -5.5892,  ...,  -1.9841,  -1.7899,  -4.7843],\n         [  7.7138,  -5.0347,  -4.6088,  ...,  -3.1614,  -3.4179,  -4.0131]],\n\n        [[  5.2152,  -8.8324,  -3.6273,  ...,  -6.6085,  -4.7241,  -6.8234],\n         [  4.8676,  -4.3746,  -2.4917,  ...,  -3.3825,  -0.8355,  -2.7390],\n         [  4.8747,  -7.0232,  -4.1367,  ...,  -4.1859,  -2.7916,  -3.0367],\n         ...,\n         [  5.6844, -10.0907,  -4.7995,  ...,  -5.5661,  -3.4763,  -6.9165],\n         [  3.8252,  -4.4261,  -1.5736,  ...,  -3.6205,  -0.7457,  -2.6781],\n         [  5.5476,  -8.0797,  -5.3136,  ...,  -5.9175,  -4.6428,  -6.6182]],\n\n        ...,\n\n        [[  6.2329,  -5.6986,  -4.4003,  ...,  -4.9978,  -5.4505,  -6.0065],\n         [  4.5816,  -3.0084,  -4.3789,  ...,  -3.6890,  -0.4907,  -4.3853],\n         [  4.2864,  -4.2727,  -3.4970,  ...,  -3.9741,  -3.0780,  -6.3296],\n         ...,\n         [  6.5369,  -4.8309,  -2.7178,  ...,  -5.2795,  -4.7246,  -5.6874],\n         [  7.1938,  -2.4227,  -3.5248,  ...,  -4.8716,  -4.8112,  -6.5379],\n         [  6.7999,  -4.8870,  -0.2368,  ...,  -5.6579,  -5.1136,  -3.9159]],\n\n        [[  4.2967,  -6.3247,  -5.5420,  ...,  -4.6959,  -4.1590,  -5.7608],\n         [  5.8049,  -3.6484,  -4.5866,  ...,  -3.8342,  -1.8794,  -5.5023],\n         [  5.3276,  -3.8784,  -3.4268,  ...,  -3.0494,  -3.3516,  -5.3999],\n         ...,\n         [  4.5262,  -5.7328,  -4.5576,  ...,  -5.2571,  -4.0224,  -4.7971],\n         [  6.1058,  -2.9771,  -4.3419,  ...,  -3.4850,  -3.5584,  -6.0711],\n         [  6.0065,  -6.8486,  -2.9187,  ...,  -5.1517,  -3.8328,  -5.4005]],\n\n        [[  6.7952,  -5.9581,  -3.8170,  ...,  -6.1306,  -3.8980,  -5.2182],\n         [  4.7843,  -4.3625,  -3.4503,  ...,  -3.0429,  -1.0069,  -5.0160],\n         [  4.7423,  -4.0734,  -2.0026,  ...,  -3.3397,  -1.5319,  -5.5408],\n         ...,\n         [  5.9233,  -6.7720,  -3.2585,  ...,  -5.0303,  -3.6403,  -6.4752],\n         [  6.4932,  -3.8687,  -2.0943,  ...,  -4.3999,  -3.3642,  -6.5363],\n         [  7.4559,  -5.1406,   0.5284,  ...,  -4.9604,  -4.5710,  -5.3826]]],\n       device='cuda:0', grad_fn=<AddBackward0>), tensor([[[-1.0254],\n         [ 0.5791],\n         [-0.6458],\n         ...,\n         [-1.2198],\n         [-2.7965],\n         [-1.1531]],\n\n        [[-1.1604],\n         [-0.9972],\n         [-2.1179],\n         ...,\n         [-0.9099],\n         [-1.0286],\n         [-3.0328]],\n\n        [[-5.0549],\n         [-3.8171],\n         [-1.7807],\n         ...,\n         [-5.8512],\n         [-3.3489],\n         [-4.7341]],\n\n        ...,\n\n        [[-1.6947],\n         [-0.4835],\n         [-4.9195],\n         ...,\n         [-3.5398],\n         [-3.4552],\n         [-3.4297]],\n\n        [[ 0.4876],\n         [-2.0698],\n         [-3.0662],\n         ...,\n         [-1.2132],\n         [-1.7824],\n         [-0.7635]],\n\n        [[ 0.7829],\n         [ 0.2189],\n         [-2.1548],\n         ...,\n         [-1.7861],\n         [-2.7979],\n         [-1.9784]]], device='cuda:0', grad_fn=<AddBackward0>), tensor([[[-3.6498, -3.4908, -3.6187,  ..., -3.5289, -3.8178, -3.6744],\n         [-3.2804, -3.1006, -3.1543,  ..., -3.0870, -3.3823, -3.2175],\n         [-3.5100, -3.3237, -3.3740,  ..., -3.3072, -3.5707, -3.4169],\n         ...,\n         [-4.1081, -4.0421, -4.0378,  ..., -3.9809, -4.1430, -4.1447],\n         [-4.1650, -4.0987, -4.1115,  ..., -4.0453, -4.2243, -4.2235],\n         [-4.1392, -4.0736, -4.0614,  ..., -3.9937, -4.1944, -4.1707]],\n\n        [[-2.3112, -2.3721, -2.2133,  ..., -2.6004, -2.6427, -2.4511],\n         [-3.4823, -3.5827, -3.4849,  ..., -3.5824, -3.7505, -3.5713],\n         [-3.5046, -3.6621, -3.5683,  ..., -3.6990, -3.8633, -3.6441],\n         ...,\n         [-3.8630, -3.8739, -3.7105,  ..., -4.0762, -4.0627, -3.8866],\n         [-3.8149, -3.8647, -3.6870,  ..., -4.0637, -4.0323, -3.8605],\n         [-4.1886, -4.2119, -4.0773,  ..., -4.4352, -4.3988, -4.2430]],\n\n        [[-1.9862, -1.7931, -1.7450,  ..., -1.8751, -2.1345, -2.0390],\n         [-1.5100, -1.3702, -1.2807,  ..., -1.4770, -1.6623, -1.6035],\n         [-1.5638, -1.4044, -1.3180,  ..., -1.5494, -1.7191, -1.6515],\n         ...,\n         [-1.8217, -1.6298, -1.5178,  ..., -1.8839, -1.9941, -1.8687],\n         [-2.0018, -1.8120, -1.7015,  ..., -2.0700, -2.1824, -2.0502],\n         [-1.9469, -1.7752, -1.6727,  ..., -2.0368, -2.1384, -1.9946]],\n\n        ...,\n\n        [[-0.7459, -0.2746, -0.5147,  ..., -0.6378, -0.9469, -0.7759],\n         [-0.9958, -0.5589, -0.7966,  ..., -0.9018, -1.2208, -1.0370],\n         [-1.0953, -0.6611, -0.8872,  ..., -0.9099, -1.3346, -1.0890],\n         ...,\n         [-1.7204, -1.1448, -1.5489,  ..., -1.9175, -1.9201, -1.9237],\n         [-1.1636, -0.6134, -0.9931,  ..., -1.3438, -1.3703, -1.3533],\n         [-1.0375, -0.4929, -0.8435,  ..., -1.2396, -1.2365, -1.2116]],\n\n        [[-2.3704, -2.1079, -2.2421,  ..., -2.4508, -2.8402, -2.6562],\n         [-3.5595, -3.2445, -3.5233,  ..., -3.5955, -3.9896, -3.7924],\n         [-4.2090, -3.8361, -4.1596,  ..., -4.1861, -4.6080, -4.4536],\n         ...,\n         [-2.9149, -2.6139, -2.8405,  ..., -3.0460, -3.2139, -3.1900],\n         [-2.9831, -2.6284, -2.8564,  ..., -3.0792, -3.2402, -3.2508],\n         [-2.7952, -2.4774, -2.7095,  ..., -2.9133, -3.0668, -3.0817]],\n\n        [[-2.1046, -1.7263, -1.9545,  ..., -2.2074, -2.3714, -2.0817],\n         [-2.8306, -2.4761, -2.6339,  ..., -2.8985, -3.0506, -2.7840],\n         [-2.7562, -2.3964, -2.5503,  ..., -2.8107, -2.9543, -2.6950],\n         ...,\n         [-2.1971, -1.8356, -2.0023,  ..., -2.3088, -2.3486, -2.1684],\n         [-2.1272, -1.7860, -1.9482,  ..., -2.2151, -2.2926, -2.0856],\n         [-1.8418, -1.4547, -1.6640,  ..., -1.9770, -1.9930, -1.8990]]],\n       device='cuda:0', grad_fn=<AddBackward0>), tensor([[[ 5.4066e-02],\n         [ 6.5631e-02],\n         [ 7.8555e-02],\n         [ 8.2301e-02],\n         [ 5.5858e-02],\n         [ 1.7058e-02],\n         [ 5.6861e-02],\n         [ 4.3544e-02],\n         [ 5.9106e-02],\n         [ 1.0269e-01],\n         [ 6.7681e-02],\n         [ 5.7432e-02],\n         [ 4.9514e-02],\n         [ 4.2039e-02],\n         [ 4.9348e-02],\n         [ 9.6293e-02],\n         [ 2.2876e-02],\n         [ 5.0893e-02],\n         [ 5.4959e-02],\n         [ 3.7836e-02],\n         [ 5.6841e-02],\n         [ 5.0191e-02],\n         [ 6.1113e-02],\n         [ 9.0875e-02]],\n\n        [[-6.7664e-02],\n         [-1.6427e-01],\n         [-1.6623e-01],\n         [-1.2173e-01],\n         [-1.8003e-01],\n         [-1.6219e-01],\n         [-1.0723e-02],\n         [-1.5421e-01],\n         [-4.9339e-02],\n         [-3.8281e-02],\n         [-1.8616e-01],\n         [ 2.1373e-01],\n         [-8.6579e-02],\n         [-9.1772e-02],\n         [-1.0777e-01],\n         [-1.2135e-01],\n         [-8.8904e-02],\n         [-1.5278e-01],\n         [-1.2438e-01],\n         [-1.0036e-01],\n         [-1.1380e-01],\n         [-9.2139e-02],\n         [-8.9316e-02],\n         [-1.1768e-01]],\n\n        [[ 6.5625e-02],\n         [ 6.0019e-02],\n         [ 5.6963e-02],\n         [ 4.7871e-02],\n         [ 1.7319e-02],\n         [ 4.6699e-02],\n         [-1.6525e-01],\n         [ 6.3119e-02],\n         [-1.7403e-02],\n         [ 8.5018e-02],\n         [ 1.1315e-01],\n         [ 1.1513e-01],\n         [ 1.0047e-01],\n         [ 9.8939e-02],\n         [ 7.9134e-02],\n         [ 1.0424e-01],\n         [ 9.2704e-02],\n         [ 1.2133e-01],\n         [ 9.9248e-02],\n         [ 4.4340e-02],\n         [ 8.7588e-02],\n         [ 1.3086e-01],\n         [ 1.1863e-01],\n         [ 9.6424e-02]],\n\n        [[ 5.2794e-02],\n         [ 1.0923e-01],\n         [ 1.1409e-01],\n         [ 7.6880e-02],\n         [ 5.6569e-02],\n         [ 6.6162e-02],\n         [ 1.1882e-01],\n         [-7.2202e-02],\n         [ 9.9407e-02],\n         [ 1.9248e-01],\n         [ 1.1154e-01],\n         [ 1.1839e-01],\n         [ 1.3504e-01],\n         [ 1.4178e-01],\n         [ 1.5760e-01],\n         [ 1.1420e-01],\n         [ 1.0585e-01],\n         [ 1.4212e-01],\n         [ 1.2363e-01],\n         [ 7.6701e-02],\n         [ 1.2803e-01],\n         [ 1.4405e-01],\n         [ 1.5990e-01],\n         [ 1.7584e-01]],\n\n        [[-1.7807e-01],\n         [-2.6471e-01],\n         [-2.6448e-01],\n         [-2.6246e-01],\n         [-1.7450e-01],\n         [-1.4318e-01],\n         [-2.0536e-01],\n         [-2.7054e-01],\n         [-2.6496e-01],\n         [ 2.3996e-02],\n         [-1.9643e-01],\n         [-1.8517e-01],\n         [-1.5990e-01],\n         [-1.4904e-01],\n         [-1.7138e-01],\n         [-1.4573e-01],\n         [-1.5216e-01],\n         [-1.3528e-01],\n         [-1.4958e-01],\n         [-1.6462e-01],\n         [-1.6598e-01],\n         [-2.1219e-01],\n         [-2.1703e-01],\n         [-1.9016e-01]],\n\n        [[-8.1026e-02],\n         [ 1.5849e-02],\n         [ 4.3204e-02],\n         [ 4.3463e-02],\n         [-9.3584e-03],\n         [ 5.5187e-03],\n         [ 3.1684e-02],\n         [ 3.5463e-02],\n         [ 3.6369e-02],\n         [ 1.6242e-02],\n         [ 2.1057e-01],\n         [ 6.2618e-02],\n         [ 4.8180e-02],\n         [ 1.1223e-01],\n         [ 8.8505e-02],\n         [ 9.5567e-02],\n         [ 6.4552e-02],\n         [ 3.1516e-02],\n         [ 1.1724e-01],\n         [ 7.3821e-02],\n         [ 4.7713e-02],\n         [ 6.2399e-02],\n         [ 7.8784e-02],\n         [ 7.6747e-02]],\n\n        [[-1.1578e-01],\n         [-1.4448e-01],\n         [-1.2108e-01],\n         [-1.1716e-01],\n         [-1.3413e-01],\n         [-6.0049e-02],\n         [-1.0755e-01],\n         [-1.5272e-01],\n         [-1.4546e-01],\n         [-2.6533e-01],\n         [-1.5269e-01],\n         [ 1.7279e-01],\n         [-1.9391e-01],\n         [-8.6409e-02],\n         [-1.7555e-01],\n         [-1.7146e-01],\n         [-1.5573e-01],\n         [-1.4953e-01],\n         [-2.7697e-02],\n         [-1.7865e-01],\n         [-1.1629e-01],\n         [-6.9994e-02],\n         [-9.2495e-02],\n         [-1.9928e-01]],\n\n        [[ 3.9459e-02],\n         [-5.4832e-02],\n         [-6.4811e-02],\n         [-8.4612e-02],\n         [-2.3616e-02],\n         [-5.4199e-02],\n         [-7.1516e-02],\n         [-4.1795e-02],\n         [-6.5328e-02],\n         [ 2.9066e-01],\n         [ 1.4585e-01],\n         [ 1.6468e-01],\n         [ 1.3082e-01],\n         [ 1.3881e-01],\n         [ 1.1905e-01],\n         [ 1.1631e-01],\n         [ 1.1235e-01],\n         [ 9.4683e-02],\n         [ 1.6876e-01],\n         [ 1.5931e-01],\n         [ 1.6417e-01],\n         [ 1.6234e-01],\n         [ 1.1294e-01],\n         [ 1.8581e-01]],\n\n        [[-6.7158e-02],\n         [-6.1223e-02],\n         [-8.2407e-02],\n         [-6.6869e-02],\n         [-5.5211e-02],\n         [ 1.2791e-02],\n         [-6.7059e-02],\n         [ 1.9043e-01],\n         [ 1.2470e-01],\n         [ 1.0622e-01],\n         [ 1.1262e-01],\n         [ 1.1784e-01],\n         [ 1.2425e-01],\n         [ 1.4761e-01],\n         [ 1.1366e-01],\n         [ 1.2769e-01],\n         [ 1.8647e-01],\n         [ 1.6956e-01],\n         [ 1.0577e-01],\n         [ 1.8000e-01],\n         [ 1.7869e-01],\n         [ 1.5395e-01],\n         [ 1.2786e-01],\n         [ 1.0609e-01]],\n\n        [[-8.6342e-02],\n         [-1.2166e-01],\n         [-2.7074e-01],\n         [-1.4543e-01],\n         [-1.5476e-01],\n         [-1.1159e-01],\n         [-8.4526e-02],\n         [-2.3460e-02],\n         [-5.5933e-02],\n         [-3.3472e-02],\n         [-1.7022e-03],\n         [-6.1379e-02],\n         [-4.8252e-02],\n         [-3.3536e-02],\n         [-4.7247e-02],\n         [ 6.0844e-02],\n         [ 3.9172e-02],\n         [-1.0941e-01],\n         [ 3.3746e-02],\n         [ 4.2120e-02],\n         [ 7.4103e-02],\n         [ 6.7480e-02],\n         [-3.9778e-02],\n         [ 4.6653e-02]],\n\n        [[ 1.1761e-04],\n         [-3.2319e-02],\n         [-8.2931e-02],\n         [-6.2712e-02],\n         [-5.5349e-02],\n         [-1.6789e-01],\n         [-5.7528e-02],\n         [-3.3631e-02],\n         [-8.9793e-02],\n         [-4.4528e-02],\n         [ 1.9845e-01],\n         [ 4.1326e-02],\n         [ 6.2142e-02],\n         [ 5.2120e-02],\n         [ 4.5284e-02],\n         [ 5.3875e-03],\n         [ 2.3621e-02],\n         [ 4.3163e-02],\n         [ 2.7918e-02],\n         [-2.7312e-03],\n         [ 2.5573e-02],\n         [ 2.2228e-02],\n         [ 2.3738e-02],\n         [ 4.5626e-02]],\n\n        [[ 1.1152e-01],\n         [ 1.1857e-01],\n         [ 1.2849e-01],\n         [ 1.0917e-01],\n         [ 9.5948e-02],\n         [ 5.3384e-02],\n         [ 1.0204e-03],\n         [ 1.0989e-01],\n         [ 6.0001e-02],\n         [ 1.5550e-01],\n         [ 1.5263e-01],\n         [ 1.9080e-01],\n         [ 1.5649e-01],\n         [ 1.7876e-01],\n         [ 1.4794e-01],\n         [ 1.8362e-01],\n         [ 3.1785e-01],\n         [ 1.4816e-01],\n         [ 1.9398e-01],\n         [ 2.9620e-01],\n         [ 1.6768e-01],\n         [ 2.6444e-01],\n         [ 1.7876e-01],\n         [ 1.6529e-01]],\n\n        [[-3.2135e-01],\n         [-2.7609e-01],\n         [-2.2708e-01],\n         [-2.7871e-01],\n         [-1.5976e-01],\n         [-1.0789e-01],\n         [-2.6115e-01],\n         [ 2.4042e-01],\n         [ 1.7649e-01],\n         [ 1.0470e-01],\n         [ 7.6834e-02],\n         [ 1.1821e-01],\n         [ 9.2225e-02],\n         [ 1.8485e-01],\n         [ 1.6472e-01],\n         [ 1.1662e-01],\n         [ 1.3644e-01],\n         [ 1.0456e-01],\n         [ 1.4690e-01],\n         [ 1.0390e-01],\n         [ 1.6453e-01],\n         [ 1.6165e-01],\n         [ 1.5546e-01],\n         [ 1.7893e-01]],\n\n        [[ 2.2485e-01],\n         [ 1.5733e-01],\n         [ 1.8498e-01],\n         [ 1.1078e-01],\n         [ 2.0727e-01],\n         [ 1.8171e-01],\n         [ 4.9812e-02],\n         [ 1.6734e-02],\n         [ 1.8851e-01],\n         [ 2.8564e-01],\n         [ 2.0382e-01],\n         [ 1.7996e-01],\n         [ 1.8341e-01],\n         [ 1.6929e-01],\n         [ 1.5521e-01],\n         [ 1.3484e-01],\n         [ 1.5028e-01],\n         [ 1.4007e-01],\n         [ 9.8987e-02],\n         [ 1.9394e-01],\n         [ 2.3100e-01],\n         [ 2.1777e-01],\n         [ 1.4207e-01],\n         [ 3.0390e-01]],\n\n        [[-2.8275e-01],\n         [-1.7993e-01],\n         [-1.3902e-01],\n         [-1.6490e-01],\n         [-1.0496e-01],\n         [-2.0422e-01],\n         [-1.8531e-01],\n         [-1.7398e-01],\n         [-2.2590e-01],\n         [-1.9143e-01],\n         [ 3.7845e-01],\n         [-1.4968e-01],\n         [-1.7335e-01],\n         [-2.0042e-01],\n         [-1.4693e-01],\n         [-1.1373e-01],\n         [-4.5550e-02],\n         [-1.5862e-01],\n         [-1.9468e-01],\n         [-9.1910e-02],\n         [-2.0067e-01],\n         [-1.8242e-01],\n         [-2.3379e-01],\n         [-2.4639e-01]],\n\n        [[ 3.5746e-02],\n         [ 1.1198e-01],\n         [ 1.5230e-01],\n         [ 2.2968e-01],\n         [ 1.2334e-01],\n         [ 7.9760e-02],\n         [ 2.4281e-02],\n         [-1.0909e-02],\n         [ 1.1329e-01],\n         [ 2.1473e-01],\n         [ 1.6258e-01],\n         [ 1.7210e-01],\n         [ 1.3568e-01],\n         [ 9.7467e-02],\n         [ 8.7748e-02],\n         [ 1.7078e-01],\n         [ 1.8598e-01],\n         [ 8.9025e-02],\n         [ 1.1402e-01],\n         [ 1.6093e-01],\n         [ 2.7516e-01],\n         [ 1.6528e-01],\n         [ 1.5849e-01],\n         [ 1.4951e-01]],\n\n        [[-6.7726e-02],\n         [-2.6111e-02],\n         [-3.7656e-02],\n         [-3.9180e-02],\n         [-2.5971e-02],\n         [-1.4467e-01],\n         [-1.0697e-02],\n         [-1.7789e-02],\n         [-8.8801e-02],\n         [-1.5108e-01],\n         [-3.3329e-02],\n         [ 2.3654e-01],\n         [ 2.0878e-02],\n         [ 2.2508e-02],\n         [ 2.8622e-02],\n         [-1.1708e-02],\n         [-4.0135e-02],\n         [ 2.9418e-02],\n         [-9.4731e-03],\n         [-2.9228e-03],\n         [-2.7782e-02],\n         [ 2.2871e-02],\n         [ 1.7818e-02],\n         [ 2.9181e-02]],\n\n        [[ 4.7783e-02],\n         [ 8.7086e-02],\n         [ 7.9555e-02],\n         [ 6.4638e-02],\n         [ 1.0188e-02],\n         [-7.4722e-03],\n         [ 7.2756e-02],\n         [ 7.3916e-02],\n         [ 7.0337e-02],\n         [ 1.6638e-01],\n         [ 9.5175e-02],\n         [ 8.1817e-02],\n         [ 1.5183e-01],\n         [ 7.3419e-02],\n         [ 1.0479e-01],\n         [ 8.2887e-02],\n         [ 6.3357e-02],\n         [ 1.0268e-01],\n         [ 1.0171e-01],\n         [ 7.6174e-02],\n         [ 8.9681e-02],\n         [ 9.0263e-02],\n         [ 7.2253e-02],\n         [ 4.0903e-02]],\n\n        [[-1.8114e-02],\n         [-3.1521e-02],\n         [-3.0011e-02],\n         [-3.3700e-02],\n         [-3.9190e-02],\n         [-7.1181e-02],\n         [-1.3108e-01],\n         [-2.4210e-02],\n         [-3.9979e-02],\n         [-5.0791e-02],\n         [-7.0238e-03],\n         [-4.6672e-02],\n         [ 3.8189e-01],\n         [-3.8349e-02],\n         [-8.6204e-02],\n         [-3.9688e-02],\n         [ 1.9305e-02],\n         [-6.7339e-02],\n         [-3.3100e-02],\n         [ 5.0904e-03],\n         [-1.5047e-02],\n         [-4.9961e-04],\n         [-1.9295e-02],\n         [-1.3981e-02]],\n\n        [[ 1.4099e-02],\n         [ 6.8466e-02],\n         [ 7.5729e-02],\n         [ 6.5672e-02],\n         [ 5.7519e-02],\n         [ 1.3579e-03],\n         [ 9.5770e-04],\n         [ 1.6213e-02],\n         [ 1.4458e-02],\n         [ 9.2938e-04],\n         [ 7.3183e-04],\n         [ 2.2929e-02],\n         [ 1.6425e-01],\n         [ 1.3149e-01],\n         [ 1.3060e-01],\n         [ 1.2997e-01],\n         [ 1.4727e-01],\n         [ 1.5043e-01],\n         [ 1.4297e-01],\n         [ 1.5185e-01],\n         [ 1.2384e-01],\n         [ 1.8071e-01],\n         [ 9.4006e-02],\n         [ 1.1730e-01]],\n\n        [[-2.9610e-01],\n         [-2.3449e-01],\n         [-2.2987e-01],\n         [-2.7641e-01],\n         [-2.4688e-01],\n         [-3.2661e-01],\n         [-2.6682e-01],\n         [-2.5042e-01],\n         [-3.3929e-01],\n         [-4.5027e-01],\n         [-2.1687e-01],\n         [-2.9021e-01],\n         [-2.4233e-01],\n         [ 2.8537e-01],\n         [-2.8036e-01],\n         [-2.9515e-01],\n         [-3.0914e-01],\n         [-3.1012e-01],\n         [-3.1859e-01],\n         [-3.0750e-01],\n         [-3.0444e-01],\n         [-2.5483e-01],\n         [-2.9749e-01],\n         [-2.7640e-01]],\n\n        [[-5.2741e-01],\n         [-4.1537e-01],\n         [-3.7248e-01],\n         [-3.3458e-01],\n         [-2.7509e-01],\n         [-3.5539e-01],\n         [-4.7727e-01],\n         [-7.2280e-01],\n         [-6.3663e-01],\n         [-6.8911e-01],\n         [-5.5427e-01],\n         [-3.6727e-01],\n         [ 1.5880e-01],\n         [-5.3511e-01],\n         [-5.0268e-01],\n         [-5.0363e-01],\n         [-3.7419e-01],\n         [-3.0913e-01],\n         [-5.0107e-01],\n         [-3.5062e-01],\n         [-5.1421e-01],\n         [-5.7398e-01],\n         [-7.1038e-01],\n         [-5.1138e-01]],\n\n        [[-4.6731e-01],\n         [-4.7546e-01],\n         [-4.7340e-01],\n         [-5.3868e-01],\n         [-4.6113e-01],\n         [-4.7867e-01],\n         [-5.9746e-01],\n         [-5.4122e-01],\n         [-5.6321e-01],\n         [-4.7033e-01],\n         [-4.6819e-01],\n         [ 7.6297e-02],\n         [-4.5826e-01],\n         [-4.3651e-01],\n         [-4.4497e-01],\n         [-4.8697e-01],\n         [-4.5469e-01],\n         [-4.2812e-01],\n         [-4.5190e-01],\n         [-4.4646e-01],\n         [-4.7458e-01],\n         [-4.2964e-01],\n         [-4.4461e-01],\n         [-4.3520e-01]],\n\n        [[ 2.3901e-02],\n         [-8.3929e-02],\n         [-5.9767e-02],\n         [-7.8982e-02],\n         [-9.1446e-02],\n         [-7.5392e-02],\n         [-8.0575e-02],\n         [-1.6147e-01],\n         [-1.3367e-01],\n         [-1.0356e-01],\n         [ 2.7246e-01],\n         [-6.2741e-02],\n         [-8.1526e-02],\n         [-8.0032e-02],\n         [-1.0672e-01],\n         [-1.1291e-01],\n         [-1.1773e-01],\n         [-1.0829e-01],\n         [-9.8497e-02],\n         [-8.1571e-02],\n         [-8.9528e-02],\n         [-5.8892e-02],\n         [-6.5702e-02],\n         [-6.0051e-02]],\n\n        [[ 4.3231e-01],\n         [ 3.1132e-01],\n         [ 3.0673e-01],\n         [ 3.0883e-01],\n         [ 3.2686e-01],\n         [ 4.0427e-01],\n         [ 2.9928e-01],\n         [ 2.4772e-01],\n         [ 2.8525e-01],\n         [ 2.3264e-01],\n         [ 3.2084e-01],\n         [ 4.6697e-01],\n         [ 3.0005e-01],\n         [ 3.2966e-01],\n         [ 3.1251e-01],\n         [ 2.9748e-01],\n         [ 2.9741e-01],\n         [ 3.1698e-01],\n         [ 3.3682e-01],\n         [ 3.0614e-01],\n         [ 2.9851e-01],\n         [ 3.3857e-01],\n         [ 3.3640e-01],\n         [ 3.2906e-01]],\n\n        [[ 3.7814e-01],\n         [ 2.7629e-01],\n         [ 2.7702e-01],\n         [ 2.7938e-01],\n         [ 3.0291e-01],\n         [ 4.2052e-01],\n         [ 3.9039e-01],\n         [ 2.7374e-01],\n         [ 2.7679e-01],\n         [ 2.8592e-01],\n         [ 3.5162e-01],\n         [ 3.4790e-01],\n         [ 3.0891e-01],\n         [ 3.0513e-01],\n         [ 3.5150e-01],\n         [ 3.5958e-01],\n         [ 4.0797e-01],\n         [ 3.0780e-01],\n         [ 3.3473e-01],\n         [ 4.5103e-01],\n         [ 3.3080e-01],\n         [ 3.7032e-01],\n         [ 3.1657e-01],\n         [ 3.1476e-01]],\n\n        [[ 2.6813e-01],\n         [ 2.0210e-01],\n         [ 2.1139e-01],\n         [ 1.7551e-01],\n         [ 1.8097e-01],\n         [ 1.8400e-01],\n         [ 1.7217e-01],\n         [ 1.8994e-01],\n         [ 4.3222e-01],\n         [ 2.5479e-01],\n         [ 2.0056e-01],\n         [ 2.4933e-01],\n         [ 2.1955e-01],\n         [ 2.4208e-01],\n         [ 1.8911e-01],\n         [ 1.9604e-01],\n         [ 1.7348e-01],\n         [ 2.9323e-01],\n         [ 2.9433e-01],\n         [ 2.2136e-01],\n         [ 3.0027e-01],\n         [ 3.0404e-01],\n         [ 3.4177e-01],\n         [ 3.1198e-01]],\n\n        [[ 3.2656e-01],\n         [ 2.8771e-01],\n         [ 2.9052e-01],\n         [ 2.7728e-01],\n         [ 4.5873e-01],\n         [ 2.4484e-01],\n         [ 2.7377e-01],\n         [ 4.9087e-01],\n         [ 3.1983e-01],\n         [ 2.7421e-01],\n         [ 2.1840e-01],\n         [ 3.6485e-01],\n         [ 5.9517e-01],\n         [ 4.3731e-01],\n         [ 5.3635e-01],\n         [ 4.7069e-01],\n         [ 4.1696e-01],\n         [ 6.4639e-01],\n         [ 4.2241e-01],\n         [ 3.5925e-01],\n         [ 3.2833e-01],\n         [ 3.7496e-01],\n         [ 3.5311e-01],\n         [ 3.7080e-01]],\n\n        [[ 8.1766e-02],\n         [-9.9239e-02],\n         [-1.4638e-01],\n         [-1.2569e-01],\n         [-3.8941e-02],\n         [-2.0013e-01],\n         [-1.3408e-01],\n         [-5.5633e-02],\n         [-7.6402e-02],\n         [-1.7483e-02],\n         [-7.9198e-02],\n         [-5.4625e-02],\n         [ 1.6237e-01],\n         [-1.0378e-01],\n         [-1.0815e-01],\n         [-9.4098e-02],\n         [-1.6403e-01],\n         [-1.1638e-01],\n         [-1.1846e-01],\n         [-1.6589e-01],\n         [-1.4727e-01],\n         [-1.1786e-01],\n         [-1.2803e-01],\n         [-9.5555e-02]],\n\n        [[ 6.6414e-01],\n         [ 6.5246e-01],\n         [ 6.4179e-01],\n         [ 5.2887e-01],\n         [ 6.3609e-01],\n         [ 6.3148e-01],\n         [ 5.5823e-01],\n         [ 6.4409e-01],\n         [ 8.3820e-02],\n         [ 5.5487e-01],\n         [ 5.5256e-01],\n         [ 5.9509e-01],\n         [ 5.1239e-01],\n         [ 5.3664e-01],\n         [ 5.0079e-01],\n         [ 5.6930e-01],\n         [ 5.5542e-01],\n         [ 5.2900e-01],\n         [ 5.4712e-01],\n         [ 5.9712e-01],\n         [ 5.5663e-01],\n         [ 6.3237e-01],\n         [ 6.4783e-01],\n         [ 5.5444e-01]]], device='cuda:0', grad_fn=<AddBackward0>), ([], [], []))\n:List trace inputs must have elements (toTypeInferredIValue at /opt/conda/conda-bld/pytorch_1579027003190/work/torch/csrc/jit/pybind_utils.h:293)\nframe #0: c10::Error::Error(c10::SourceLocation, std::string const&) + 0x47 (0x7eff980b3627 in /home/aloui/miniconda3/envs/vilbert-mt/lib/python3.6/site-packages/torch/lib/libc10.so)\nframe #1: <unknown function> + 0x6e4c9f (0x7eff8c4efc9f in /home/aloui/miniconda3/envs/vilbert-mt/lib/python3.6/site-packages/torch/lib/libtorch_python.so)\nframe #2: <unknown function> + 0x769f4b (0x7eff8c574f4b in /home/aloui/miniconda3/envs/vilbert-mt/lib/python3.6/site-packages/torch/lib/libtorch_python.so)\nframe #3: torch::jit::tracer::trace(std::vector<c10::IValue, std::allocator<c10::IValue> >, std::function<std::vector<c10::IValue, std::allocator<c10::IValue> > (std::vector<c10::IValue, std::allocator<c10::IValue> >)> const&, std::function<std::string (at::Tensor const&)>, bool, torch::jit::script::Module*) + 0x4e6 (0x7eff60d96e26 in /home/aloui/miniconda3/envs/vilbert-mt/lib/python3.6/site-packages/torch/lib/libtorch.so)\nframe #4: <unknown function> + 0x7660e1 (0x7eff8c5710e1 in /home/aloui/miniconda3/envs/vilbert-mt/lib/python3.6/site-packages/torch/lib/libtorch_python.so)\nframe #5: <unknown function> + 0x77ffb1 (0x7eff8c58afb1 in /home/aloui/miniconda3/envs/vilbert-mt/lib/python3.6/site-packages/torch/lib/libtorch_python.so)\nframe #6: <unknown function> + 0x28c076 (0x7eff8c097076 in /home/aloui/miniconda3/envs/vilbert-mt/lib/python3.6/site-packages/torch/lib/libtorch_python.so)\nframe #7: _PyCFunction_FastCallDict + 0x154 (0x55cc9ec18304 in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\nframe #8: <unknown function> + 0x199c5e (0x55cc9ec9fc5e in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\nframe #9: _PyEval_EvalFrameDefault + 0x30a (0x55cc9ecc281a in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\nframe #10: <unknown function> + 0x19335e (0x55cc9ec9935e in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\nframe #11: <unknown function> + 0x193f31 (0x55cc9ec99f31 in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\nframe #12: <unknown function> + 0x199be5 (0x55cc9ec9fbe5 in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\nframe #13: _PyEval_EvalFrameDefault + 0x30a (0x55cc9ecc281a in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\nframe #14: <unknown function> + 0x192f26 (0x55cc9ec98f26 in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\nframe #15: <unknown function> + 0x193f31 (0x55cc9ec99f31 in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\nframe #16: <unknown function> + 0x199be5 (0x55cc9ec9fbe5 in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\nframe #17: _PyEval_EvalFrameDefault + 0x30a (0x55cc9ecc281a in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\nframe #18: <unknown function> + 0x192f26 (0x55cc9ec98f26 in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\nframe #19: <unknown function> + 0x193f31 (0x55cc9ec99f31 in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\nframe #20: <unknown function> + 0x199be5 (0x55cc9ec9fbe5 in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\nframe #21: _PyEval_EvalFrameDefault + 0x30a (0x55cc9ecc281a in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\nframe #22: <unknown function> + 0x192f26 (0x55cc9ec98f26 in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\nframe #23: <unknown function> + 0x193f31 (0x55cc9ec99f31 in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\nframe #24: <unknown function> + 0x199be5 (0x55cc9ec9fbe5 in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\nframe #25: _PyEval_EvalFrameDefault + 0x10c9 (0x55cc9ecc35d9 in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\nframe #26: PyEval_EvalCodeEx + 0x329 (0x55cc9ec9aa49 in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\nframe #27: PyEval_EvalCode + 0x1c (0x55cc9ec9b7ec in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\nframe #28: <unknown function> + 0x1ba227 (0x55cc9ecc0227 in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\nframe #29: _PyCFunction_FastCallDict + 0x91 (0x55cc9ec18241 in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\nframe #30: <unknown function> + 0x199b0c (0x55cc9ec9fb0c in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\nframe #31: _PyEval_EvalFrameDefault + 0x30a (0x55cc9ecc281a in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\nframe #32: _PyGen_Send + 0x256 (0x55cc9eca2bc6 in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\nframe #33: _PyEval_EvalFrameDefault + 0x1445 (0x55cc9ecc3955 in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\nframe #34: _PyGen_Send + 0x256 (0x55cc9eca2bc6 in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\nframe #35: _PyEval_EvalFrameDefault + 0x1445 (0x55cc9ecc3955 in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\nframe #36: _PyGen_Send + 0x256 (0x55cc9eca2bc6 in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\nframe #37: _PyCFunction_FastCallDict + 0x115 (0x55cc9ec182c5 in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\nframe #38: <unknown function> + 0x199b0c (0x55cc9ec9fb0c in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\nframe #39: _PyEval_EvalFrameDefault + 0x30a (0x55cc9ecc281a in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\nframe #40: <unknown function> + 0x193cfb (0x55cc9ec99cfb in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\nframe #41: <unknown function> + 0x199be5 (0x55cc9ec9fbe5 in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\nframe #42: _PyEval_EvalFrameDefault + 0x30a (0x55cc9ecc281a in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\nframe #43: <unknown function> + 0x193cfb (0x55cc9ec99cfb in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\nframe #44: <unknown function> + 0x199be5 (0x55cc9ec9fbe5 in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\nframe #45: _PyEval_EvalFrameDefault + 0x30a (0x55cc9ecc281a in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\nframe #46: <unknown function> + 0x192f26 (0x55cc9ec98f26 in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\nframe #47: _PyFunction_FastCallDict + 0x3d8 (0x55cc9ec9a628 in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\nframe #48: _PyObject_FastCallDict + 0x26f (0x55cc9ec186cf in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\nframe #49: _PyObject_Call_Prepend + 0x63 (0x55cc9ec1d143 in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\nframe #50: PyObject_Call + 0x3e (0x55cc9ec1810e in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\nframe #51: _PyEval_EvalFrameDefault + 0x1aaf (0x55cc9ecc3fbf in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\nframe #52: <unknown function> + 0x1931f6 (0x55cc9ec991f6 in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\nframe #53: <unknown function> + 0x193f31 (0x55cc9ec99f31 in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\nframe #54: <unknown function> + 0x199be5 (0x55cc9ec9fbe5 in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\nframe #55: _PyEval_EvalFrameDefault + 0x10c9 (0x55cc9ecc35d9 in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\nframe #56: <unknown function> + 0x19c744 (0x55cc9eca2744 in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\nframe #57: _PyCFunction_FastCallDict + 0x91 (0x55cc9ec18241 in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\nframe #58: <unknown function> + 0x199b0c (0x55cc9ec9fb0c in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\nframe #59: _PyEval_EvalFrameDefault + 0x30a (0x55cc9ecc281a in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\nframe #60: <unknown function> + 0x1931f6 (0x55cc9ec991f6 in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\nframe #61: <unknown function> + 0x193f31 (0x55cc9ec99f31 in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\nframe #62: <unknown function> + 0x199be5 (0x55cc9ec9fbe5 in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\nframe #63: _PyEval_EvalFrameDefault + 0x30a (0x55cc9ecc281a in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-928ed1fbb0d1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mwriter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSummaryWriter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogdir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'results/runs'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0minput_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mquestion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspatials\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msegment_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mco_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask_tokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_to_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/vilbert-mt/lib/python3.6/site-packages/tensorboardX/writer.py\u001b[0m in \u001b[0;36madd_graph\u001b[0;34m(self, model, input_to_model, verbose)\u001b[0m\n\u001b[1;32m    792\u001b[0m         \"\"\"\n\u001b[1;32m    793\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensorboard\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pytorch_graph\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 794\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_file_writer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_to_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    795\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    796\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0madd_graph_deprecated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_to_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprofile_with_cuda\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/vilbert-mt/lib/python3.6/site-packages/torch/utils/tensorboard/_pytorch_graph.py\u001b[0m in \u001b[0;36mgraph\u001b[0;34m(model, args, verbose)\u001b[0m\n\u001b[1;32m    289\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Error occurs, No graph saved'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 291\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    292\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/vilbert-mt/lib/python3.6/site-packages/torch/utils/tensorboard/_pytorch_graph.py\u001b[0m in \u001b[0;36mgraph\u001b[0;34m(model, args, verbose)\u001b[0m\n\u001b[1;32m    283\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0monnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# TODO: move outside of torch.onnx?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 285\u001b[0;31m             \u001b[0mtrace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    286\u001b[0m             \u001b[0mgraph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_pass_inline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/vilbert-mt/lib/python3.6/site-packages/torch/jit/__init__.py\u001b[0m in \u001b[0;36mtrace\u001b[0;34m(func, example_inputs, optimize, check_trace, check_inputs, check_tolerance, _force_outplace, _module_class, _compilation_unit)\u001b[0m\n\u001b[1;32m    880\u001b[0m         return trace_module(func, {'forward': example_inputs}, None,\n\u001b[1;32m    881\u001b[0m                             \u001b[0mcheck_trace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrap_check_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheck_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 882\u001b[0;31m                             check_tolerance, _force_outplace, _module_class)\n\u001b[0m\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m     if (hasattr(func, '__self__') and isinstance(func.__self__, torch.nn.Module) and\n",
      "\u001b[0;32m~/miniconda3/envs/vilbert-mt/lib/python3.6/site-packages/torch/jit/__init__.py\u001b[0m in \u001b[0;36mtrace_module\u001b[0;34m(mod, inputs, optimize, check_trace, check_inputs, check_tolerance, _force_outplace, _module_class, _compilation_unit)\u001b[0m\n\u001b[1;32m   1032\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmod\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mmethod_name\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"forward\"\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1033\u001b[0m             \u001b[0mexample_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexample_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1034\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_c\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_method_from_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexample_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar_lookup_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_force_outplace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1035\u001b[0m             \u001b[0mcheck_trace_method\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_c\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Tracer cannot infer type of (tensor([[-23.9768, -17.3129, -18.0523,  ..., -18.6565, -18.3060, -14.8244],\n        [-26.2138, -18.8952, -17.7499,  ..., -17.4112, -15.3365, -17.8206],\n        [-24.8113, -16.7020, -11.6527,  ..., -15.2050, -14.3076, -10.0045],\n        ...,\n        [-27.0051, -15.3371, -20.5083,  ..., -19.9755, -16.9174, -17.5259],\n        [-21.7966, -14.3504, -19.0064,  ..., -13.6335, -11.8910, -26.7599],\n        [-23.3009, -11.6584, -19.6952,  ..., -18.6055, -13.8711, -18.0167]],\n       device='cuda:0', grad_fn=<AddmmBackward>), tensor([[-11.6474, -10.8408,  -8.1201,  ..., -13.7666, -13.3638, -14.8178],\n        [-14.1130,  -8.2416, -11.8985,  ..., -15.3526, -14.5676, -16.1072],\n        [-10.0281,  -8.5481, -12.1849,  ...,  -9.9922, -13.6915, -11.6269],\n        ...,\n        [-20.1335, -18.3920, -17.5234,  ..., -20.9741, -23.5247, -22.5615],\n        [ -6.5798,  -8.0710,  -7.1975,  ...,  -9.0155,  -8.8422, -10.2870],\n        [-18.6119, -14.4927, -17.6004,  ..., -18.2182, -18.8035, -19.1235]],\n       device='cuda:0', grad_fn=<AddmmBackward>), tensor([[-0.6393],\n        [-0.1429],\n        [-2.1546],\n        [-5.1147],\n        [-1.6715],\n        [ 0.3507],\n        [-4.3397],\n        [ 2.2866],\n        [-1.4691],\n        [ 1.4585],\n        [-0.2973],\n        [ 0.7474],\n        [ 2.5556],\n        [-2.9994],\n        [-0.9246],\n        [-1.2214],\n        [ 0.3344],\n        [ 2.2141],\n        [-0.7545],\n        [ 2.4200],\n        [-0.0531],\n        [ 3.1947],\n        [-0.2689],\n        [ 0.4529],\n        [-0.3984],\n        [-0.2024],\n        [ 1.1264],\n        [ 1.3671],\n        [-3.4349],\n        [-0.3805]], device='cuda:0', grad_fn=<AddmmBackward>), tensor([[ -1.8382,   2.1890],\n        [  9.7137,  -9.1303],\n        [  1.1245,  -0.7504],\n        [ -8.7560,   9.4857],\n        [-12.7439,  12.7932],\n        [-12.3451,  12.5709],\n        [ -1.1877,   0.6844],\n        [ -4.0932,   4.0128],\n        [ -4.8093,   5.3705],\n        [ -3.7177,   3.9173],\n        [-12.6056,  12.4244],\n        [ 10.6988, -10.2227],\n        [  2.8526,  -2.8399],\n        [ -7.0294,   7.1356],\n        [-10.3483,   9.9678]], device='cuda:0', grad_fn=<AddmmBackward>), tensor([[-1.3022, -1.1211, -3.1991],\n        [-0.0492, -0.8463, -3.6581],\n        [-0.1244, -1.9052, -2.7197],\n        [-1.2288,  0.7291, -5.5015],\n        [-0.3299, -2.6304, -0.9506],\n        [-1.6865, -1.4229, -2.1603],\n        [ 0.4084, -1.3018, -4.3268],\n        [-3.0534, -1.7261,  0.4608],\n        [ 0.6957, -1.7683, -3.7300],\n        [-2.5832, -0.6753, -0.2382],\n        [-0.4761, -1.3521, -2.6981],\n        [-2.4724, -0.0574, -2.8649],\n        [-3.2873,  0.2401, -0.6161],\n        [ 2.8250, -3.0116, -5.6009],\n        [ 0.4068,  0.0392, -5.6889],\n        [ 0.2833, -1.2190, -3.7594],\n        [-1.5270, -1.1284, -2.1290],\n        [-2.2854, -2.1912,  0.3826],\n        [-0.8855, -0.2406, -2.5146],\n        [-2.2929, -1.9686,  0.3879],\n        [-0.9590, -0.1366, -3.1811],\n        [-3.6603, -1.3946,  1.0387],\n        [-2.8627,  0.4189, -2.4454],\n        [-0.9705, -0.0349, -1.1119],\n        [-1.2466, -2.2507, -3.0363],\n        [-0.8483, -2.6603, -3.1504],\n        [-2.7211, -2.8056, -0.4124],\n        [-0.7093, -1.7536, -2.3936],\n        [-1.6274,  0.5352, -3.8358],\n        [-2.8041, -0.9302, -1.3755]], device='cuda:0', grad_fn=<AddmmBackward>), tensor([[[  8.1071,  -5.0885,  -3.7664,  ...,  -1.4273,  -0.9021,  -4.1969],\n         [  3.8177,  -4.5532,  -2.8071,  ...,  -1.3409,  -1.7692,  -2.2690],\n         [  7.0173,  -5.5335,  -4.4290,  ...,  -1.3300,   0.1980,  -3.6034],\n         ...,\n         [  7.1785,  -6.1633,  -3.6649,  ...,  -1.6600,  -1.7262,  -5.0354],\n         [  6.9941,  -5.3046,  -2.6913,  ...,  -3.1742,  -2.2862,  -3.5778],\n         [  7.5086,  -5.9734,  -2.9408,  ...,  -3.7117,  -2.2481,  -3.2648]],\n\n        [[  7.4254,  -6.7579,  -4.9328,  ...,  -3.9803,  -2.2647,  -2.4394],\n         [  7.2897,  -5.9018,  -5.5442,  ...,  -1.9450,  -1.7594,  -4.7357],\n         [  5.6920,  -5.7744,  -4.4779,  ...,  -3.6136,  -1.5126,  -1.5384],\n         ...,\n         [  6.6963,  -6.7992,  -6.3011,  ...,  -3.5846,  -2.3700,  -3.7784],\n         [  7.2653,  -5.9123,  -5.5892,  ...,  -1.9841,  -1.7899,  -4.7843],\n         [  7.7138,  -5.0347,  -4.6088,  ...,  -3.1614,  -3.4179,  -4.0131]],\n\n        [[  5.2152,  -8.8324,  -3.6273,  ...,  -6.6085,  -4.7241,  -6.8234],\n         [  4.8676,  -4.3746,  -2.4917,  ...,  -3.3825,  -0.8355,  -2.7390],\n         [  4.8747,  -7.0232,  -4.1367,  ...,  -4.1859,  -2.7916,  -3.0367],\n         ...,\n         [  5.6844, -10.0907,  -4.7995,  ...,  -5.5661,  -3.4763,  -6.9165],\n         [  3.8252,  -4.4261,  -1.5736,  ...,  -3.6205,  -0.7457,  -2.6781],\n         [  5.5476,  -8.0797,  -5.3136,  ...,  -5.9175,  -4.6428,  -6.6182]],\n\n        ...,\n\n        [[  6.2329,  -5.6986,  -4.4003,  ...,  -4.9978,  -5.4505,  -6.0065],\n         [  4.5816,  -3.0084,  -4.3789,  ...,  -3.6890,  -0.4907,  -4.3853],\n         [  4.2864,  -4.2727,  -3.4970,  ...,  -3.9741,  -3.0780,  -6.3296],\n         ...,\n         [  6.5369,  -4.8309,  -2.7178,  ...,  -5.2795,  -4.7246,  -5.6874],\n         [  7.1938,  -2.4227,  -3.5248,  ...,  -4.8716,  -4.8112,  -6.5379],\n         [  6.7999,  -4.8870,  -0.2368,  ...,  -5.6579,  -5.1136,  -3.9159]],\n\n        [[  4.2967,  -6.3247,  -5.5420,  ...,  -4.6959,  -4.1590,  -5.7608],\n         [  5.8049,  -3.6484,  -4.5866,  ...,  -3.8342,  -1.8794,  -5.5023],\n         [  5.3276,  -3.8784,  -3.4268,  ...,  -3.0494,  -3.3516,  -5.3999],\n         ...,\n         [  4.5262,  -5.7328,  -4.5576,  ...,  -5.2571,  -4.0224,  -4.7971],\n         [  6.1058,  -2.9771,  -4.3419,  ...,  -3.4850,  -3.5584,  -6.0711],\n         [  6.0065,  -6.8486,  -2.9187,  ...,  -5.1517,  -3.8328,  -5.4005]],\n\n        [[  6.7952,  -5.9581,  -3.8170,  ...,  -6.1306,  -3.8980,  -5.2182],\n         [  4.7843,  -4.3625,  -3.4503,  ...,  -3.0429,  -1.0069,  -5.0160],\n         [  4.7423,  -4.0734,  -2.0026,  ...,  -3.3397,  -1.5319,  -5.5408],\n         ...,\n         [  5.9233,  -6.7720,  -3.2585,  ...,  -5.0303,  -3.6403,  -6.4752],\n         [  6.4932,  -3.8687,  -2.0943,  ...,  -4.3999,  -3.3642,  -6.5363],\n         [  7.4559,  -5.1406,   0.5284,  ...,  -4.9604,  -4.5710,  -5.3826]]],\n       device='cuda:0', grad_fn=<AddBackward0>), tensor([[[-1.0254],\n         [ 0.5791],\n         [-0.6458],\n         ...,\n         [-1.2198],\n         [-2.7965],\n         [-1.1531]],\n\n        [[-1.1604],\n         [-0.9972],\n         [-2.1179],\n         ...,\n         [-0.9099],\n         [-1.0286],\n         [-3.0328]],\n\n        [[-5.0549],\n         [-3.8171],\n         [-1.7807],\n         ...,\n         [-5.8512],\n         [-3.3489],\n         [-4.7341]],\n\n        ...,\n\n        [[-1.6947],\n         [-0.4835],\n         [-4.9195],\n         ...,\n         [-3.5398],\n         [-3.4552],\n         [-3.4297]],\n\n        [[ 0.4876],\n         [-2.0698],\n         [-3.0662],\n         ...,\n         [-1.2132],\n         [-1.7824],\n         [-0.7635]],\n\n        [[ 0.7829],\n         [ 0.2189],\n         [-2.1548],\n         ...,\n         [-1.7861],\n         [-2.7979],\n         [-1.9784]]], device='cuda:0', grad_fn=<AddBackward0>), tensor([[[-3.6498, -3.4908, -3.6187,  ..., -3.5289, -3.8178, -3.6744],\n         [-3.2804, -3.1006, -3.1543,  ..., -3.0870, -3.3823, -3.2175],\n         [-3.5100, -3.3237, -3.3740,  ..., -3.3072, -3.5707, -3.4169],\n         ...,\n         [-4.1081, -4.0421, -4.0378,  ..., -3.9809, -4.1430, -4.1447],\n         [-4.1650, -4.0987, -4.1115,  ..., -4.0453, -4.2243, -4.2235],\n         [-4.1392, -4.0736, -4.0614,  ..., -3.9937, -4.1944, -4.1707]],\n\n        [[-2.3112, -2.3721, -2.2133,  ..., -2.6004, -2.6427, -2.4511],\n         [-3.4823, -3.5827, -3.4849,  ..., -3.5824, -3.7505, -3.5713],\n         [-3.5046, -3.6621, -3.5683,  ..., -3.6990, -3.8633, -3.6441],\n         ...,\n         [-3.8630, -3.8739, -3.7105,  ..., -4.0762, -4.0627, -3.8866],\n         [-3.8149, -3.8647, -3.6870,  ..., -4.0637, -4.0323, -3.8605],\n         [-4.1886, -4.2119, -4.0773,  ..., -4.4352, -4.3988, -4.2430]],\n\n        [[-1.9862, -1.7931, -1.7450,  ..., -1.8751, -2.1345, -2.0390],\n         [-1.5100, -1.3702, -1.2807,  ..., -1.4770, -1.6623, -1.6035],\n         [-1.5638, -1.4044, -1.3180,  ..., -1.5494, -1.7191, -1.6515],\n         ...,\n         [-1.8217, -1.6298, -1.5178,  ..., -1.8839, -1.9941, -1.8687],\n         [-2.0018, -1.8120, -1.7015,  ..., -2.0700, -2.1824, -2.0502],\n         [-1.9469, -1.7752, -1.6727,  ..., -2.0368, -2.1384, -1.9946]],\n\n        ...,\n\n        [[-0.7459, -0.2746, -0.5147,  ..., -0.6378, -0.9469, -0.7759],\n         [-0.9958, -0.5589, -0.7966,  ..., -0.9018, -1.2208, -1.0370],\n         [-1.0953, -0.6611, -0.8872,  ..., -0.9099, -1.3346, -1.0890],\n         ...,\n         [-1.7204, -1.1448, -1.5489,  ..., -1.9175, -1.9201, -1.9237],\n         [-1.1636, -0.6134, -0.9931,  ..., -1.3438, -1.3703, -1.3533],\n         [-1.0375, -0.4929, -0.8435,  ..., -1.2396, -1.2365, -1.2116]],\n\n        [[-2.3704, -2.1079, -2.2421,  ..., -2.4508, -2.8402, -2.6562],\n         [-3.5595, -3.2445, -3.5233,  ..., -3.5955, -3.9896, -3.7924],\n         [-4.2090, -3.8361, -4.1596,  ..., -4.1861, -4.6080, -4.4536],\n         ...,\n         [-2.9149, -2.6139, -2.8405,  ..., -3.0460, -3.2139, -3.1900],\n         [-2.9831, -2.6284, -2.8564,  ..., -3.0792, -3.2402, -3.2508],\n         [-2.7952, -2.4774, -2.7095,  ..., -2.9133, -3.0668, -3.0817]],\n\n        [[-2.1046, -1.7263, -1.9545,  ..., -2.2074, -2.3714, -2.0817],\n         [-2.8306, -2.4761, -2.6339,  ..., -2.8985, -3.0506, -2.7840],\n         [-2.7562, -2.3964, -2.5503,  ..., -2.8107, -2.9543, -2.6950],\n         ...,\n         [-2.1971, -1.8356, -2.0023,  ..., -2.3088, -2.3486, -2.1684],\n         [-2.1272, -1.7860, -1.9482,  ..., -2.2151, -2.2926, -2.0856],\n         [-1.8418, -1.4547, -1.6640,  ..., -1.9770, -1.9930, -1.8990]]],\n       device='cuda:0', grad_fn=<AddBackward0>), tensor([[[ 5.4066e-02],\n         [ 6.5631e-02],\n         [ 7.8555e-02],\n         [ 8.2301e-02],\n         [ 5.5858e-02],\n         [ 1.7058e-02],\n         [ 5.6861e-02],\n         [ 4.3544e-02],\n         [ 5.9106e-02],\n         [ 1.0269e-01],\n         [ 6.7681e-02],\n         [ 5.7432e-02],\n         [ 4.9514e-02],\n         [ 4.2039e-02],\n         [ 4.9348e-02],\n         [ 9.6293e-02],\n         [ 2.2876e-02],\n         [ 5.0893e-02],\n         [ 5.4959e-02],\n         [ 3.7836e-02],\n         [ 5.6841e-02],\n         [ 5.0191e-02],\n         [ 6.1113e-02],\n         [ 9.0875e-02]],\n\n        [[-6.7664e-02],\n         [-1.6427e-01],\n         [-1.6623e-01],\n         [-1.2173e-01],\n         [-1.8003e-01],\n         [-1.6219e-01],\n         [-1.0723e-02],\n         [-1.5421e-01],\n         [-4.9339e-02],\n         [-3.8281e-02],\n         [-1.8616e-01],\n         [ 2.1373e-01],\n         [-8.6579e-02],\n         [-9.1772e-02],\n         [-1.0777e-01],\n         [-1.2135e-01],\n         [-8.8904e-02],\n         [-1.5278e-01],\n         [-1.2438e-01],\n         [-1.0036e-01],\n         [-1.1380e-01],\n         [-9.2139e-02],\n         [-8.9316e-02],\n         [-1.1768e-01]],\n\n        [[ 6.5625e-02],\n         [ 6.0019e-02],\n         [ 5.6963e-02],\n         [ 4.7871e-02],\n         [ 1.7319e-02],\n         [ 4.6699e-02],\n         [-1.6525e-01],\n         [ 6.3119e-02],\n         [-1.7403e-02],\n         [ 8.5018e-02],\n         [ 1.1315e-01],\n         [ 1.1513e-01],\n         [ 1.0047e-01],\n         [ 9.8939e-02],\n         [ 7.9134e-02],\n         [ 1.0424e-01],\n         [ 9.2704e-02],\n         [ 1.2133e-01],\n         [ 9.9248e-02],\n         [ 4.4340e-02],\n         [ 8.7588e-02],\n         [ 1.3086e-01],\n         [ 1.1863e-01],\n         [ 9.6424e-02]],\n\n        [[ 5.2794e-02],\n         [ 1.0923e-01],\n         [ 1.1409e-01],\n         [ 7.6880e-02],\n         [ 5.6569e-02],\n         [ 6.6162e-02],\n         [ 1.1882e-01],\n         [-7.2202e-02],\n         [ 9.9407e-02],\n         [ 1.9248e-01],\n         [ 1.1154e-01],\n         [ 1.1839e-01],\n         [ 1.3504e-01],\n         [ 1.4178e-01],\n         [ 1.5760e-01],\n         [ 1.1420e-01],\n         [ 1.0585e-01],\n         [ 1.4212e-01],\n         [ 1.2363e-01],\n         [ 7.6701e-02],\n         [ 1.2803e-01],\n         [ 1.4405e-01],\n         [ 1.5990e-01],\n         [ 1.7584e-01]],\n\n        [[-1.7807e-01],\n         [-2.6471e-01],\n         [-2.6448e-01],\n         [-2.6246e-01],\n         [-1.7450e-01],\n         [-1.4318e-01],\n         [-2.0536e-01],\n         [-2.7054e-01],\n         [-2.6496e-01],\n         [ 2.3996e-02],\n         [-1.9643e-01],\n         [-1.8517e-01],\n         [-1.5990e-01],\n         [-1.4904e-01],\n         [-1.7138e-01],\n         [-1.4573e-01],\n         [-1.5216e-01],\n         [-1.3528e-01],\n         [-1.4958e-01],\n         [-1.6462e-01],\n         [-1.6598e-01],\n         [-2.1219e-01],\n         [-2.1703e-01],\n         [-1.9016e-01]],\n\n        [[-8.1026e-02],\n         [ 1.5849e-02],\n         [ 4.3204e-02],\n         [ 4.3463e-02],\n         [-9.3584e-03],\n         [ 5.5187e-03],\n         [ 3.1684e-02],\n         [ 3.5463e-02],\n         [ 3.6369e-02],\n         [ 1.6242e-02],\n         [ 2.1057e-01],\n         [ 6.2618e-02],\n         [ 4.8180e-02],\n         [ 1.1223e-01],\n         [ 8.8505e-02],\n         [ 9.5567e-02],\n         [ 6.4552e-02],\n         [ 3.1516e-02],\n         [ 1.1724e-01],\n         [ 7.3821e-02],\n         [ 4.7713e-02],\n         [ 6.2399e-02],\n         [ 7.8784e-02],\n         [ 7.6747e-02]],\n\n        [[-1.1578e-01],\n         [-1.4448e-01],\n         [-1.2108e-01],\n         [-1.1716e-01],\n         [-1.3413e-01],\n         [-6.0049e-02],\n         [-1.0755e-01],\n         [-1.5272e-01],\n         [-1.4546e-01],\n         [-2.6533e-01],\n         [-1.5269e-01],\n         [ 1.7279e-01],\n         [-1.9391e-01],\n         [-8.6409e-02],\n         [-1.7555e-01],\n         [-1.7146e-01],\n         [-1.5573e-01],\n         [-1.4953e-01],\n         [-2.7697e-02],\n         [-1.7865e-01],\n         [-1.1629e-01],\n         [-6.9994e-02],\n         [-9.2495e-02],\n         [-1.9928e-01]],\n\n        [[ 3.9459e-02],\n         [-5.4832e-02],\n         [-6.4811e-02],\n         [-8.4612e-02],\n         [-2.3616e-02],\n         [-5.4199e-02],\n         [-7.1516e-02],\n         [-4.1795e-02],\n         [-6.5328e-02],\n         [ 2.9066e-01],\n         [ 1.4585e-01],\n         [ 1.6468e-01],\n         [ 1.3082e-01],\n         [ 1.3881e-01],\n         [ 1.1905e-01],\n         [ 1.1631e-01],\n         [ 1.1235e-01],\n         [ 9.4683e-02],\n         [ 1.6876e-01],\n         [ 1.5931e-01],\n         [ 1.6417e-01],\n         [ 1.6234e-01],\n         [ 1.1294e-01],\n         [ 1.8581e-01]],\n\n        [[-6.7158e-02],\n         [-6.1223e-02],\n         [-8.2407e-02],\n         [-6.6869e-02],\n         [-5.5211e-02],\n         [ 1.2791e-02],\n         [-6.7059e-02],\n         [ 1.9043e-01],\n         [ 1.2470e-01],\n         [ 1.0622e-01],\n         [ 1.1262e-01],\n         [ 1.1784e-01],\n         [ 1.2425e-01],\n         [ 1.4761e-01],\n         [ 1.1366e-01],\n         [ 1.2769e-01],\n         [ 1.8647e-01],\n         [ 1.6956e-01],\n         [ 1.0577e-01],\n         [ 1.8000e-01],\n         [ 1.7869e-01],\n         [ 1.5395e-01],\n         [ 1.2786e-01],\n         [ 1.0609e-01]],\n\n        [[-8.6342e-02],\n         [-1.2166e-01],\n         [-2.7074e-01],\n         [-1.4543e-01],\n         [-1.5476e-01],\n         [-1.1159e-01],\n         [-8.4526e-02],\n         [-2.3460e-02],\n         [-5.5933e-02],\n         [-3.3472e-02],\n         [-1.7022e-03],\n         [-6.1379e-02],\n         [-4.8252e-02],\n         [-3.3536e-02],\n         [-4.7247e-02],\n         [ 6.0844e-02],\n         [ 3.9172e-02],\n         [-1.0941e-01],\n         [ 3.3746e-02],\n         [ 4.2120e-02],\n         [ 7.4103e-02],\n         [ 6.7480e-02],\n         [-3.9778e-02],\n         [ 4.6653e-02]],\n\n        [[ 1.1761e-04],\n         [-3.2319e-02],\n         [-8.2931e-02],\n         [-6.2712e-02],\n         [-5.5349e-02],\n         [-1.6789e-01],\n         [-5.7528e-02],\n         [-3.3631e-02],\n         [-8.9793e-02],\n         [-4.4528e-02],\n         [ 1.9845e-01],\n         [ 4.1326e-02],\n         [ 6.2142e-02],\n         [ 5.2120e-02],\n         [ 4.5284e-02],\n         [ 5.3875e-03],\n         [ 2.3621e-02],\n         [ 4.3163e-02],\n         [ 2.7918e-02],\n         [-2.7312e-03],\n         [ 2.5573e-02],\n         [ 2.2228e-02],\n         [ 2.3738e-02],\n         [ 4.5626e-02]],\n\n        [[ 1.1152e-01],\n         [ 1.1857e-01],\n         [ 1.2849e-01],\n         [ 1.0917e-01],\n         [ 9.5948e-02],\n         [ 5.3384e-02],\n         [ 1.0204e-03],\n         [ 1.0989e-01],\n         [ 6.0001e-02],\n         [ 1.5550e-01],\n         [ 1.5263e-01],\n         [ 1.9080e-01],\n         [ 1.5649e-01],\n         [ 1.7876e-01],\n         [ 1.4794e-01],\n         [ 1.8362e-01],\n         [ 3.1785e-01],\n         [ 1.4816e-01],\n         [ 1.9398e-01],\n         [ 2.9620e-01],\n         [ 1.6768e-01],\n         [ 2.6444e-01],\n         [ 1.7876e-01],\n         [ 1.6529e-01]],\n\n        [[-3.2135e-01],\n         [-2.7609e-01],\n         [-2.2708e-01],\n         [-2.7871e-01],\n         [-1.5976e-01],\n         [-1.0789e-01],\n         [-2.6115e-01],\n         [ 2.4042e-01],\n         [ 1.7649e-01],\n         [ 1.0470e-01],\n         [ 7.6834e-02],\n         [ 1.1821e-01],\n         [ 9.2225e-02],\n         [ 1.8485e-01],\n         [ 1.6472e-01],\n         [ 1.1662e-01],\n         [ 1.3644e-01],\n         [ 1.0456e-01],\n         [ 1.4690e-01],\n         [ 1.0390e-01],\n         [ 1.6453e-01],\n         [ 1.6165e-01],\n         [ 1.5546e-01],\n         [ 1.7893e-01]],\n\n        [[ 2.2485e-01],\n         [ 1.5733e-01],\n         [ 1.8498e-01],\n         [ 1.1078e-01],\n         [ 2.0727e-01],\n         [ 1.8171e-01],\n         [ 4.9812e-02],\n         [ 1.6734e-02],\n         [ 1.8851e-01],\n         [ 2.8564e-01],\n         [ 2.0382e-01],\n         [ 1.7996e-01],\n         [ 1.8341e-01],\n         [ 1.6929e-01],\n         [ 1.5521e-01],\n         [ 1.3484e-01],\n         [ 1.5028e-01],\n         [ 1.4007e-01],\n         [ 9.8987e-02],\n         [ 1.9394e-01],\n         [ 2.3100e-01],\n         [ 2.1777e-01],\n         [ 1.4207e-01],\n         [ 3.0390e-01]],\n\n        [[-2.8275e-01],\n         [-1.7993e-01],\n         [-1.3902e-01],\n         [-1.6490e-01],\n         [-1.0496e-01],\n         [-2.0422e-01],\n         [-1.8531e-01],\n         [-1.7398e-01],\n         [-2.2590e-01],\n         [-1.9143e-01],\n         [ 3.7845e-01],\n         [-1.4968e-01],\n         [-1.7335e-01],\n         [-2.0042e-01],\n         [-1.4693e-01],\n         [-1.1373e-01],\n         [-4.5550e-02],\n         [-1.5862e-01],\n         [-1.9468e-01],\n         [-9.1910e-02],\n         [-2.0067e-01],\n         [-1.8242e-01],\n         [-2.3379e-01],\n         [-2.4639e-01]],\n\n        [[ 3.5746e-02],\n         [ 1.1198e-01],\n         [ 1.5230e-01],\n         [ 2.2968e-01],\n         [ 1.2334e-01],\n         [ 7.9760e-02],\n         [ 2.4281e-02],\n         [-1.0909e-02],\n         [ 1.1329e-01],\n         [ 2.1473e-01],\n         [ 1.6258e-01],\n         [ 1.7210e-01],\n         [ 1.3568e-01],\n         [ 9.7467e-02],\n         [ 8.7748e-02],\n         [ 1.7078e-01],\n         [ 1.8598e-01],\n         [ 8.9025e-02],\n         [ 1.1402e-01],\n         [ 1.6093e-01],\n         [ 2.7516e-01],\n         [ 1.6528e-01],\n         [ 1.5849e-01],\n         [ 1.4951e-01]],\n\n        [[-6.7726e-02],\n         [-2.6111e-02],\n         [-3.7656e-02],\n         [-3.9180e-02],\n         [-2.5971e-02],\n         [-1.4467e-01],\n         [-1.0697e-02],\n         [-1.7789e-02],\n         [-8.8801e-02],\n         [-1.5108e-01],\n         [-3.3329e-02],\n         [ 2.3654e-01],\n         [ 2.0878e-02],\n         [ 2.2508e-02],\n         [ 2.8622e-02],\n         [-1.1708e-02],\n         [-4.0135e-02],\n         [ 2.9418e-02],\n         [-9.4731e-03],\n         [-2.9228e-03],\n         [-2.7782e-02],\n         [ 2.2871e-02],\n         [ 1.7818e-02],\n         [ 2.9181e-02]],\n\n        [[ 4.7783e-02],\n         [ 8.7086e-02],\n         [ 7.9555e-02],\n         [ 6.4638e-02],\n         [ 1.0188e-02],\n         [-7.4722e-03],\n         [ 7.2756e-02],\n         [ 7.3916e-02],\n         [ 7.0337e-02],\n         [ 1.6638e-01],\n         [ 9.5175e-02],\n         [ 8.1817e-02],\n         [ 1.5183e-01],\n         [ 7.3419e-02],\n         [ 1.0479e-01],\n         [ 8.2887e-02],\n         [ 6.3357e-02],\n         [ 1.0268e-01],\n         [ 1.0171e-01],\n         [ 7.6174e-02],\n         [ 8.9681e-02],\n         [ 9.0263e-02],\n         [ 7.2253e-02],\n         [ 4.0903e-02]],\n\n        [[-1.8114e-02],\n         [-3.1521e-02],\n         [-3.0011e-02],\n         [-3.3700e-02],\n         [-3.9190e-02],\n         [-7.1181e-02],\n         [-1.3108e-01],\n         [-2.4210e-02],\n         [-3.9979e-02],\n         [-5.0791e-02],\n         [-7.0238e-03],\n         [-4.6672e-02],\n         [ 3.8189e-01],\n         [-3.8349e-02],\n         [-8.6204e-02],\n         [-3.9688e-02],\n         [ 1.9305e-02],\n         [-6.7339e-02],\n         [-3.3100e-02],\n         [ 5.0904e-03],\n         [-1.5047e-02],\n         [-4.9961e-04],\n         [-1.9295e-02],\n         [-1.3981e-02]],\n\n        [[ 1.4099e-02],\n         [ 6.8466e-02],\n         [ 7.5729e-02],\n         [ 6.5672e-02],\n         [ 5.7519e-02],\n         [ 1.3579e-03],\n         [ 9.5770e-04],\n         [ 1.6213e-02],\n         [ 1.4458e-02],\n         [ 9.2938e-04],\n         [ 7.3183e-04],\n         [ 2.2929e-02],\n         [ 1.6425e-01],\n         [ 1.3149e-01],\n         [ 1.3060e-01],\n         [ 1.2997e-01],\n         [ 1.4727e-01],\n         [ 1.5043e-01],\n         [ 1.4297e-01],\n         [ 1.5185e-01],\n         [ 1.2384e-01],\n         [ 1.8071e-01],\n         [ 9.4006e-02],\n         [ 1.1730e-01]],\n\n        [[-2.9610e-01],\n         [-2.3449e-01],\n         [-2.2987e-01],\n         [-2.7641e-01],\n         [-2.4688e-01],\n         [-3.2661e-01],\n         [-2.6682e-01],\n         [-2.5042e-01],\n         [-3.3929e-01],\n         [-4.5027e-01],\n         [-2.1687e-01],\n         [-2.9021e-01],\n         [-2.4233e-01],\n         [ 2.8537e-01],\n         [-2.8036e-01],\n         [-2.9515e-01],\n         [-3.0914e-01],\n         [-3.1012e-01],\n         [-3.1859e-01],\n         [-3.0750e-01],\n         [-3.0444e-01],\n         [-2.5483e-01],\n         [-2.9749e-01],\n         [-2.7640e-01]],\n\n        [[-5.2741e-01],\n         [-4.1537e-01],\n         [-3.7248e-01],\n         [-3.3458e-01],\n         [-2.7509e-01],\n         [-3.5539e-01],\n         [-4.7727e-01],\n         [-7.2280e-01],\n         [-6.3663e-01],\n         [-6.8911e-01],\n         [-5.5427e-01],\n         [-3.6727e-01],\n         [ 1.5880e-01],\n         [-5.3511e-01],\n         [-5.0268e-01],\n         [-5.0363e-01],\n         [-3.7419e-01],\n         [-3.0913e-01],\n         [-5.0107e-01],\n         [-3.5062e-01],\n         [-5.1421e-01],\n         [-5.7398e-01],\n         [-7.1038e-01],\n         [-5.1138e-01]],\n\n        [[-4.6731e-01],\n         [-4.7546e-01],\n         [-4.7340e-01],\n         [-5.3868e-01],\n         [-4.6113e-01],\n         [-4.7867e-01],\n         [-5.9746e-01],\n         [-5.4122e-01],\n         [-5.6321e-01],\n         [-4.7033e-01],\n         [-4.6819e-01],\n         [ 7.6297e-02],\n         [-4.5826e-01],\n         [-4.3651e-01],\n         [-4.4497e-01],\n         [-4.8697e-01],\n         [-4.5469e-01],\n         [-4.2812e-01],\n         [-4.5190e-01],\n         [-4.4646e-01],\n         [-4.7458e-01],\n         [-4.2964e-01],\n         [-4.4461e-01],\n         [-4.3520e-01]],\n\n        [[ 2.3901e-02],\n         [-8.3929e-02],\n         [-5.9767e-02],\n         [-7.8982e-02],\n         [-9.1446e-02],\n         [-7.5392e-02],\n         [-8.0575e-02],\n         [-1.6147e-01],\n         [-1.3367e-01],\n         [-1.0356e-01],\n         [ 2.7246e-01],\n         [-6.2741e-02],\n         [-8.1526e-02],\n         [-8.0032e-02],\n         [-1.0672e-01],\n         [-1.1291e-01],\n         [-1.1773e-01],\n         [-1.0829e-01],\n         [-9.8497e-02],\n         [-8.1571e-02],\n         [-8.9528e-02],\n         [-5.8892e-02],\n         [-6.5702e-02],\n         [-6.0051e-02]],\n\n        [[ 4.3231e-01],\n         [ 3.1132e-01],\n         [ 3.0673e-01],\n         [ 3.0883e-01],\n         [ 3.2686e-01],\n         [ 4.0427e-01],\n         [ 2.9928e-01],\n         [ 2.4772e-01],\n         [ 2.8525e-01],\n         [ 2.3264e-01],\n         [ 3.2084e-01],\n         [ 4.6697e-01],\n         [ 3.0005e-01],\n         [ 3.2966e-01],\n         [ 3.1251e-01],\n         [ 2.9748e-01],\n         [ 2.9741e-01],\n         [ 3.1698e-01],\n         [ 3.3682e-01],\n         [ 3.0614e-01],\n         [ 2.9851e-01],\n         [ 3.3857e-01],\n         [ 3.3640e-01],\n         [ 3.2906e-01]],\n\n        [[ 3.7814e-01],\n         [ 2.7629e-01],\n         [ 2.7702e-01],\n         [ 2.7938e-01],\n         [ 3.0291e-01],\n         [ 4.2052e-01],\n         [ 3.9039e-01],\n         [ 2.7374e-01],\n         [ 2.7679e-01],\n         [ 2.8592e-01],\n         [ 3.5162e-01],\n         [ 3.4790e-01],\n         [ 3.0891e-01],\n         [ 3.0513e-01],\n         [ 3.5150e-01],\n         [ 3.5958e-01],\n         [ 4.0797e-01],\n         [ 3.0780e-01],\n         [ 3.3473e-01],\n         [ 4.5103e-01],\n         [ 3.3080e-01],\n         [ 3.7032e-01],\n         [ 3.1657e-01],\n         [ 3.1476e-01]],\n\n        [[ 2.6813e-01],\n         [ 2.0210e-01],\n         [ 2.1139e-01],\n         [ 1.7551e-01],\n         [ 1.8097e-01],\n         [ 1.8400e-01],\n         [ 1.7217e-01],\n         [ 1.8994e-01],\n         [ 4.3222e-01],\n         [ 2.5479e-01],\n         [ 2.0056e-01],\n         [ 2.4933e-01],\n         [ 2.1955e-01],\n         [ 2.4208e-01],\n         [ 1.8911e-01],\n         [ 1.9604e-01],\n         [ 1.7348e-01],\n         [ 2.9323e-01],\n         [ 2.9433e-01],\n         [ 2.2136e-01],\n         [ 3.0027e-01],\n         [ 3.0404e-01],\n         [ 3.4177e-01],\n         [ 3.1198e-01]],\n\n        [[ 3.2656e-01],\n         [ 2.8771e-01],\n         [ 2.9052e-01],\n         [ 2.7728e-01],\n         [ 4.5873e-01],\n         [ 2.4484e-01],\n         [ 2.7377e-01],\n         [ 4.9087e-01],\n         [ 3.1983e-01],\n         [ 2.7421e-01],\n         [ 2.1840e-01],\n         [ 3.6485e-01],\n         [ 5.9517e-01],\n         [ 4.3731e-01],\n         [ 5.3635e-01],\n         [ 4.7069e-01],\n         [ 4.1696e-01],\n         [ 6.4639e-01],\n         [ 4.2241e-01],\n         [ 3.5925e-01],\n         [ 3.2833e-01],\n         [ 3.7496e-01],\n         [ 3.5311e-01],\n         [ 3.7080e-01]],\n\n        [[ 8.1766e-02],\n         [-9.9239e-02],\n         [-1.4638e-01],\n         [-1.2569e-01],\n         [-3.8941e-02],\n         [-2.0013e-01],\n         [-1.3408e-01],\n         [-5.5633e-02],\n         [-7.6402e-02],\n         [-1.7483e-02],\n         [-7.9198e-02],\n         [-5.4625e-02],\n         [ 1.6237e-01],\n         [-1.0378e-01],\n         [-1.0815e-01],\n         [-9.4098e-02],\n         [-1.6403e-01],\n         [-1.1638e-01],\n         [-1.1846e-01],\n         [-1.6589e-01],\n         [-1.4727e-01],\n         [-1.1786e-01],\n         [-1.2803e-01],\n         [-9.5555e-02]],\n\n        [[ 6.6414e-01],\n         [ 6.5246e-01],\n         [ 6.4179e-01],\n         [ 5.2887e-01],\n         [ 6.3609e-01],\n         [ 6.3148e-01],\n         [ 5.5823e-01],\n         [ 6.4409e-01],\n         [ 8.3820e-02],\n         [ 5.5487e-01],\n         [ 5.5256e-01],\n         [ 5.9509e-01],\n         [ 5.1239e-01],\n         [ 5.3664e-01],\n         [ 5.0079e-01],\n         [ 5.6930e-01],\n         [ 5.5542e-01],\n         [ 5.2900e-01],\n         [ 5.4712e-01],\n         [ 5.9712e-01],\n         [ 5.5663e-01],\n         [ 6.3237e-01],\n         [ 6.4783e-01],\n         [ 5.5444e-01]]], device='cuda:0', grad_fn=<AddBackward0>), ([], [], []))\n:List trace inputs must have elements (toTypeInferredIValue at /opt/conda/conda-bld/pytorch_1579027003190/work/torch/csrc/jit/pybind_utils.h:293)\nframe #0: c10::Error::Error(c10::SourceLocation, std::string const&) + 0x47 (0x7eff980b3627 in /home/aloui/miniconda3/envs/vilbert-mt/lib/python3.6/site-packages/torch/lib/libc10.so)\nframe #1: <unknown function> + 0x6e4c9f (0x7eff8c4efc9f in /home/aloui/miniconda3/envs/vilbert-mt/lib/python3.6/site-packages/torch/lib/libtorch_python.so)\nframe #2: <unknown function> + 0x769f4b (0x7eff8c574f4b in /home/aloui/miniconda3/envs/vilbert-mt/lib/python3.6/site-packages/torch/lib/libtorch_python.so)\nframe #3: torch::jit::tracer::trace(std::vector<c10::IValue, std::allocator<c10::IValue> >, std::function<std::vector<c10::IValue, std::allocator<c10::IValue> > (std::vector<c10::IValue, std::allocator<c10::IValue> >)> const&, std::function<std::string (at::Tensor const&)>, bool, torch::jit::script::Module*) + 0x4e6 (0x7eff60d96e26 in /home/aloui/miniconda3/envs/vilbert-mt/lib/python3.6/site-packages/torch/lib/libtorch.so)\nframe #4: <unknown function> + 0x7660e1 (0x7eff8c5710e1 in /home/aloui/miniconda3/envs/vilbert-mt/lib/python3.6/site-packages/torch/lib/libtorch_python.so)\nframe #5: <unknown function> + 0x77ffb1 (0x7eff8c58afb1 in /home/aloui/miniconda3/envs/vilbert-mt/lib/python3.6/site-packages/torch/lib/libtorch_python.so)\nframe #6: <unknown function> + 0x28c076 (0x7eff8c097076 in /home/aloui/miniconda3/envs/vilbert-mt/lib/python3.6/site-packages/torch/lib/libtorch_python.so)\nframe #7: _PyCFunction_FastCallDict + 0x154 (0x55cc9ec18304 in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\nframe #8: <unknown function> + 0x199c5e (0x55cc9ec9fc5e in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\nframe #9: _PyEval_EvalFrameDefault + 0x30a (0x55cc9ecc281a in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\nframe #10: <unknown function> + 0x19335e (0x55cc9ec9935e in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\nframe #11: <unknown function> + 0x193f31 (0x55cc9ec99f31 in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\nframe #12: <unknown function> + 0x199be5 (0x55cc9ec9fbe5 in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\nframe #13: _PyEval_EvalFrameDefault + 0x30a (0x55cc9ecc281a in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\nframe #14: <unknown function> + 0x192f26 (0x55cc9ec98f26 in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\nframe #15: <unknown function> + 0x193f31 (0x55cc9ec99f31 in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\nframe #16: <unknown function> + 0x199be5 (0x55cc9ec9fbe5 in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\nframe #17: _PyEval_EvalFrameDefault + 0x30a (0x55cc9ecc281a in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\nframe #18: <unknown function> + 0x192f26 (0x55cc9ec98f26 in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\nframe #19: <unknown function> + 0x193f31 (0x55cc9ec99f31 in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\nframe #20: <unknown function> + 0x199be5 (0x55cc9ec9fbe5 in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\nframe #21: _PyEval_EvalFrameDefault + 0x30a (0x55cc9ecc281a in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\nframe #22: <unknown function> + 0x192f26 (0x55cc9ec98f26 in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\nframe #23: <unknown function> + 0x193f31 (0x55cc9ec99f31 in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\nframe #24: <unknown function> + 0x199be5 (0x55cc9ec9fbe5 in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\nframe #25: _PyEval_EvalFrameDefault + 0x10c9 (0x55cc9ecc35d9 in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\nframe #26: PyEval_EvalCodeEx + 0x329 (0x55cc9ec9aa49 in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\nframe #27: PyEval_EvalCode + 0x1c (0x55cc9ec9b7ec in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\nframe #28: <unknown function> + 0x1ba227 (0x55cc9ecc0227 in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\nframe #29: _PyCFunction_FastCallDict + 0x91 (0x55cc9ec18241 in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\nframe #30: <unknown function> + 0x199b0c (0x55cc9ec9fb0c in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\nframe #31: _PyEval_EvalFrameDefault + 0x30a (0x55cc9ecc281a in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\nframe #32: _PyGen_Send + 0x256 (0x55cc9eca2bc6 in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\nframe #33: _PyEval_EvalFrameDefault + 0x1445 (0x55cc9ecc3955 in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\nframe #34: _PyGen_Send + 0x256 (0x55cc9eca2bc6 in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\nframe #35: _PyEval_EvalFrameDefault + 0x1445 (0x55cc9ecc3955 in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\nframe #36: _PyGen_Send + 0x256 (0x55cc9eca2bc6 in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\nframe #37: _PyCFunction_FastCallDict + 0x115 (0x55cc9ec182c5 in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\nframe #38: <unknown function> + 0x199b0c (0x55cc9ec9fb0c in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\nframe #39: _PyEval_EvalFrameDefault + 0x30a (0x55cc9ecc281a in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\nframe #40: <unknown function> + 0x193cfb (0x55cc9ec99cfb in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\nframe #41: <unknown function> + 0x199be5 (0x55cc9ec9fbe5 in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\nframe #42: _PyEval_EvalFrameDefault + 0x30a (0x55cc9ecc281a in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\nframe #43: <unknown function> + 0x193cfb (0x55cc9ec99cfb in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\nframe #44: <unknown function> + 0x199be5 (0x55cc9ec9fbe5 in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\nframe #45: _PyEval_EvalFrameDefault + 0x30a (0x55cc9ecc281a in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\nframe #46: <unknown function> + 0x192f26 (0x55cc9ec98f26 in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\nframe #47: _PyFunction_FastCallDict + 0x3d8 (0x55cc9ec9a628 in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\nframe #48: _PyObject_FastCallDict + 0x26f (0x55cc9ec186cf in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\nframe #49: _PyObject_Call_Prepend + 0x63 (0x55cc9ec1d143 in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\nframe #50: PyObject_Call + 0x3e (0x55cc9ec1810e in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\nframe #51: _PyEval_EvalFrameDefault + 0x1aaf (0x55cc9ecc3fbf in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\nframe #52: <unknown function> + 0x1931f6 (0x55cc9ec991f6 in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\nframe #53: <unknown function> + 0x193f31 (0x55cc9ec99f31 in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\nframe #54: <unknown function> + 0x199be5 (0x55cc9ec9fbe5 in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\nframe #55: _PyEval_EvalFrameDefault + 0x10c9 (0x55cc9ecc35d9 in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\nframe #56: <unknown function> + 0x19c744 (0x55cc9eca2744 in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\nframe #57: _PyCFunction_FastCallDict + 0x91 (0x55cc9ec18241 in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\nframe #58: <unknown function> + 0x199b0c (0x55cc9ec9fb0c in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\nframe #59: _PyEval_EvalFrameDefault + 0x30a (0x55cc9ecc281a in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\nframe #60: <unknown function> + 0x1931f6 (0x55cc9ec991f6 in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\nframe #61: <unknown function> + 0x193f31 (0x55cc9ec99f31 in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\nframe #62: <unknown function> + 0x199be5 (0x55cc9ec9fbe5 in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\nframe #63: _PyEval_EvalFrameDefault + 0x30a (0x55cc9ecc281a in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\n"
     ]
    }
   ],
   "source": [
    "writer = SummaryWriter(logdir='results/runs')\n",
    "input_ = (question, features, spatials, segment_ids, input_mask, image_mask, co_attention_mask, task_tokens)\n",
    "writer.add_graph(model, input_to_model=input_, verbose=True)\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method add_graph in module tensorboardX.writer:\n",
      "\n",
      "add_graph(model, input_to_model=None, verbose=False) method of tensorboardX.writer.SummaryWriter instance\n",
      "    Add graph data to summary. The graph is actually processed by `torch.utils.tensorboard.add_graph()`\n",
      "    \n",
      "    Args:\n",
      "        model (torch.nn.Module): Model to draw.\n",
      "        input_to_model (torch.Tensor or list of torch.Tensor): A variable or a tuple of\n",
      "            variables to be fed.\n",
      "        verbose (bool): Whether to print graph structure in console.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(writer.add_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VILBertForVLTasks(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (task_embeddings): Embedding(20, 768)\n",
       "    )\n",
       "    (v_embeddings): BertImageEmbeddings(\n",
       "      (image_embeddings): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "      (image_location_embeddings): Linear(in_features=5, out_features=1024, bias=True)\n",
       "      (LayerNorm): FusedLayerNorm(torch.Size([1024]), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (v_layer): ModuleList(\n",
       "        (0): BertImageLayer(\n",
       "          (attention): BertImageAttention(\n",
       "            (self): BertImageSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertImageSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): FusedLayerNorm(torch.Size([1024]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertImageIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (output): BertImageOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([1024]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertImageLayer(\n",
       "          (attention): BertImageAttention(\n",
       "            (self): BertImageSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertImageSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): FusedLayerNorm(torch.Size([1024]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertImageIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (output): BertImageOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([1024]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertImageLayer(\n",
       "          (attention): BertImageAttention(\n",
       "            (self): BertImageSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertImageSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): FusedLayerNorm(torch.Size([1024]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertImageIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (output): BertImageOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([1024]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertImageLayer(\n",
       "          (attention): BertImageAttention(\n",
       "            (self): BertImageSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertImageSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): FusedLayerNorm(torch.Size([1024]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertImageIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (output): BertImageOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([1024]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertImageLayer(\n",
       "          (attention): BertImageAttention(\n",
       "            (self): BertImageSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertImageSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): FusedLayerNorm(torch.Size([1024]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertImageIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (output): BertImageOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([1024]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertImageLayer(\n",
       "          (attention): BertImageAttention(\n",
       "            (self): BertImageSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertImageSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): FusedLayerNorm(torch.Size([1024]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertImageIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (output): BertImageOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([1024]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (c_layer): ModuleList(\n",
       "        (0): BertConnectionLayer(\n",
       "          (biattention): BertBiAttention(\n",
       "            (query1): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (key1): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (value1): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (dropout1): Dropout(p=0.1, inplace=False)\n",
       "            (query2): Linear(in_features=768, out_features=1024, bias=True)\n",
       "            (key2): Linear(in_features=768, out_features=1024, bias=True)\n",
       "            (value2): Linear(in_features=768, out_features=1024, bias=True)\n",
       "            (dropout2): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (biOutput): BertBiOutput(\n",
       "            (dense1): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm1): FusedLayerNorm(torch.Size([1024]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout1): Dropout(p=0.1, inplace=False)\n",
       "            (q_dense1): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_dropout1): Dropout(p=0.1, inplace=False)\n",
       "            (dense2): Linear(in_features=1024, out_features=768, bias=True)\n",
       "            (LayerNorm2): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout2): Dropout(p=0.1, inplace=False)\n",
       "            (q_dense2): Linear(in_features=1024, out_features=768, bias=True)\n",
       "            (q_dropout2): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (v_intermediate): BertImageIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (v_output): BertImageOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([1024]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (t_intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (t_output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertConnectionLayer(\n",
       "          (biattention): BertBiAttention(\n",
       "            (query1): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (key1): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (value1): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (dropout1): Dropout(p=0.1, inplace=False)\n",
       "            (query2): Linear(in_features=768, out_features=1024, bias=True)\n",
       "            (key2): Linear(in_features=768, out_features=1024, bias=True)\n",
       "            (value2): Linear(in_features=768, out_features=1024, bias=True)\n",
       "            (dropout2): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (biOutput): BertBiOutput(\n",
       "            (dense1): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm1): FusedLayerNorm(torch.Size([1024]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout1): Dropout(p=0.1, inplace=False)\n",
       "            (q_dense1): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_dropout1): Dropout(p=0.1, inplace=False)\n",
       "            (dense2): Linear(in_features=1024, out_features=768, bias=True)\n",
       "            (LayerNorm2): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout2): Dropout(p=0.1, inplace=False)\n",
       "            (q_dense2): Linear(in_features=1024, out_features=768, bias=True)\n",
       "            (q_dropout2): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (v_intermediate): BertImageIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (v_output): BertImageOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([1024]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (t_intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (t_output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertConnectionLayer(\n",
       "          (biattention): BertBiAttention(\n",
       "            (query1): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (key1): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (value1): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (dropout1): Dropout(p=0.1, inplace=False)\n",
       "            (query2): Linear(in_features=768, out_features=1024, bias=True)\n",
       "            (key2): Linear(in_features=768, out_features=1024, bias=True)\n",
       "            (value2): Linear(in_features=768, out_features=1024, bias=True)\n",
       "            (dropout2): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (biOutput): BertBiOutput(\n",
       "            (dense1): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm1): FusedLayerNorm(torch.Size([1024]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout1): Dropout(p=0.1, inplace=False)\n",
       "            (q_dense1): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_dropout1): Dropout(p=0.1, inplace=False)\n",
       "            (dense2): Linear(in_features=1024, out_features=768, bias=True)\n",
       "            (LayerNorm2): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout2): Dropout(p=0.1, inplace=False)\n",
       "            (q_dense2): Linear(in_features=1024, out_features=768, bias=True)\n",
       "            (q_dropout2): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (v_intermediate): BertImageIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (v_output): BertImageOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([1024]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (t_intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (t_output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertConnectionLayer(\n",
       "          (biattention): BertBiAttention(\n",
       "            (query1): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (key1): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (value1): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (dropout1): Dropout(p=0.1, inplace=False)\n",
       "            (query2): Linear(in_features=768, out_features=1024, bias=True)\n",
       "            (key2): Linear(in_features=768, out_features=1024, bias=True)\n",
       "            (value2): Linear(in_features=768, out_features=1024, bias=True)\n",
       "            (dropout2): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (biOutput): BertBiOutput(\n",
       "            (dense1): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm1): FusedLayerNorm(torch.Size([1024]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout1): Dropout(p=0.1, inplace=False)\n",
       "            (q_dense1): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_dropout1): Dropout(p=0.1, inplace=False)\n",
       "            (dense2): Linear(in_features=1024, out_features=768, bias=True)\n",
       "            (LayerNorm2): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout2): Dropout(p=0.1, inplace=False)\n",
       "            (q_dense2): Linear(in_features=1024, out_features=768, bias=True)\n",
       "            (q_dropout2): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (v_intermediate): BertImageIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (v_output): BertImageOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([1024]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (t_intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (t_output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertConnectionLayer(\n",
       "          (biattention): BertBiAttention(\n",
       "            (query1): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (key1): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (value1): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (dropout1): Dropout(p=0.1, inplace=False)\n",
       "            (query2): Linear(in_features=768, out_features=1024, bias=True)\n",
       "            (key2): Linear(in_features=768, out_features=1024, bias=True)\n",
       "            (value2): Linear(in_features=768, out_features=1024, bias=True)\n",
       "            (dropout2): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (biOutput): BertBiOutput(\n",
       "            (dense1): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm1): FusedLayerNorm(torch.Size([1024]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout1): Dropout(p=0.1, inplace=False)\n",
       "            (q_dense1): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_dropout1): Dropout(p=0.1, inplace=False)\n",
       "            (dense2): Linear(in_features=1024, out_features=768, bias=True)\n",
       "            (LayerNorm2): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout2): Dropout(p=0.1, inplace=False)\n",
       "            (q_dense2): Linear(in_features=1024, out_features=768, bias=True)\n",
       "            (q_dropout2): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (v_intermediate): BertImageIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (v_output): BertImageOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([1024]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (t_intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (t_output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertConnectionLayer(\n",
       "          (biattention): BertBiAttention(\n",
       "            (query1): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (key1): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (value1): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (dropout1): Dropout(p=0.1, inplace=False)\n",
       "            (query2): Linear(in_features=768, out_features=1024, bias=True)\n",
       "            (key2): Linear(in_features=768, out_features=1024, bias=True)\n",
       "            (value2): Linear(in_features=768, out_features=1024, bias=True)\n",
       "            (dropout2): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (biOutput): BertBiOutput(\n",
       "            (dense1): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm1): FusedLayerNorm(torch.Size([1024]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout1): Dropout(p=0.1, inplace=False)\n",
       "            (q_dense1): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_dropout1): Dropout(p=0.1, inplace=False)\n",
       "            (dense2): Linear(in_features=1024, out_features=768, bias=True)\n",
       "            (LayerNorm2): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout2): Dropout(p=0.1, inplace=False)\n",
       "            (q_dense2): Linear(in_features=1024, out_features=768, bias=True)\n",
       "            (q_dropout2): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (v_intermediate): BertImageIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (v_output): BertImageOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([1024]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (t_intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (t_output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (t_pooler): BertTextPooler(\n",
       "      (dense): Linear(in_features=768, out_features=1024, bias=True)\n",
       "      (activation): ReLU()\n",
       "    )\n",
       "    (v_pooler): BertImagePooler(\n",
       "      (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      (activation): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (cls): BertPreTrainingHeads(\n",
       "    (predictions): BertLMPredictionHead(\n",
       "      (transform): BertPredictionHeadTransform(\n",
       "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "      )\n",
       "      (decoder): Linear(in_features=768, out_features=30522, bias=False)\n",
       "    )\n",
       "    (bi_seq_relationship): Linear(in_features=1024, out_features=2, bias=True)\n",
       "    (imagePredictions): BertImagePredictionHead(\n",
       "      (transform): BertImgPredictionHeadTransform(\n",
       "        (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (LayerNorm): FusedLayerNorm(torch.Size([1024]), eps=1e-12, elementwise_affine=True)\n",
       "      )\n",
       "      (decoder): Linear(in_features=1024, out_features=1601, bias=True)\n",
       "    )\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (vil_prediction): SimpleClassifier(\n",
       "    (logit_fc): Sequential(\n",
       "      (0): Linear(in_features=1024, out_features=2048, bias=True)\n",
       "      (1): GeLU()\n",
       "      (2): FusedLayerNorm(torch.Size([2048]), eps=1e-12, elementwise_affine=True)\n",
       "      (3): Linear(in_features=2048, out_features=3129, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (vil_prediction_gqa): SimpleClassifier(\n",
       "    (logit_fc): Sequential(\n",
       "      (0): Linear(in_features=1024, out_features=2048, bias=True)\n",
       "      (1): GeLU()\n",
       "      (2): FusedLayerNorm(torch.Size([2048]), eps=1e-12, elementwise_affine=True)\n",
       "      (3): Linear(in_features=2048, out_features=1533, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (vil_binary_prediction): SimpleClassifier(\n",
       "    (logit_fc): Sequential(\n",
       "      (0): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "      (1): GeLU()\n",
       "      (2): FusedLayerNorm(torch.Size([2048]), eps=1e-12, elementwise_affine=True)\n",
       "      (3): Linear(in_features=2048, out_features=2, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (vil_logit): Linear(in_features=1024, out_features=1, bias=True)\n",
       "  (vil_tri_prediction): Linear(in_features=1024, out_features=3, bias=True)\n",
       "  (vision_logit): Linear(in_features=1024, out_features=1, bias=True)\n",
       "  (linguisic_logit): Linear(in_features=768, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(10.9015, device='cuda:0', grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vil_prediction[0][2969]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2969, 2785, 2293,  878,   89, 2621, 2134, 2621, 1403,  425, 1027,  411,\n",
       "         425, 1403,  444, 1076, 2218, 2621,  402, 2621, 1136,  425,  711, 2785,\n",
       "        2681, 2681,  990,  425, 1684, 2594], device='cuda:0')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1., device='cuda:0')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hots[0][2969]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([30, 3129])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import _pickle as cPickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "targ = cPickle.load(open('datasets/VQA/cache/train_target.pkl', \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'image_id': 458752,\n",
       "  'labels': [1164],\n",
       "  'scores': [1],\n",
       "  'question_id': 458752000},\n",
       " {'image_id': 458752,\n",
       "  'labels': [1840, 290],\n",
       "  'scores': [0.3, 1],\n",
       "  'question_id': 458752001},\n",
       " {'image_id': 458752,\n",
       "  'labels': [1491],\n",
       "  'scores': [1],\n",
       "  'question_id': 458752002},\n",
       " {'image_id': 458752,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [1, 0.3],\n",
       "  'question_id': 458752003},\n",
       " {'image_id': 262146,\n",
       "  'labels': [3006],\n",
       "  'scores': [1],\n",
       "  'question_id': 262146000},\n",
       " {'image_id': 262146,\n",
       "  'labels': [1561],\n",
       "  'scores': [1],\n",
       "  'question_id': 262146001},\n",
       " {'image_id': 262146,\n",
       "  'labels': [2241, 1227, 1333],\n",
       "  'scores': [0.3, 0.3, 1],\n",
       "  'question_id': 262146002},\n",
       " {'image_id': 524291,\n",
       "  'labels': [1712],\n",
       "  'scores': [1],\n",
       "  'question_id': 524291000},\n",
       " {'image_id': 524291,\n",
       "  'labels': [425],\n",
       "  'scores': [1],\n",
       "  'question_id': 524291001},\n",
       " {'image_id': 524291,\n",
       "  'labels': [1712],\n",
       "  'scores': [1],\n",
       "  'question_id': 524291002},\n",
       " {'image_id': 393221,\n",
       "  'labels': [425],\n",
       "  'scores': [1],\n",
       "  'question_id': 393221000},\n",
       " {'image_id': 393221,\n",
       "  'labels': [425],\n",
       "  'scores': [1],\n",
       "  'question_id': 393221001},\n",
       " {'image_id': 393221,\n",
       "  'labels': [2154, 1448],\n",
       "  'scores': [0.3, 0.3],\n",
       "  'question_id': 393221002},\n",
       " {'image_id': 393223,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [1, 0.6],\n",
       "  'question_id': 393223000},\n",
       " {'image_id': 393223,\n",
       "  'labels': [3006, 2183],\n",
       "  'scores': [0.9, 0.3],\n",
       "  'question_id': 393223001},\n",
       " {'image_id': 393223,\n",
       "  'labels': [75, 2966, 2360],\n",
       "  'scores': [0.3, 0.3, 1],\n",
       "  'question_id': 393223002},\n",
       " {'image_id': 393223,\n",
       "  'labels': [425],\n",
       "  'scores': [1],\n",
       "  'question_id': 393223003},\n",
       " {'image_id': 393224,\n",
       "  'labels': [1403],\n",
       "  'scores': [1],\n",
       "  'question_id': 393224000},\n",
       " {'image_id': 393224,\n",
       "  'labels': [931, 1954, 735, 3079],\n",
       "  'scores': [0.3, 0.6, 0.3, 0.3],\n",
       "  'question_id': 393224001},\n",
       " {'image_id': 393224,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [0.9, 1],\n",
       "  'question_id': 393224002},\n",
       " {'image_id': 393224,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [0.3, 1],\n",
       "  'question_id': 393224003},\n",
       " {'image_id': 393224,\n",
       "  'labels': [1403],\n",
       "  'scores': [1],\n",
       "  'question_id': 393224004},\n",
       " {'image_id': 393224,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [0.3, 1],\n",
       "  'question_id': 393224005},\n",
       " {'image_id': 524297,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [1, 0.9],\n",
       "  'question_id': 524297000},\n",
       " {'image_id': 524297,\n",
       "  'labels': [1086, 1851, 2324],\n",
       "  'scores': [0.3, 0.3, 1],\n",
       "  'question_id': 524297001},\n",
       " {'image_id': 524297,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [0.3, 1],\n",
       "  'question_id': 524297002},\n",
       " {'image_id': 524297,\n",
       "  'labels': [1403],\n",
       "  'scores': [1],\n",
       "  'question_id': 524297003},\n",
       " {'image_id': 393227,\n",
       "  'labels': [425],\n",
       "  'scores': [1],\n",
       "  'question_id': 393227000},\n",
       " {'image_id': 393227,\n",
       "  'labels': [547],\n",
       "  'scores': [1],\n",
       "  'question_id': 393227001},\n",
       " {'image_id': 393227,\n",
       "  'labels': [2195, 2621, 841],\n",
       "  'scores': [1, 0.3, 0.3],\n",
       "  'question_id': 393227002},\n",
       " {'image_id': 393227,\n",
       "  'labels': [411, 545],\n",
       "  'scores': [1, 0.3],\n",
       "  'question_id': 393227003},\n",
       " {'image_id': 393227,\n",
       "  'labels': [1403],\n",
       "  'scores': [1],\n",
       "  'question_id': 393227004},\n",
       " {'image_id': 131084,\n",
       "  'labels': [2852, 990],\n",
       "  'scores': [0.9, 1],\n",
       "  'question_id': 131084000},\n",
       " {'image_id': 131084,\n",
       "  'labels': [425],\n",
       "  'scores': [1],\n",
       "  'question_id': 131084001},\n",
       " {'image_id': 131084,\n",
       "  'labels': [2062, 746, 2514],\n",
       "  'scores': [0.9, 0.6, 1],\n",
       "  'question_id': 131084002},\n",
       " {'image_id': 131074,\n",
       "  'labels': [1880, 905, 103, 2274, 1566],\n",
       "  'scores': [0.3, 0.3, 0.3, 0.3, 0.3],\n",
       "  'question_id': 131074000},\n",
       " {'image_id': 131074,\n",
       "  'labels': [841],\n",
       "  'scores': [1],\n",
       "  'question_id': 131074001},\n",
       " {'image_id': 131074,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [1, 0.9],\n",
       "  'question_id': 131074002},\n",
       " {'image_id': 131074,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [0.9, 1],\n",
       "  'question_id': 131074003},\n",
       " {'image_id': 131074,\n",
       "  'labels': [1601],\n",
       "  'scores': [1],\n",
       "  'question_id': 131074004},\n",
       " {'image_id': 131074,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [1, 0.6],\n",
       "  'question_id': 131074005},\n",
       " {'image_id': 393230,\n",
       "  'labels': [1561],\n",
       "  'scores': [1],\n",
       "  'question_id': 393230000},\n",
       " {'image_id': 393230,\n",
       "  'labels': [2195],\n",
       "  'scores': [1],\n",
       "  'question_id': 393230001},\n",
       " {'image_id': 393230,\n",
       "  'labels': [1403],\n",
       "  'scores': [1],\n",
       "  'question_id': 393230002},\n",
       " {'image_id': 393230,\n",
       "  'labels': [1561],\n",
       "  'scores': [1],\n",
       "  'question_id': 393230003},\n",
       " {'image_id': 393230,\n",
       "  'labels': [1880, 337],\n",
       "  'scores': [1, 0.3],\n",
       "  'question_id': 393230004},\n",
       " {'image_id': 393230,\n",
       "  'labels': [1434, 1198, 2423, 1162],\n",
       "  'scores': [0.3, 0.6, 0.3, 0.6],\n",
       "  'question_id': 393230005},\n",
       " {'image_id': 393230,\n",
       "  'labels': [1403],\n",
       "  'scores': [1],\n",
       "  'question_id': 393230006},\n",
       " {'image_id': 393230,\n",
       "  'labels': [411, 337],\n",
       "  'scores': [1, 0.3],\n",
       "  'question_id': 393230007},\n",
       " {'image_id': 393230,\n",
       "  'labels': [425],\n",
       "  'scores': [1],\n",
       "  'question_id': 393230008},\n",
       " {'image_id': 393230,\n",
       "  'labels': [1198, 2806, 2692, 1429, 1008],\n",
       "  'scores': [0.3, 0.6, 1, 0.3, 0.3],\n",
       "  'question_id': 393230009},\n",
       " {'image_id': 393230,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [1, 1],\n",
       "  'question_id': 393230010},\n",
       " {'image_id': 131087,\n",
       "  'labels': [51, 689],\n",
       "  'scores': [0.3, 1],\n",
       "  'question_id': 131087000},\n",
       " {'image_id': 131087,\n",
       "  'labels': [425],\n",
       "  'scores': [1],\n",
       "  'question_id': 131087001},\n",
       " {'image_id': 131087,\n",
       "  'labels': [425],\n",
       "  'scores': [1],\n",
       "  'question_id': 131087002},\n",
       " {'image_id': 131087,\n",
       "  'labels': [425],\n",
       "  'scores': [1],\n",
       "  'question_id': 131087003},\n",
       " {'image_id': 131087,\n",
       "  'labels': [1930, 689],\n",
       "  'scores': [0.9, 0.6],\n",
       "  'question_id': 131087004},\n",
       " {'image_id': 131075,\n",
       "  'labels': [2507, 175, 2437, 2786],\n",
       "  'scores': [0.6, 0.3, 0.3, 0.6],\n",
       "  'question_id': 131075000},\n",
       " {'image_id': 131075,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [0.3, 1],\n",
       "  'question_id': 131075001},\n",
       " {'image_id': 131075,\n",
       "  'labels': [275, 2551, 2875, 2522, 963],\n",
       "  'scores': [0.6, 1, 0.3, 0.3, 0.3],\n",
       "  'question_id': 131075002},\n",
       " {'image_id': 131075,\n",
       "  'labels': [2094, 1616, 2679],\n",
       "  'scores': [0.3, 0.6, 0.3],\n",
       "  'question_id': 131075003},\n",
       " {'image_id': 131075,\n",
       "  'labels': [1403],\n",
       "  'scores': [1],\n",
       "  'question_id': 131075004},\n",
       " {'image_id': 131075,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [1, 1],\n",
       "  'question_id': 131075005},\n",
       " {'image_id': 131075,\n",
       "  'labels': [517, 1076, 2875, 1616],\n",
       "  'scores': [1, 0.3, 0.3, 0.3],\n",
       "  'question_id': 131075006},\n",
       " {'image_id': 131075,\n",
       "  'labels': [2973, 2723, 1255],\n",
       "  'scores': [1, 0.6, 0.6],\n",
       "  'question_id': 131075007},\n",
       " {'image_id': 131075,\n",
       "  'labels': [2973],\n",
       "  'scores': [1],\n",
       "  'question_id': 131075008},\n",
       " {'image_id': 131075,\n",
       "  'labels': [2918, 1375, 1932],\n",
       "  'scores': [1, 1, 0.3],\n",
       "  'question_id': 131075009},\n",
       " {'image_id': 131075,\n",
       "  'labels': [1938],\n",
       "  'scores': [0.3],\n",
       "  'question_id': 131075010},\n",
       " {'image_id': 131075,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [1, 0.6],\n",
       "  'question_id': 131075011},\n",
       " {'image_id': 131075,\n",
       "  'labels': [425, 458],\n",
       "  'scores': [0.3, 0.6],\n",
       "  'question_id': 131075012},\n",
       " {'image_id': 131075,\n",
       "  'labels': [1060, 2723],\n",
       "  'scores': [0.3, 0.6],\n",
       "  'question_id': 131075013},\n",
       " {'image_id': 131075,\n",
       "  'labels': [1906, 2634, 750, 1444],\n",
       "  'scores': [0.3, 0.3, 0.3, 0.3],\n",
       "  'question_id': 131075014},\n",
       " {'image_id': 137045,\n",
       "  'labels': [1227],\n",
       "  'scores': [1],\n",
       "  'question_id': 137045000},\n",
       " {'image_id': 137045,\n",
       "  'labels': [425],\n",
       "  'scores': [1],\n",
       "  'question_id': 137045001},\n",
       " {'image_id': 137045,\n",
       "  'labels': [2914],\n",
       "  'scores': [1],\n",
       "  'question_id': 137045002},\n",
       " {'image_id': 131093,\n",
       "  'labels': [425],\n",
       "  'scores': [1],\n",
       "  'question_id': 131093000},\n",
       " {'image_id': 131093,\n",
       "  'labels': [444, 1403],\n",
       "  'scores': [0.3, 1],\n",
       "  'question_id': 131093001},\n",
       " {'image_id': 131093,\n",
       "  'labels': [444, 2621],\n",
       "  'scores': [0.3, 1],\n",
       "  'question_id': 131093002},\n",
       " {'image_id': 131093,\n",
       "  'labels': [425],\n",
       "  'scores': [1],\n",
       "  'question_id': 131093003},\n",
       " {'image_id': 524311,\n",
       "  'labels': [1848, 1863],\n",
       "  'scores': [0.3, 1],\n",
       "  'question_id': 524311000},\n",
       " {'image_id': 524311,\n",
       "  'labels': [425],\n",
       "  'scores': [1],\n",
       "  'question_id': 524311001},\n",
       " {'image_id': 524311,\n",
       "  'labels': [2447, 2339, 149],\n",
       "  'scores': [0.3, 0.3, 1],\n",
       "  'question_id': 524311002},\n",
       " {'image_id': 25,\n",
       "  'labels': [1539, 1095],\n",
       "  'scores': [1, 0.6],\n",
       "  'question_id': 25000},\n",
       " {'image_id': 25,\n",
       "  'labels': [2681, 2541, 1970],\n",
       "  'scores': [1, 0.3, 0.3],\n",
       "  'question_id': 25001},\n",
       " {'image_id': 25, 'labels': [425], 'scores': [1], 'question_id': 25002},\n",
       " {'image_id': 25, 'labels': [425], 'scores': [1], 'question_id': 25003},\n",
       " {'image_id': 25,\n",
       "  'labels': [492, 60, 2210, 425],\n",
       "  'scores': [0.3, 0.3, 0.3, 0.3],\n",
       "  'question_id': 25004},\n",
       " {'image_id': 25, 'labels': [1403], 'scores': [1], 'question_id': 25005},\n",
       " {'image_id': 25,\n",
       "  'labels': [1539, 1803, 1095],\n",
       "  'scores': [1, 0.9, 0.3],\n",
       "  'question_id': 25006},\n",
       " {'image_id': 25,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [1, 0.6],\n",
       "  'question_id': 25007},\n",
       " {'image_id': 25,\n",
       "  'labels': [425, 841, 1403],\n",
       "  'scores': [0.9, 0.3, 1],\n",
       "  'question_id': 25008},\n",
       " {'image_id': 25,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [1, 1],\n",
       "  'question_id': 25009},\n",
       " {'image_id': 25,\n",
       "  'labels': [1539, 1803, 1095],\n",
       "  'scores': [0.6, 1, 0.3],\n",
       "  'question_id': 25010},\n",
       " {'image_id': 25,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [1, 0.3],\n",
       "  'question_id': 25011},\n",
       " {'image_id': 25,\n",
       "  'labels': [2195, 425],\n",
       "  'scores': [0.3, 1],\n",
       "  'question_id': 25012},\n",
       " {'image_id': 25, 'labels': [1403], 'scores': [1], 'question_id': 25013},\n",
       " {'image_id': 25,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [1, 1],\n",
       "  'question_id': 25014},\n",
       " {'image_id': 25,\n",
       "  'labels': [2195, 841],\n",
       "  'scores': [0.6, 1],\n",
       "  'question_id': 25015},\n",
       " {'image_id': 25, 'labels': [1403], 'scores': [1], 'question_id': 25016},\n",
       " {'image_id': 25,\n",
       "  'labels': [841, 991],\n",
       "  'scores': [1, 0.3],\n",
       "  'question_id': 25017},\n",
       " {'image_id': 524314,\n",
       "  'labels': [490, 1645],\n",
       "  'scores': [0.3, 0.3],\n",
       "  'question_id': 524314000},\n",
       " {'image_id': 524314, 'labels': [], 'scores': [], 'question_id': 524314001},\n",
       " {'image_id': 524314, 'labels': [], 'scores': [], 'question_id': 524314002},\n",
       " {'image_id': 262171,\n",
       "  'labels': [703, 3031, 311, 1618],\n",
       "  'scores': [0.3, 1, 0.3, 0.9],\n",
       "  'question_id': 262171000},\n",
       " {'image_id': 262171,\n",
       "  'labels': [990],\n",
       "  'scores': [1],\n",
       "  'question_id': 262171001},\n",
       " {'image_id': 262171,\n",
       "  'labels': [2033, 2428],\n",
       "  'scores': [1, 0.9],\n",
       "  'question_id': 262171002},\n",
       " {'image_id': 262172,\n",
       "  'labels': [876, 425, 2785],\n",
       "  'scores': [0.3, 0.3, 0.6],\n",
       "  'question_id': 262172000},\n",
       " {'image_id': 262172,\n",
       "  'labels': [275],\n",
       "  'scores': [1],\n",
       "  'question_id': 262172001},\n",
       " {'image_id': 262172,\n",
       "  'labels': [425],\n",
       "  'scores': [1],\n",
       "  'question_id': 262172002},\n",
       " {'image_id': 131101,\n",
       "  'labels': [1204, 1333, 1559],\n",
       "  'scores': [1, 0.3, 0.9],\n",
       "  'question_id': 131101000},\n",
       " {'image_id': 131101,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [0.6, 1],\n",
       "  'question_id': 131101001},\n",
       " {'image_id': 131101,\n",
       "  'labels': [2387],\n",
       "  'scores': [1],\n",
       "  'question_id': 131101002},\n",
       " {'image_id': 30, 'labels': [425], 'scores': [1], 'question_id': 30000},\n",
       " {'image_id': 30,\n",
       "  'labels': [2643, 2325, 2343],\n",
       "  'scores': [0.3, 0.3, 0.9],\n",
       "  'question_id': 30001},\n",
       " {'image_id': 30,\n",
       "  'labels': [2387, 949, 1403, 2785],\n",
       "  'scores': [0.6, 0.3, 0.3, 1],\n",
       "  'question_id': 30002},\n",
       " {'image_id': 30,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [1, 1],\n",
       "  'question_id': 30003},\n",
       " {'image_id': 30, 'labels': [3006], 'scores': [1], 'question_id': 30004},\n",
       " {'image_id': 30,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [0.3, 1],\n",
       "  'question_id': 30005},\n",
       " {'image_id': 524320,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [0.9, 1],\n",
       "  'question_id': 524320000},\n",
       " {'image_id': 524320,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [0.9, 1],\n",
       "  'question_id': 524320001},\n",
       " {'image_id': 524320,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [0.3, 1],\n",
       "  'question_id': 524320002},\n",
       " {'image_id': 240304,\n",
       "  'labels': [425, 660],\n",
       "  'scores': [0.3, 1],\n",
       "  'question_id': 240304000},\n",
       " {'image_id': 240304,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [1, 0.3],\n",
       "  'question_id': 240304001},\n",
       " {'image_id': 240304,\n",
       "  'labels': [2525, 2643, 575],\n",
       "  'scores': [0.6, 0.6, 0.6],\n",
       "  'question_id': 240304002},\n",
       " {'image_id': 34, 'labels': [1403], 'scores': [1], 'question_id': 34000},\n",
       " {'image_id': 34, 'labels': [660], 'scores': [1], 'question_id': 34001},\n",
       " {'image_id': 34,\n",
       "  'labels': [1015, 429, 878, 841, 1913, 632],\n",
       "  'scores': [0.3, 0.9, 0.3, 0.6, 0.3, 0.3],\n",
       "  'question_id': 34002},\n",
       " {'image_id': 393251,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [1, 0.3],\n",
       "  'question_id': 393251000},\n",
       " {'image_id': 393251,\n",
       "  'labels': [425],\n",
       "  'scores': [1],\n",
       "  'question_id': 393251001},\n",
       " {'image_id': 393251,\n",
       "  'labels': [2274, 484],\n",
       "  'scores': [0.3, 1],\n",
       "  'question_id': 393251002},\n",
       " {'image_id': 393251,\n",
       "  'labels': [2614, 755, 425],\n",
       "  'scores': [0.3, 1, 0.3],\n",
       "  'question_id': 393251003},\n",
       " {'image_id': 262180,\n",
       "  'labels': [120, 1831, 960],\n",
       "  'scores': [0.3, 1, 0.3],\n",
       "  'question_id': 262180000},\n",
       " {'image_id': 262180,\n",
       "  'labels': [425],\n",
       "  'scores': [1],\n",
       "  'question_id': 262180001},\n",
       " {'image_id': 262180,\n",
       "  'labels': [1719],\n",
       "  'scores': [1],\n",
       "  'question_id': 262180002},\n",
       " {'image_id': 262180,\n",
       "  'labels': [3110, 1831, 1715],\n",
       "  'scores': [1, 0.6, 0.3],\n",
       "  'question_id': 262180003},\n",
       " {'image_id': 524325,\n",
       "  'labels': [1239],\n",
       "  'scores': [1],\n",
       "  'question_id': 524325000},\n",
       " {'image_id': 524325,\n",
       "  'labels': [480],\n",
       "  'scores': [1],\n",
       "  'question_id': 524325001},\n",
       " {'image_id': 524325,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [1, 0.3],\n",
       "  'question_id': 524325002},\n",
       " {'image_id': 43697, 'labels': [425], 'scores': [1], 'question_id': 43697000},\n",
       " {'image_id': 43697, 'labels': [3006], 'scores': [1], 'question_id': 43697001},\n",
       " {'image_id': 43697, 'labels': [1403], 'scores': [1], 'question_id': 43697002},\n",
       " {'image_id': 43697,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [0.6, 1],\n",
       "  'question_id': 43697003},\n",
       " {'image_id': 43697,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [1, 0.6],\n",
       "  'question_id': 43697004},\n",
       " {'image_id': 43697,\n",
       "  'labels': [2274, 106, 1245, 1005],\n",
       "  'scores': [0.3, 0.3, 1, 0.3],\n",
       "  'question_id': 43697005},\n",
       " {'image_id': 43697,\n",
       "  'labels': [1225, 1354],\n",
       "  'scores': [0.9, 1],\n",
       "  'question_id': 43697006},\n",
       " {'image_id': 262184,\n",
       "  'labels': [1403],\n",
       "  'scores': [1],\n",
       "  'question_id': 262184000},\n",
       " {'image_id': 262184,\n",
       "  'labels': [681, 1123],\n",
       "  'scores': [1, 0.3],\n",
       "  'question_id': 262184001},\n",
       " {'image_id': 262184,\n",
       "  'labels': [1687, 2210, 179],\n",
       "  'scores': [0.9, 0.3, 0.3],\n",
       "  'question_id': 262184002},\n",
       " {'image_id': 131113,\n",
       "  'labels': [2594, 730, 3090, 1333],\n",
       "  'scores': [1, 0.3, 0.3, 0.6],\n",
       "  'question_id': 131113000},\n",
       " {'image_id': 131113,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [1, 1],\n",
       "  'question_id': 131113001},\n",
       " {'image_id': 131113,\n",
       "  'labels': [919, 775],\n",
       "  'scores': [0.3, 1],\n",
       "  'question_id': 131113002},\n",
       " {'image_id': 131113,\n",
       "  'labels': [3025, 2864],\n",
       "  'scores': [0.6, 1],\n",
       "  'question_id': 131113003},\n",
       " {'image_id': 262187,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [0.6, 1],\n",
       "  'question_id': 262187000},\n",
       " {'image_id': 262187,\n",
       "  'labels': [2241, 1062, 1333],\n",
       "  'scores': [0.3, 0.6, 1],\n",
       "  'question_id': 262187001},\n",
       " {'image_id': 262187,\n",
       "  'labels': [1577, 1579, 3041, 445, 221],\n",
       "  'scores': [1, 0.3, 0.3, 0.3, 0.3],\n",
       "  'question_id': 262187002},\n",
       " {'image_id': 262187,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [0.6, 1],\n",
       "  'question_id': 262187003},\n",
       " {'image_id': 131118,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [1, 0.9],\n",
       "  'question_id': 131118000},\n",
       " {'image_id': 131118,\n",
       "  'labels': [841, 3031],\n",
       "  'scores': [1, 0.3],\n",
       "  'question_id': 131118001},\n",
       " {'image_id': 131118,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [1, 1],\n",
       "  'question_id': 131118002},\n",
       " {'image_id': 262191,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [1, 1],\n",
       "  'question_id': 262191000},\n",
       " {'image_id': 262191,\n",
       "  'labels': [425],\n",
       "  'scores': [0.6],\n",
       "  'question_id': 262191001},\n",
       " {'image_id': 262191,\n",
       "  'labels': [160, 853],\n",
       "  'scores': [1, 1],\n",
       "  'question_id': 262191002},\n",
       " {'image_id': 49, 'labels': [425], 'scores': [1], 'question_id': 49000},\n",
       " {'image_id': 49, 'labels': [1227], 'scores': [1], 'question_id': 49001},\n",
       " {'image_id': 49,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [0.9, 1],\n",
       "  'question_id': 49002},\n",
       " {'image_id': 524338,\n",
       "  'labels': [2195, 2621, 3031, 1239],\n",
       "  'scores': [0.3, 1, 0.3, 0.6],\n",
       "  'question_id': 524338000},\n",
       " {'image_id': 524338,\n",
       "  'labels': [598, 735, 1553, 2645, 2132, 1830],\n",
       "  'scores': [0.6, 0.3, 0.3, 0.3, 0.3, 0.3],\n",
       "  'question_id': 524338001},\n",
       " {'image_id': 524338,\n",
       "  'labels': [1403],\n",
       "  'scores': [1],\n",
       "  'question_id': 524338002},\n",
       " {'image_id': 213863,\n",
       "  'labels': [1775],\n",
       "  'scores': [1],\n",
       "  'question_id': 213863000},\n",
       " {'image_id': 213863,\n",
       "  'labels': [2985],\n",
       "  'scores': [1],\n",
       "  'question_id': 213863001},\n",
       " {'image_id': 213863,\n",
       "  'labels': [2588, 1840, 1083],\n",
       "  'scores': [0.3, 1, 0.3],\n",
       "  'question_id': 213863002},\n",
       " {'image_id': 393268,\n",
       "  'labels': [411],\n",
       "  'scores': [1],\n",
       "  'question_id': 393268000},\n",
       " {'image_id': 393268,\n",
       "  'labels': [2984, 1388],\n",
       "  'scores': [0.3, 1],\n",
       "  'question_id': 393268001},\n",
       " {'image_id': 393268,\n",
       "  'labels': [745, 1420, 750, 1906, 823],\n",
       "  'scores': [0.3, 0.3, 0.3, 0.3, 0.3],\n",
       "  'question_id': 393268002},\n",
       " {'image_id': 131126,\n",
       "  'labels': [35, 1553, 586, 750, 2712],\n",
       "  'scores': [0.6, 0.3, 0.3, 0.3, 0.3],\n",
       "  'question_id': 131126000},\n",
       " {'image_id': 131126,\n",
       "  'labels': [2387, 383, 758, 2785],\n",
       "  'scores': [0.3, 0.9, 0.3, 0.6],\n",
       "  'question_id': 131126001},\n",
       " {'image_id': 131126,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [1, 1],\n",
       "  'question_id': 131126002},\n",
       " {'image_id': 131127,\n",
       "  'labels': [603],\n",
       "  'scores': [1],\n",
       "  'question_id': 131127000},\n",
       " {'image_id': 131127,\n",
       "  'labels': [1403],\n",
       "  'scores': [1],\n",
       "  'question_id': 131127001},\n",
       " {'image_id': 131127,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [0.9, 1],\n",
       "  'question_id': 131127002},\n",
       " {'image_id': 131128,\n",
       "  'labels': [1191, 759],\n",
       "  'scores': [1, 0.3],\n",
       "  'question_id': 131128000},\n",
       " {'image_id': 131128,\n",
       "  'labels': [1191, 1190],\n",
       "  'scores': [1, 0.3],\n",
       "  'question_id': 131128001},\n",
       " {'image_id': 131128,\n",
       "  'labels': [2621, 841, 1618],\n",
       "  'scores': [1, 0.3, 0.3],\n",
       "  'question_id': 131128002},\n",
       " {'image_id': 131128,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [0.3, 1],\n",
       "  'question_id': 131128003},\n",
       " {'image_id': 262201,\n",
       "  'labels': [2862, 751, 1288, 1319],\n",
       "  'scores': [0.3, 0.3, 0.3, 0.3],\n",
       "  'question_id': 262201000},\n",
       " {'image_id': 262201,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [0.3, 1],\n",
       "  'question_id': 262201001},\n",
       " {'image_id': 262201,\n",
       "  'labels': [1978, 2387, 2383],\n",
       "  'scores': [0.3, 1, 0.3],\n",
       "  'question_id': 262201002},\n",
       " {'image_id': 262201,\n",
       "  'labels': [1403],\n",
       "  'scores': [1],\n",
       "  'question_id': 262201003},\n",
       " {'image_id': 370986,\n",
       "  'labels': [2435, 433, 469],\n",
       "  'scores': [0.6, 0.6, 0.9],\n",
       "  'question_id': 370986000},\n",
       " {'image_id': 370986,\n",
       "  'labels': [2195, 2621, 841],\n",
       "  'scores': [0.3, 0.3, 1],\n",
       "  'question_id': 370986001},\n",
       " {'image_id': 370986,\n",
       "  'labels': [2621],\n",
       "  'scores': [1],\n",
       "  'question_id': 370986002},\n",
       " {'image_id': 262204,\n",
       "  'labels': [841],\n",
       "  'scores': [1],\n",
       "  'question_id': 262204000},\n",
       " {'image_id': 262204,\n",
       "  'labels': [825],\n",
       "  'scores': [1],\n",
       "  'question_id': 262204001},\n",
       " {'image_id': 262204,\n",
       "  'labels': [1880],\n",
       "  'scores': [1],\n",
       "  'question_id': 262204002},\n",
       " {'image_id': 131133,\n",
       "  'labels': [2241, 1491, 1333],\n",
       "  'scores': [1, 0.3, 0.9],\n",
       "  'question_id': 131133000},\n",
       " {'image_id': 131133,\n",
       "  'labels': [1209, 377, 2386, 583, 187],\n",
       "  'scores': [0.3, 0.9, 0.3, 0.3, 0.3],\n",
       "  'question_id': 131133001},\n",
       " {'image_id': 131133,\n",
       "  'labels': [425],\n",
       "  'scores': [1],\n",
       "  'question_id': 131133002},\n",
       " {'image_id': 262207,\n",
       "  'labels': [2594, 1880, 1892, 3090],\n",
       "  'scores': [0.6, 0.3, 0.6, 0.9],\n",
       "  'question_id': 262207000},\n",
       " {'image_id': 262207,\n",
       "  'labels': [425],\n",
       "  'scores': [1],\n",
       "  'question_id': 262207001},\n",
       " {'image_id': 262207,\n",
       "  'labels': [2325, 1177, 1408],\n",
       "  'scores': [1, 0.3, 0.6],\n",
       "  'question_id': 262207002},\n",
       " {'image_id': 262207,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [1, 1],\n",
       "  'question_id': 262207003},\n",
       " {'image_id': 64,\n",
       "  'labels': [1968, 806, 2152, 3000],\n",
       "  'scores': [0.3, 0.3, 1, 0.3],\n",
       "  'question_id': 64000},\n",
       " {'image_id': 64,\n",
       "  'labels': [425, 169, 1403],\n",
       "  'scores': [1, 0.3, 1],\n",
       "  'question_id': 64001},\n",
       " {'image_id': 64, 'labels': [425], 'scores': [1], 'question_id': 64002},\n",
       " {'image_id': 64, 'labels': [94], 'scores': [1], 'question_id': 64003},\n",
       " {'image_id': 64,\n",
       "  'labels': [244, 2009],\n",
       "  'scores': [0.3, 0.3],\n",
       "  'question_id': 64004},\n",
       " {'image_id': 458763,\n",
       "  'labels': [3026, 2534],\n",
       "  'scores': [1, 0.3],\n",
       "  'question_id': 458763000},\n",
       " {'image_id': 458763,\n",
       "  'labels': [2621],\n",
       "  'scores': [1],\n",
       "  'question_id': 458763001},\n",
       " {'image_id': 458763,\n",
       "  'labels': [2195, 444],\n",
       "  'scores': [1, 1],\n",
       "  'question_id': 458763002},\n",
       " {'image_id': 458763,\n",
       "  'labels': [411, 990],\n",
       "  'scores': [1, 0.3],\n",
       "  'question_id': 458763003},\n",
       " {'image_id': 458763,\n",
       "  'labels': [3010],\n",
       "  'scores': [1],\n",
       "  'question_id': 458763004},\n",
       " {'image_id': 458763,\n",
       "  'labels': [4, 1397, 1207],\n",
       "  'scores': [0.3, 1, 0.3],\n",
       "  'question_id': 458763005},\n",
       " {'image_id': 458763,\n",
       "  'labels': [1403],\n",
       "  'scores': [1],\n",
       "  'question_id': 458763006},\n",
       " {'image_id': 567990,\n",
       "  'labels': [2529, 2763],\n",
       "  'scores': [0.6, 1],\n",
       "  'question_id': 567990000},\n",
       " {'image_id': 567990,\n",
       "  'labels': [425],\n",
       "  'scores': [1],\n",
       "  'question_id': 567990001},\n",
       " {'image_id': 567990,\n",
       "  'labels': [1742, 2511],\n",
       "  'scores': [1, 0.3],\n",
       "  'question_id': 567990002},\n",
       " {'image_id': 567990,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [1, 0.3],\n",
       "  'question_id': 567990003},\n",
       " {'image_id': 393286,\n",
       "  'labels': [425],\n",
       "  'scores': [1],\n",
       "  'question_id': 393286000},\n",
       " {'image_id': 393286,\n",
       "  'labels': [1403],\n",
       "  'scores': [1],\n",
       "  'question_id': 393286001},\n",
       " {'image_id': 393286,\n",
       "  'labels': [2773, 2369],\n",
       "  'scores': [1, 0.3],\n",
       "  'question_id': 393286002},\n",
       " {'image_id': 71, 'labels': [425], 'scores': [1], 'question_id': 71000},\n",
       " {'image_id': 71, 'labels': [425], 'scores': [1], 'question_id': 71001},\n",
       " {'image_id': 71, 'labels': [223], 'scores': [0.3], 'question_id': 71002},\n",
       " {'image_id': 72,\n",
       "  'labels': [2621, 841],\n",
       "  'scores': [0.3, 1],\n",
       "  'question_id': 72000},\n",
       " {'image_id': 72,\n",
       "  'labels': [575, 841, 660],\n",
       "  'scores': [1, 0.3, 0.3],\n",
       "  'question_id': 72001},\n",
       " {'image_id': 72, 'labels': [425], 'scores': [1], 'question_id': 72002},\n",
       " {'image_id': 393228,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [1, 0.3],\n",
       "  'question_id': 393228000},\n",
       " {'image_id': 393228,\n",
       "  'labels': [1403],\n",
       "  'scores': [1],\n",
       "  'question_id': 393228001},\n",
       " {'image_id': 393228,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [1, 0.6],\n",
       "  'question_id': 393228002},\n",
       " {'image_id': 393290,\n",
       "  'labels': [2306, 2274],\n",
       "  'scores': [1, 0.3],\n",
       "  'question_id': 393290000},\n",
       " {'image_id': 393290,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [1, 1],\n",
       "  'question_id': 393290001},\n",
       " {'image_id': 393290,\n",
       "  'labels': [2063, 311, 1618],\n",
       "  'scores': [0.3, 1, 1],\n",
       "  'question_id': 393290002},\n",
       " {'image_id': 393291,\n",
       "  'labels': [2969, 2203, 1678, 2785],\n",
       "  'scores': [0.9, 0.3, 0.3, 0.6],\n",
       "  'question_id': 393291000},\n",
       " {'image_id': 393291,\n",
       "  'labels': [1540],\n",
       "  'scores': [1],\n",
       "  'question_id': 393291001},\n",
       " {'image_id': 393291,\n",
       "  'labels': [3006, 2661, 759, 775],\n",
       "  'scores': [1, 0.3, 0.6, 0.3],\n",
       "  'question_id': 393291002},\n",
       " {'image_id': 393291,\n",
       "  'labels': [652, 1108],\n",
       "  'scores': [1, 1],\n",
       "  'question_id': 393291003},\n",
       " {'image_id': 393291,\n",
       "  'labels': [2868, 2920, 1775],\n",
       "  'scores': [1, 0.3, 0.3],\n",
       "  'question_id': 393291004},\n",
       " {'image_id': 393291,\n",
       "  'labels': [1491, 2594, 3090],\n",
       "  'scores': [0.6, 1, 0.6],\n",
       "  'question_id': 393291005},\n",
       " {'image_id': 393291,\n",
       "  'labels': [425, 1403, 49],\n",
       "  'scores': [0.3, 1, 0.3],\n",
       "  'question_id': 393291006},\n",
       " {'image_id': 393291,\n",
       "  'labels': [444, 2621, 841],\n",
       "  'scores': [0.3, 1, 0.6],\n",
       "  'question_id': 393291007},\n",
       " {'image_id': 393292,\n",
       "  'labels': [1403],\n",
       "  'scores': [1],\n",
       "  'question_id': 393292000},\n",
       " {'image_id': 393292,\n",
       "  'labels': [425],\n",
       "  'scores': [1],\n",
       "  'question_id': 393292001},\n",
       " {'image_id': 393292,\n",
       "  'labels': [2195, 841],\n",
       "  'scores': [1, 1],\n",
       "  'question_id': 393292002},\n",
       " {'image_id': 262221,\n",
       "  'labels': [2588, 2285],\n",
       "  'scores': [0.3, 1],\n",
       "  'question_id': 262221000},\n",
       " {'image_id': 262221,\n",
       "  'labels': [694],\n",
       "  'scores': [1],\n",
       "  'question_id': 262221001},\n",
       " {'image_id': 262221,\n",
       "  'labels': [2195, 841],\n",
       "  'scores': [1, 0.3],\n",
       "  'question_id': 262221002},\n",
       " {'image_id': 78,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [0.6, 1],\n",
       "  'question_id': 78000},\n",
       " {'image_id': 78,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [1, 0.3],\n",
       "  'question_id': 78001},\n",
       " {'image_id': 78,\n",
       "  'labels': [1296, 2063, 2673],\n",
       "  'scores': [0.3, 0.3, 1],\n",
       "  'question_id': 78002},\n",
       " {'image_id': 81,\n",
       "  'labels': [425, 2621, 1403],\n",
       "  'scores': [0.6, 0.3, 1],\n",
       "  'question_id': 81000},\n",
       " {'image_id': 81,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [0.6, 1],\n",
       "  'question_id': 81001},\n",
       " {'image_id': 81,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [1, 1],\n",
       "  'question_id': 81002},\n",
       " {'image_id': 81, 'labels': [342], 'scores': [1], 'question_id': 81003},\n",
       " {'image_id': 81, 'labels': [425], 'scores': [1], 'question_id': 81004},\n",
       " {'image_id': 86,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [1, 1],\n",
       "  'question_id': 86000},\n",
       " {'image_id': 86, 'labels': [2038], 'scores': [1], 'question_id': 86001},\n",
       " {'image_id': 86,\n",
       "  'labels': [1434, 1769, 28],\n",
       "  'scores': [1, 0.3, 1],\n",
       "  'question_id': 86002},\n",
       " {'image_id': 524375,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [1, 0.6],\n",
       "  'question_id': 524375000},\n",
       " {'image_id': 524375,\n",
       "  'labels': [2681, 1549, 2174],\n",
       "  'scores': [0.3, 1, 0.3],\n",
       "  'question_id': 524375001},\n",
       " {'image_id': 524375,\n",
       "  'labels': [1034, 1820, 1029, 1001, 735],\n",
       "  'scores': [1, 0.6, 0.3, 0.3, 0.3],\n",
       "  'question_id': 524375002},\n",
       " {'image_id': 524375,\n",
       "  'labels': [1989, 2769, 1995, 444, 2621, 3031, 1239],\n",
       "  'scores': [0.6, 0.3, 0.3, 0.3, 0.3, 0.3, 0.6],\n",
       "  'question_id': 524375003},\n",
       " {'image_id': 524375,\n",
       "  'labels': [1712, 2831, 3088],\n",
       "  'scores': [0.3, 0.3, 0.6],\n",
       "  'question_id': 524375004},\n",
       " {'image_id': 524375,\n",
       "  'labels': [683],\n",
       "  'scores': [0.6],\n",
       "  'question_id': 524375005},\n",
       " {'image_id': 524375,\n",
       "  'labels': [425],\n",
       "  'scores': [1],\n",
       "  'question_id': 524375006},\n",
       " {'image_id': 524375,\n",
       "  'labels': [1403],\n",
       "  'scores': [1],\n",
       "  'question_id': 524375007},\n",
       " {'image_id': 131160,\n",
       "  'labels': [3006, 914, 730],\n",
       "  'scores': [1, 0.9, 0.3],\n",
       "  'question_id': 131160000},\n",
       " {'image_id': 131160,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [1, 0.6],\n",
       "  'question_id': 131160001},\n",
       " {'image_id': 131160,\n",
       "  'labels': [3115, 1562, 2412, 2807, 1113],\n",
       "  'scores': [0.3, 0.3, 0.9, 0.3, 0.3],\n",
       "  'question_id': 131160002},\n",
       " {'image_id': 524377,\n",
       "  'labels': [1934, 425],\n",
       "  'scores': [0.3, 0.3],\n",
       "  'question_id': 524377000},\n",
       " {'image_id': 524377,\n",
       "  'labels': [1403],\n",
       "  'scores': [1],\n",
       "  'question_id': 524377001},\n",
       " {'image_id': 524377,\n",
       "  'labels': [2195, 3023],\n",
       "  'scores': [1, 0.3],\n",
       "  'question_id': 524377002},\n",
       " {'image_id': 524377,\n",
       "  'labels': [425],\n",
       "  'scores': [1],\n",
       "  'question_id': 524377003},\n",
       " {'image_id': 524377,\n",
       "  'labels': [158],\n",
       "  'scores': [1],\n",
       "  'question_id': 524377004},\n",
       " {'image_id': 524377,\n",
       "  'labels': [19, 1861, 1915, 1084, 1208],\n",
       "  'scores': [0.3, 0.3, 0.3, 0.3, 0.3],\n",
       "  'question_id': 524377005},\n",
       " {'image_id': 524377,\n",
       "  'labels': [459, 611, 314],\n",
       "  'scores': [1, 0.6, 0.3],\n",
       "  'question_id': 524377006},\n",
       " {'image_id': 524377,\n",
       "  'labels': [1403],\n",
       "  'scores': [1],\n",
       "  'question_id': 524377007},\n",
       " {'image_id': 524377,\n",
       "  'labels': [1943, 1553, 534],\n",
       "  'scores': [1, 0.3, 0.3],\n",
       "  'question_id': 524377008},\n",
       " {'image_id': 524377,\n",
       "  'labels': [158, 1861, 625],\n",
       "  'scores': [1, 0.3, 0.3],\n",
       "  'question_id': 524377009},\n",
       " {'image_id': 524377,\n",
       "  'labels': [966, 2357, 518, 3091],\n",
       "  'scores': [0.3, 0.3, 0.9, 0.9],\n",
       "  'question_id': 524377010},\n",
       " {'image_id': 524377,\n",
       "  'labels': [1670, 966, 2346, 3091],\n",
       "  'scores': [0.3, 0.3, 0.6, 0.9],\n",
       "  'question_id': 524377011},\n",
       " {'image_id': 524377,\n",
       "  'labels': [1943, 2580, 106, 534, 1245],\n",
       "  'scores': [1, 0.3, 0.3, 0.9, 0.3],\n",
       "  'question_id': 524377012},\n",
       " {'image_id': 524377,\n",
       "  'labels': [1943],\n",
       "  'scores': [0.3],\n",
       "  'question_id': 524377013},\n",
       " {'image_id': 524377,\n",
       "  'labels': [518, 2346, 3091],\n",
       "  'scores': [0.3, 0.3, 1],\n",
       "  'question_id': 524377014},\n",
       " {'image_id': 524377,\n",
       "  'labels': [1403],\n",
       "  'scores': [1],\n",
       "  'question_id': 524377015},\n",
       " {'image_id': 524377,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [0.6, 1],\n",
       "  'question_id': 524377016},\n",
       " {'image_id': 524377,\n",
       "  'labels': [1433, 1076, 885, 261, 294],\n",
       "  'scores': [0.3, 1, 0.3, 0.3, 0.3],\n",
       "  'question_id': 524377017},\n",
       " {'image_id': 524377,\n",
       "  'labels': [2146, 2580],\n",
       "  'scores': [0.3, 0.3],\n",
       "  'question_id': 524377018},\n",
       " {'image_id': 524377,\n",
       "  'labels': [2195],\n",
       "  'scores': [1],\n",
       "  'question_id': 524377019},\n",
       " {'image_id': 524377,\n",
       "  'labels': [1943, 1245, 1951, 158, 2580, 1470, 534],\n",
       "  'scores': [0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.9],\n",
       "  'question_id': 524377020},\n",
       " {'image_id': 524377,\n",
       "  'labels': [3006],\n",
       "  'scores': [1],\n",
       "  'question_id': 524377021},\n",
       " {'image_id': 524377,\n",
       "  'labels': [444, 3031],\n",
       "  'scores': [1, 0.3],\n",
       "  'question_id': 524377022},\n",
       " {'image_id': 524377,\n",
       "  'labels': [1943, 1983, 534, 2796],\n",
       "  'scores': [1, 0.3, 0.6, 0.3],\n",
       "  'question_id': 524377023},\n",
       " {'image_id': 524377,\n",
       "  'labels': [2195],\n",
       "  'scores': [1],\n",
       "  'question_id': 524377024},\n",
       " {'image_id': 524377,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [0.3, 1],\n",
       "  'question_id': 524377025},\n",
       " {'image_id': 524377,\n",
       "  'labels': [19, 1354],\n",
       "  'scores': [0.3, 1],\n",
       "  'question_id': 524377026},\n",
       " {'image_id': 524377,\n",
       "  'labels': [2195],\n",
       "  'scores': [1],\n",
       "  'question_id': 524377027},\n",
       " {'image_id': 524377,\n",
       "  'labels': [1470, 1134, 3023],\n",
       "  'scores': [0.6, 0.6, 0.3],\n",
       "  'question_id': 524377028},\n",
       " {'image_id': 524377,\n",
       "  'labels': [523, 1218],\n",
       "  'scores': [0.6, 0.6],\n",
       "  'question_id': 524377029},\n",
       " {'image_id': 524377,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [1, 0.6],\n",
       "  'question_id': 524377030},\n",
       " {'image_id': 524377,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [0.9, 1],\n",
       "  'question_id': 524377031},\n",
       " {'image_id': 524377,\n",
       "  'labels': [1943, 2580, 106, 534],\n",
       "  'scores': [0.3, 1, 0.3, 0.9],\n",
       "  'question_id': 524377032},\n",
       " {'image_id': 524377,\n",
       "  'labels': [2861, 1487, 1951],\n",
       "  'scores': [1, 0.3, 0.3],\n",
       "  'question_id': 524377033},\n",
       " {'image_id': 524377,\n",
       "  'labels': [1861, 1403, 158, 2346, 3023],\n",
       "  'scores': [0.3, 0.3, 1, 0.3, 0.3],\n",
       "  'question_id': 524377034},\n",
       " {'image_id': 524377,\n",
       "  'labels': [158, 1861, 625],\n",
       "  'scores': [1, 1, 0.3],\n",
       "  'question_id': 524377035},\n",
       " {'image_id': 524377,\n",
       "  'labels': [1861, 158, 2346, 518, 3091, 1545],\n",
       "  'scores': [0.3, 1, 0.3, 0.3, 0.3, 0.3],\n",
       "  'question_id': 524377036},\n",
       " {'image_id': 524377,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [0.3, 1],\n",
       "  'question_id': 524377037},\n",
       " {'image_id': 524377,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [1, 1],\n",
       "  'question_id': 524377038},\n",
       " {'image_id': 524377,\n",
       "  'labels': [1403],\n",
       "  'scores': [1],\n",
       "  'question_id': 524377039},\n",
       " {'image_id': 524377,\n",
       "  'labels': [158, 1403, 1387, 1001, 2933],\n",
       "  'scores': [0.3, 0.3, 0.3, 0.3, 1],\n",
       "  'question_id': 524377040},\n",
       " {'image_id': 524377,\n",
       "  'labels': [1403],\n",
       "  'scores': [1],\n",
       "  'question_id': 524377041},\n",
       " {'image_id': 524377,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [1, 0.6],\n",
       "  'question_id': 524377042},\n",
       " {'image_id': 524377,\n",
       "  'labels': [1403],\n",
       "  'scores': [1],\n",
       "  'question_id': 524377043},\n",
       " {'image_id': 524377,\n",
       "  'labels': [425],\n",
       "  'scores': [1],\n",
       "  'question_id': 524377044},\n",
       " {'image_id': 524377,\n",
       "  'labels': [425],\n",
       "  'scores': [1],\n",
       "  'question_id': 524377045},\n",
       " {'image_id': 524377,\n",
       "  'labels': [518, 796, 3091],\n",
       "  'scores': [0.9, 0.3, 1],\n",
       "  'question_id': 524377046},\n",
       " {'image_id': 524377,\n",
       "  'labels': [2146, 949, 518],\n",
       "  'scores': [0.3, 0.3, 0.3],\n",
       "  'question_id': 524377047},\n",
       " {'image_id': 524377,\n",
       "  'labels': [1403],\n",
       "  'scores': [1],\n",
       "  'question_id': 524377048},\n",
       " {'image_id': 524377,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [1, 1],\n",
       "  'question_id': 524377049},\n",
       " {'image_id': 524377,\n",
       "  'labels': [1943, 421, 534, 2580, 419],\n",
       "  'scores': [1, 0.3, 0.3, 0.3, 0.9],\n",
       "  'question_id': 524377050},\n",
       " {'image_id': 524377,\n",
       "  'labels': [2195, 2621, 841],\n",
       "  'scores': [1, 0.3, 0.3],\n",
       "  'question_id': 524377051},\n",
       " {'image_id': 524377,\n",
       "  'labels': [1943, 2580, 534],\n",
       "  'scores': [0.9, 0.6, 0.9],\n",
       "  'question_id': 524377052},\n",
       " {'image_id': 524377,\n",
       "  'labels': [701, 1333, 2861],\n",
       "  'scores': [1, 0.3, 0.6],\n",
       "  'question_id': 524377053},\n",
       " {'image_id': 524377,\n",
       "  'labels': [158, 2346, 1084],\n",
       "  'scores': [1, 0.3, 0.3],\n",
       "  'question_id': 524377054},\n",
       " {'image_id': 393306,\n",
       "  'labels': [1403],\n",
       "  'scores': [1],\n",
       "  'question_id': 393306000},\n",
       " {'image_id': 393306,\n",
       "  'labels': [2613, 2883],\n",
       "  'scores': [1, 0.6],\n",
       "  'question_id': 393306001},\n",
       " {'image_id': 393306,\n",
       "  'labels': [2993, 2613],\n",
       "  'scores': [1, 0.3],\n",
       "  'question_id': 393306002},\n",
       " {'image_id': 393306,\n",
       "  'labels': [2387, 2785],\n",
       "  'scores': [0.3, 1],\n",
       "  'question_id': 393306003},\n",
       " {'image_id': 262159,\n",
       "  'labels': [1403],\n",
       "  'scores': [1],\n",
       "  'question_id': 262159000},\n",
       " {'image_id': 262159,\n",
       "  'labels': [425],\n",
       "  'scores': [1],\n",
       "  'question_id': 262159001},\n",
       " {'image_id': 262159,\n",
       "  'labels': [841],\n",
       "  'scores': [1],\n",
       "  'question_id': 262159002},\n",
       " {'image_id': 262159,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [1, 1],\n",
       "  'question_id': 262159003},\n",
       " {'image_id': 262159,\n",
       "  'labels': [1190, 1191, 3006, 990, 759],\n",
       "  'scores': [0.3, 0.3, 0.9, 0.3, 1],\n",
       "  'question_id': 262159004},\n",
       " {'image_id': 262159,\n",
       "  'labels': [1403],\n",
       "  'scores': [1],\n",
       "  'question_id': 262159005},\n",
       " {'image_id': 262159,\n",
       "  'labels': [3006, 990, 759],\n",
       "  'scores': [0.3, 0.3, 1],\n",
       "  'question_id': 262159006},\n",
       " {'image_id': 262159,\n",
       "  'labels': [1491, 1191, 759],\n",
       "  'scores': [0.3, 0.3, 1],\n",
       "  'question_id': 262159007},\n",
       " {'image_id': 262159,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [0.9, 1],\n",
       "  'question_id': 262159008},\n",
       " {'image_id': 262159,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [1, 0.3],\n",
       "  'question_id': 262159009},\n",
       " {'image_id': 262159,\n",
       "  'labels': [990, 759],\n",
       "  'scores': [0.3, 1],\n",
       "  'question_id': 262159010},\n",
       " {'image_id': 262159,\n",
       "  'labels': [2674, 1027, 2104, 2210],\n",
       "  'scores': [0.3, 0.6, 0.3, 0.6],\n",
       "  'question_id': 262159011},\n",
       " {'image_id': 262159,\n",
       "  'labels': [425],\n",
       "  'scores': [1],\n",
       "  'question_id': 262159012},\n",
       " {'image_id': 92,\n",
       "  'labels': [1989, 1994, 2195, 2621, 841, 311, 703, 2063],\n",
       "  'scores': [0.3, 0.3, 0.3, 0.3, 0.3, 0.9, 0.3, 0.3],\n",
       "  'question_id': 92000},\n",
       " {'image_id': 92, 'labels': [425], 'scores': [1], 'question_id': 92001},\n",
       " {'image_id': 92,\n",
       "  'labels': [2195, 2621],\n",
       "  'scores': [1, 0.3],\n",
       "  'question_id': 92002},\n",
       " {'image_id': 94,\n",
       "  'labels': [745, 1403, 713, 2274, 1643, 1726],\n",
       "  'scores': [0.3, 0.3, 0.3, 0.3, 0.3, 0.9],\n",
       "  'question_id': 94000},\n",
       " {'image_id': 94, 'labels': [], 'scores': [], 'question_id': 94001},\n",
       " {'image_id': 94, 'labels': [841], 'scores': [1], 'question_id': 94002},\n",
       " {'image_id': 94,\n",
       "  'labels': [1768, 1784, 2952],\n",
       "  'scores': [1, 0.3, 0.3],\n",
       "  'question_id': 94003},\n",
       " {'image_id': 94,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [1, 0.6],\n",
       "  'question_id': 94004},\n",
       " {'image_id': 393311,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [0.3, 1],\n",
       "  'question_id': 393311000},\n",
       " {'image_id': 393311,\n",
       "  'labels': [949],\n",
       "  'scores': [0.6],\n",
       "  'question_id': 393311001},\n",
       " {'image_id': 393311,\n",
       "  'labels': [602, 1422, 2250],\n",
       "  'scores': [0.6, 0.6, 0.6],\n",
       "  'question_id': 393311002},\n",
       " {'image_id': 393311,\n",
       "  'labels': [1764, 1862, 377],\n",
       "  'scores': [1, 0.3, 0.3],\n",
       "  'question_id': 393311003},\n",
       " {'image_id': 393311, 'labels': [], 'scores': [], 'question_id': 393311004},\n",
       " {'image_id': 393311, 'labels': [], 'scores': [], 'question_id': 393311005},\n",
       " {'image_id': 393311, 'labels': [], 'scores': [], 'question_id': 393311006},\n",
       " {'image_id': 393311,\n",
       "  'labels': [1764, 2459, 1448],\n",
       "  'scores': [0.6, 0.3, 0.3],\n",
       "  'question_id': 393311007},\n",
       " {'image_id': 393311,\n",
       "  'labels': [199, 2468],\n",
       "  'scores': [0.9, 1],\n",
       "  'question_id': 393311008},\n",
       " {'image_id': 524386,\n",
       "  'labels': [425],\n",
       "  'scores': [1],\n",
       "  'question_id': 524386000},\n",
       " {'image_id': 524386,\n",
       "  'labels': [1265, 2325, 1177, 2237, 3026, 1495],\n",
       "  'scores': [0.3, 0.6, 0.3, 0.3, 0.3, 0.3],\n",
       "  'question_id': 524386001},\n",
       " {'image_id': 524386,\n",
       "  'labels': [1403],\n",
       "  'scores': [1],\n",
       "  'question_id': 524386002},\n",
       " {'image_id': 524386,\n",
       "  'labels': [1403],\n",
       "  'scores': [1],\n",
       "  'question_id': 524386003},\n",
       " {'image_id': 524386,\n",
       "  'labels': [2621, 841],\n",
       "  'scores': [0.3, 1],\n",
       "  'question_id': 524386004},\n",
       " {'image_id': 524386,\n",
       "  'labels': [3057, 3017, 3059, 653],\n",
       "  'scores': [0.3, 1, 0.3, 0.3],\n",
       "  'question_id': 524386005},\n",
       " {'image_id': 524386,\n",
       "  'labels': [2562, 1108, 2541],\n",
       "  'scores': [0.6, 1, 0.3],\n",
       "  'question_id': 524386006},\n",
       " {'image_id': 524386,\n",
       "  'labels': [2621, 841],\n",
       "  'scores': [0.6, 1],\n",
       "  'question_id': 524386007},\n",
       " {'image_id': 524386,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [1, 1],\n",
       "  'question_id': 524386008},\n",
       " {'image_id': 524386,\n",
       "  'labels': [1970, 2391],\n",
       "  'scores': [0.3, 0.3],\n",
       "  'question_id': 524386009},\n",
       " {'image_id': 524386,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [0.3, 1],\n",
       "  'question_id': 524386010},\n",
       " {'image_id': 524386,\n",
       "  'labels': [1239],\n",
       "  'scores': [1],\n",
       "  'question_id': 524386011},\n",
       " {'image_id': 524386,\n",
       "  'labels': [1744, 2391, 1299],\n",
       "  'scores': [0.3, 0.3, 0.3],\n",
       "  'question_id': 524386012},\n",
       " {'image_id': 524386,\n",
       "  'labels': [2195],\n",
       "  'scores': [1],\n",
       "  'question_id': 524386013},\n",
       " {'image_id': 524386,\n",
       "  'labels': [1880, 3090],\n",
       "  'scores': [1, 0.3],\n",
       "  'question_id': 524386014},\n",
       " {'image_id': 524386,\n",
       "  'labels': [2621, 1239],\n",
       "  'scores': [1, 1],\n",
       "  'question_id': 524386015},\n",
       " {'image_id': 131172,\n",
       "  'labels': [2195, 841],\n",
       "  'scores': [1, 0.3],\n",
       "  'question_id': 131172000},\n",
       " {'image_id': 131172,\n",
       "  'labels': [2443, 2985],\n",
       "  'scores': [1, 0.6],\n",
       "  'question_id': 131172001},\n",
       " {'image_id': 131172,\n",
       "  'labels': [411, 1227],\n",
       "  'scores': [0.3, 1],\n",
       "  'question_id': 131172002},\n",
       " {'image_id': 131172,\n",
       "  'labels': [490, 2032, 707],\n",
       "  'scores': [0.3, 1, 0.3],\n",
       "  'question_id': 131172003},\n",
       " {'image_id': 393317,\n",
       "  'labels': [1429],\n",
       "  'scores': [0.6],\n",
       "  'question_id': 393317000},\n",
       " {'image_id': 393317,\n",
       "  'labels': [1049, 907, 1364, 2596],\n",
       "  'scores': [0.3, 1, 0.9, 0.3],\n",
       "  'question_id': 393317001},\n",
       " {'image_id': 393317,\n",
       "  'labels': [425],\n",
       "  'scores': [1],\n",
       "  'question_id': 393317002},\n",
       " {'image_id': 393317,\n",
       "  'labels': [2274],\n",
       "  'scores': [1],\n",
       "  'question_id': 393317003},\n",
       " {'image_id': 393317,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [0.9, 1],\n",
       "  'question_id': 393317004},\n",
       " {'image_id': 393317,\n",
       "  'labels': [503],\n",
       "  'scores': [1],\n",
       "  'question_id': 393317005},\n",
       " {'image_id': 393317,\n",
       "  'labels': [2596, 406, 1364, 3112, 907],\n",
       "  'scores': [0.3, 0.6, 0.3, 0.3, 1],\n",
       "  'question_id': 393317006},\n",
       " {'image_id': 393317,\n",
       "  'labels': [841],\n",
       "  'scores': [1],\n",
       "  'question_id': 393317007},\n",
       " {'image_id': 393317,\n",
       "  'labels': [1353],\n",
       "  'scores': [1],\n",
       "  'question_id': 393317008},\n",
       " {'image_id': 393317,\n",
       "  'labels': [425],\n",
       "  'scores': [1],\n",
       "  'question_id': 393317009},\n",
       " {'image_id': 393317,\n",
       "  'labels': [990],\n",
       "  'scores': [1],\n",
       "  'question_id': 393317010},\n",
       " {'image_id': 393317,\n",
       "  'labels': [2305, 3109, 1566],\n",
       "  'scores': [1, 1, 0.6],\n",
       "  'question_id': 393317011},\n",
       " {'image_id': 393317,\n",
       "  'labels': [306, 2435, 469, 433, 2904],\n",
       "  'scores': [0.3, 0.6, 0.3, 1, 0.3],\n",
       "  'question_id': 393317012},\n",
       " {'image_id': 393317,\n",
       "  'labels': [425],\n",
       "  'scores': [1],\n",
       "  'question_id': 393317013},\n",
       " {'image_id': 393317,\n",
       "  'labels': [2195],\n",
       "  'scores': [1],\n",
       "  'question_id': 393317014},\n",
       " {'image_id': 131174,\n",
       "  'labels': [3031, 1239],\n",
       "  'scores': [1, 0.9],\n",
       "  'question_id': 131174000},\n",
       " {'image_id': 131174,\n",
       "  'labels': [2195],\n",
       "  'scores': [1],\n",
       "  'question_id': 131174001},\n",
       " {'image_id': 131174,\n",
       "  'labels': [425],\n",
       "  'scores': [1],\n",
       "  'question_id': 131174002},\n",
       " {'image_id': 546151, 'labels': [], 'scores': [], 'question_id': 546151000},\n",
       " {'image_id': 546151,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [1, 0.3],\n",
       "  'question_id': 546151001},\n",
       " {'image_id': 546151,\n",
       "  'labels': [2195, 2621],\n",
       "  'scores': [1, 1],\n",
       "  'question_id': 546151002},\n",
       " {'image_id': 21826,\n",
       "  'labels': [2862, 1198, 1021, 2154],\n",
       "  'scores': [0.3, 1, 0.3, 0.9],\n",
       "  'question_id': 21826000},\n",
       " {'image_id': 21826, 'labels': [841], 'scores': [1], 'question_id': 21826001},\n",
       " {'image_id': 21826, 'labels': [1561], 'scores': [1], 'question_id': 21826002},\n",
       " {'image_id': 109,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [1, 1],\n",
       "  'question_id': 109000},\n",
       " {'image_id': 109,\n",
       "  'labels': [2195, 841],\n",
       "  'scores': [1, 0.3],\n",
       "  'question_id': 109001},\n",
       " {'image_id': 109,\n",
       "  'labels': [2621, 3031, 1239],\n",
       "  'scores': [0.6, 0.9, 1],\n",
       "  'question_id': 109002},\n",
       " {'image_id': 109,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [0.9, 1],\n",
       "  'question_id': 109003},\n",
       " {'image_id': 109,\n",
       "  'labels': [846, 1521, 1716, 2428, 2838],\n",
       "  'scores': [0.9, 0.3, 0.3, 1, 0.3],\n",
       "  'question_id': 109004},\n",
       " {'image_id': 109, 'labels': [425], 'scores': [1], 'question_id': 109005},\n",
       " {'image_id': 110,\n",
       "  'labels': [411, 1880, 1892, 2594],\n",
       "  'scores': [0.3, 1, 0.6, 0.6],\n",
       "  'question_id': 110000},\n",
       " {'image_id': 110, 'labels': [425], 'scores': [1], 'question_id': 110001},\n",
       " {'image_id': 110, 'labels': [1983], 'scores': [1], 'question_id': 110002},\n",
       " {'image_id': 305853,\n",
       "  'labels': [575, 1027, 103, 619],\n",
       "  'scores': [0.3, 0.3, 0.9, 0.3],\n",
       "  'question_id': 305853000},\n",
       " {'image_id': 305853,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [1, 0.3],\n",
       "  'question_id': 305853001},\n",
       " {'image_id': 305853,\n",
       "  'labels': [1064],\n",
       "  'scores': [1],\n",
       "  'question_id': 305853002},\n",
       " {'image_id': 305853,\n",
       "  'labels': [351, 1187, 1428, 668, 63, 3059],\n",
       "  'scores': [0.3, 0.3, 0.3, 0.6, 0.3, 0.3],\n",
       "  'question_id': 305853003},\n",
       " {'image_id': 113,\n",
       "  'labels': [2621, 841],\n",
       "  'scores': [1, 0.3],\n",
       "  'question_id': 113000},\n",
       " {'image_id': 113, 'labels': [411], 'scores': [1], 'question_id': 113001},\n",
       " {'image_id': 113,\n",
       "  'labels': [2314, 2563],\n",
       "  'scores': [1, 1],\n",
       "  'question_id': 113002},\n",
       " {'image_id': 113,\n",
       "  'labels': [2859, 741, 2563, 750, 3103, 590],\n",
       "  'scores': [0.3, 0.3, 0.3, 0.3, 0.6, 0.3],\n",
       "  'question_id': 113003},\n",
       " {'image_id': 113,\n",
       "  'labels': [1557, 1184],\n",
       "  'scores': [1, 1],\n",
       "  'question_id': 113004},\n",
       " {'image_id': 113, 'labels': [425], 'scores': [1], 'question_id': 113005},\n",
       " {'image_id': 113, 'labels': [1403], 'scores': [1], 'question_id': 113006},\n",
       " {'image_id': 113,\n",
       "  'labels': [1564, 1553, 1929, 1798],\n",
       "  'scores': [0.3, 0.3, 0.3, 0.3],\n",
       "  'question_id': 113007},\n",
       " {'image_id': 262260,\n",
       "  'labels': [2145, 668, 675, 1043],\n",
       "  'scores': [0.3, 0.3, 0.3, 0.3],\n",
       "  'question_id': 262260000},\n",
       " {'image_id': 262260,\n",
       "  'labels': [311, 1618],\n",
       "  'scores': [0.3, 1],\n",
       "  'question_id': 262260001},\n",
       " {'image_id': 262260,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [1, 0.9],\n",
       "  'question_id': 262260002},\n",
       " {'image_id': 262261,\n",
       "  'labels': [484],\n",
       "  'scores': [1],\n",
       "  'question_id': 262261000},\n",
       " {'image_id': 262261,\n",
       "  'labels': [1677, 605, 416, 2329],\n",
       "  'scores': [1, 0.3, 0.9, 0.6],\n",
       "  'question_id': 262261001},\n",
       " {'image_id': 262261,\n",
       "  'labels': [425],\n",
       "  'scores': [1],\n",
       "  'question_id': 262261002},\n",
       " {'image_id': 131190,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [1, 0.9],\n",
       "  'question_id': 131190000},\n",
       " {'image_id': 131190,\n",
       "  'labels': [1403],\n",
       "  'scores': [1],\n",
       "  'question_id': 131190001},\n",
       " {'image_id': 131190,\n",
       "  'labels': [425],\n",
       "  'scores': [1],\n",
       "  'question_id': 131190002},\n",
       " {'image_id': 131190,\n",
       "  'labels': [1333],\n",
       "  'scores': [1],\n",
       "  'question_id': 131190003},\n",
       " {'image_id': 131190,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [1, 1],\n",
       "  'question_id': 131190004},\n",
       " {'image_id': 131190,\n",
       "  'labels': [1405, 735, 2132, 1207, 2368, 990],\n",
       "  'scores': [0.6, 0.3, 0.3, 0.3, 0.3, 0.6],\n",
       "  'question_id': 131190005},\n",
       " {'image_id': 131190,\n",
       "  'labels': [1403],\n",
       "  'scores': [1],\n",
       "  'question_id': 131190006},\n",
       " {'image_id': 131190,\n",
       "  'labels': [425],\n",
       "  'scores': [1],\n",
       "  'question_id': 131190007},\n",
       " {'image_id': 131190,\n",
       "  'labels': [704, 1649, 3010, 399, 2739, 3006],\n",
       "  'scores': [0.6, 0.3, 0.9, 0.3, 0.3, 0.3],\n",
       "  'question_id': 131190008},\n",
       " {'image_id': 131190,\n",
       "  'labels': [2489, 1204, 3006, 2064, 1333],\n",
       "  'scores': [0.3, 0.3, 0.3, 0.3, 1],\n",
       "  'question_id': 131190009},\n",
       " {'image_id': 131190,\n",
       "  'labels': [2195],\n",
       "  'scores': [1],\n",
       "  'question_id': 131190010},\n",
       " {'image_id': 131190,\n",
       "  'labels': [98, 1076, 1927, 2679],\n",
       "  'scores': [0.3, 0.3, 0.3, 0.3],\n",
       "  'question_id': 131190011},\n",
       " {'image_id': 131190,\n",
       "  'labels': [2211, 2018, 1208, 860],\n",
       "  'scores': [0.3, 1, 0.6, 0.3],\n",
       "  'question_id': 131190012},\n",
       " {'image_id': 131190,\n",
       "  'labels': [2195],\n",
       "  'scores': [1],\n",
       "  'question_id': 131190013},\n",
       " {'image_id': 131190,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [1, 1],\n",
       "  'question_id': 131190014},\n",
       " {'image_id': 131190,\n",
       "  'labels': [425, 187, 1403],\n",
       "  'scores': [0.3, 0.3, 1],\n",
       "  'question_id': 131190015},\n",
       " {'image_id': 131190,\n",
       "  'labels': [123, 94, 674, 2595, 2274],\n",
       "  'scores': [0.3, 0.6, 0.6, 0.3, 0.6],\n",
       "  'question_id': 131190016},\n",
       " {'image_id': 131190,\n",
       "  'labels': [1403],\n",
       "  'scores': [1],\n",
       "  'question_id': 131190017},\n",
       " {'image_id': 131190,\n",
       "  'labels': [3006, 2697],\n",
       "  'scores': [1, 0.3],\n",
       "  'question_id': 131190018},\n",
       " {'image_id': 131190,\n",
       "  'labels': [3054, 2639, 1095],\n",
       "  'scores': [0.3, 0.3, 1],\n",
       "  'question_id': 131190019},\n",
       " {'image_id': 131190,\n",
       "  'labels': [2264, 2638, 575, 660, 2858],\n",
       "  'scores': [0.3, 1, 0.3, 0.9, 0.3],\n",
       "  'question_id': 131190020},\n",
       " {'image_id': 131190,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [1, 1],\n",
       "  'question_id': 131190021},\n",
       " {'image_id': 131190,\n",
       "  'labels': [444],\n",
       "  'scores': [1],\n",
       "  'question_id': 131190022},\n",
       " {'image_id': 131190,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [0.9, 1],\n",
       "  'question_id': 131190023},\n",
       " {'image_id': 131190,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [0.6, 1],\n",
       "  'question_id': 131190024},\n",
       " {'image_id': 131190,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [0.6, 1],\n",
       "  'question_id': 131190025},\n",
       " {'image_id': 131190,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [1, 0.9],\n",
       "  'question_id': 131190026},\n",
       " {'image_id': 131190,\n",
       "  'labels': [1403],\n",
       "  'scores': [1],\n",
       "  'question_id': 131190027},\n",
       " {'image_id': 131190,\n",
       "  'labels': [3031, 1239, 311, 1618],\n",
       "  'scores': [1, 0.6, 0.3, 0.9],\n",
       "  'question_id': 131190028},\n",
       " {'image_id': 131190,\n",
       "  'labels': [3031, 1239, 1618],\n",
       "  'scores': [0.6, 1, 1],\n",
       "  'question_id': 131190029},\n",
       " {'image_id': 131190,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [1, 1],\n",
       "  'question_id': 131190030},\n",
       " {'image_id': 131197,\n",
       "  'labels': [2177],\n",
       "  'scores': [0.6],\n",
       "  'question_id': 131197000},\n",
       " {'image_id': 131197, 'labels': [27], 'scores': [1], 'question_id': 131197001},\n",
       " {'image_id': 131197,\n",
       "  'labels': [821, 2140, 27, 2274],\n",
       "  'scores': [0.6, 0.3, 1, 0.3],\n",
       "  'question_id': 131197002},\n",
       " {'image_id': 131197,\n",
       "  'labels': [841],\n",
       "  'scores': [1],\n",
       "  'question_id': 131197003},\n",
       " {'image_id': 131197,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [1, 1],\n",
       "  'question_id': 131197004},\n",
       " {'image_id': 127,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [1, 0.3],\n",
       "  'question_id': 127000},\n",
       " {'image_id': 127, 'labels': [3006], 'scores': [1], 'question_id': 127001},\n",
       " {'image_id': 127, 'labels': [484], 'scores': [0.6], 'question_id': 127002},\n",
       " {'image_id': 262273,\n",
       "  'labels': [759, 2208],\n",
       "  'scores': [1, 0.3],\n",
       "  'question_id': 262273000},\n",
       " {'image_id': 262273,\n",
       "  'labels': [425],\n",
       "  'scores': [1],\n",
       "  'question_id': 262273001},\n",
       " {'image_id': 262273,\n",
       "  'labels': [707, 1429, 1008, 2806],\n",
       "  'scores': [0.3, 0.3, 1, 0.3],\n",
       "  'question_id': 262273002},\n",
       " {'image_id': 262273,\n",
       "  'labels': [1227, 1713],\n",
       "  'scores': [1, 0.3],\n",
       "  'question_id': 262273003},\n",
       " {'image_id': 262273,\n",
       "  'labels': [696, 2868, 425],\n",
       "  'scores': [1, 0.9, 0.3],\n",
       "  'question_id': 262273004},\n",
       " {'image_id': 262273,\n",
       "  'labels': [2195],\n",
       "  'scores': [1],\n",
       "  'question_id': 262273005},\n",
       " {'image_id': 262273,\n",
       "  'labels': [1403],\n",
       "  'scores': [1],\n",
       "  'question_id': 262273006},\n",
       " {'image_id': 262273,\n",
       "  'labels': [1138, 1227],\n",
       "  'scores': [0.3, 1],\n",
       "  'question_id': 262273007},\n",
       " {'image_id': 262273,\n",
       "  'labels': [2195],\n",
       "  'scores': [1],\n",
       "  'question_id': 262273008},\n",
       " {'image_id': 524420,\n",
       "  'labels': [1227],\n",
       "  'scores': [1],\n",
       "  'question_id': 524420000},\n",
       " {'image_id': 524420,\n",
       "  'labels': [425],\n",
       "  'scores': [1],\n",
       "  'question_id': 524420001},\n",
       " {'image_id': 524420,\n",
       "  'labels': [425],\n",
       "  'scores': [1],\n",
       "  'question_id': 524420002},\n",
       " {'image_id': 524420,\n",
       "  'labels': [425],\n",
       "  'scores': [1],\n",
       "  'question_id': 524420003},\n",
       " {'image_id': 524420,\n",
       "  'labels': [1954],\n",
       "  'scores': [1],\n",
       "  'question_id': 524420004},\n",
       " {'image_id': 436929,\n",
       "  'labels': [36, 280, 1395, 2984, 808, 2274],\n",
       "  'scores': [0.3, 0.6, 1, 0.3, 0.3, 0.3],\n",
       "  'question_id': 436929000},\n",
       " {'image_id': 436929,\n",
       "  'labels': [1403],\n",
       "  'scores': [1],\n",
       "  'question_id': 436929001},\n",
       " {'image_id': 436929,\n",
       "  'labels': [2621, 841],\n",
       "  'scores': [1, 0.3],\n",
       "  'question_id': 436929002},\n",
       " {'image_id': 436929,\n",
       "  'labels': [425, 2621, 1403],\n",
       "  'scores': [1, 0.3, 0.3],\n",
       "  'question_id': 436929003},\n",
       " {'image_id': 436929,\n",
       "  'labels': [1403],\n",
       "  'scores': [1],\n",
       "  'question_id': 436929004},\n",
       " {'image_id': 436929,\n",
       "  'labels': [425],\n",
       "  'scores': [1],\n",
       "  'question_id': 436929005},\n",
       " {'image_id': 436929,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [1, 1],\n",
       "  'question_id': 436929006},\n",
       " {'image_id': 131208,\n",
       "  'labels': [1874, 2640, 425],\n",
       "  'scores': [0.3, 0.3, 0.3],\n",
       "  'question_id': 131208000},\n",
       " {'image_id': 131208,\n",
       "  'labels': [425],\n",
       "  'scores': [1],\n",
       "  'question_id': 131208001},\n",
       " {'image_id': 131208,\n",
       "  'labels': [1204, 1491, 1333],\n",
       "  'scores': [0.3, 0.3, 1],\n",
       "  'question_id': 131208002},\n",
       " {'image_id': 284012,\n",
       "  'labels': [2069],\n",
       "  'scores': [1],\n",
       "  'question_id': 284012000},\n",
       " {'image_id': 284012,\n",
       "  'labels': [425],\n",
       "  'scores': [1],\n",
       "  'question_id': 284012001},\n",
       " {'image_id': 284012, 'labels': [], 'scores': [], 'question_id': 284012002},\n",
       " {'image_id': 284012,\n",
       "  'labels': [1433, 788, 1366, 933],\n",
       "  'scores': [0.9, 0.3, 0.3, 0.6],\n",
       "  'question_id': 284012003},\n",
       " {'image_id': 284012,\n",
       "  'labels': [1390, 3031, 1239, 1618],\n",
       "  'scores': [0.3, 1, 0.6, 0.3],\n",
       "  'question_id': 284012004},\n",
       " {'image_id': 284012,\n",
       "  'labels': [2638, 190],\n",
       "  'scores': [0.6, 0.6],\n",
       "  'question_id': 284012005},\n",
       " {'image_id': 284012,\n",
       "  'labels': [1880, 3006],\n",
       "  'scores': [1, 0.3],\n",
       "  'question_id': 284012006},\n",
       " {'image_id': 138, 'labels': [841], 'scores': [1], 'question_id': 138000},\n",
       " {'image_id': 138,\n",
       "  'labels': [945, 146, 148, 1846],\n",
       "  'scores': [0.3, 0.3, 1, 0.3],\n",
       "  'question_id': 138001},\n",
       " {'image_id': 138,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [0.6, 1],\n",
       "  'question_id': 138002},\n",
       " {'image_id': 262283,\n",
       "  'labels': [1013, 1204],\n",
       "  'scores': [1, 0.6],\n",
       "  'question_id': 262283000},\n",
       " {'image_id': 262283,\n",
       "  'labels': [425],\n",
       "  'scores': [1],\n",
       "  'question_id': 262283001},\n",
       " {'image_id': 262283, 'labels': [], 'scores': [], 'question_id': 262283002},\n",
       " {'image_id': 262283,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [1, 1],\n",
       "  'question_id': 262283003},\n",
       " {'image_id': 524428,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [1, 1],\n",
       "  'question_id': 524428000},\n",
       " {'image_id': 524428,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [0.9, 1],\n",
       "  'question_id': 524428001},\n",
       " {'image_id': 524428,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [1, 1],\n",
       "  'question_id': 524428002},\n",
       " {'image_id': 524428,\n",
       "  'labels': [1880, 3006],\n",
       "  'scores': [1, 0.3],\n",
       "  'question_id': 524428003},\n",
       " {'image_id': 262285,\n",
       "  'labels': [1989, 1990, 2769, 1992, 311, 703, 2063],\n",
       "  'scores': [0.3, 0.6, 0.3, 0.6, 0.6, 0.3, 0.3],\n",
       "  'question_id': 262285000},\n",
       " {'image_id': 262285,\n",
       "  'labels': [492],\n",
       "  'scores': [1],\n",
       "  'question_id': 262285001},\n",
       " {'image_id': 262285,\n",
       "  'labels': [1418, 17, 783, 1403],\n",
       "  'scores': [0.3, 0.3, 0.3, 1],\n",
       "  'question_id': 262285002},\n",
       " {'image_id': 262285,\n",
       "  'labels': [1403],\n",
       "  'scores': [1],\n",
       "  'question_id': 262285003},\n",
       " {'image_id': 262285,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [1, 1],\n",
       "  'question_id': 262285004},\n",
       " {'image_id': 142,\n",
       "  'labels': [1831, 960],\n",
       "  'scores': [1, 0.6],\n",
       "  'question_id': 142000},\n",
       " {'image_id': 142,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [1, 1],\n",
       "  'question_id': 142001},\n",
       " {'image_id': 142,\n",
       "  'labels': [411, 337],\n",
       "  'scores': [1, 0.6],\n",
       "  'question_id': 142002},\n",
       " {'image_id': 131215,\n",
       "  'labels': [1403],\n",
       "  'scores': [1],\n",
       "  'question_id': 131215000},\n",
       " {'image_id': 131215,\n",
       "  'labels': [425],\n",
       "  'scores': [1],\n",
       "  'question_id': 131215001},\n",
       " {'image_id': 131215,\n",
       "  'labels': [425],\n",
       "  'scores': [1],\n",
       "  'question_id': 131215002},\n",
       " {'image_id': 131215,\n",
       "  'labels': [606, 2711, 2449],\n",
       "  'scores': [1, 0.3, 0.6],\n",
       "  'question_id': 131215003},\n",
       " {'image_id': 131215,\n",
       "  'labels': [1302, 82, 563, 456],\n",
       "  'scores': [0.3, 0.3, 1, 0.3],\n",
       "  'question_id': 131215004},\n",
       " {'image_id': 144,\n",
       "  'labels': [2483, 1477, 2681, 1549, 2321],\n",
       "  'scores': [0.3, 0.3, 1, 0.3, 0.3],\n",
       "  'question_id': 144000},\n",
       " {'image_id': 144,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [1, 0.3],\n",
       "  'question_id': 144001},\n",
       " {'image_id': 144,\n",
       "  'labels': [991, 218],\n",
       "  'scores': [1, 0.3],\n",
       "  'question_id': 144002},\n",
       " {'image_id': 393362,\n",
       "  'labels': [425],\n",
       "  'scores': [1],\n",
       "  'question_id': 393362000},\n",
       " {'image_id': 393362,\n",
       "  'labels': [425],\n",
       "  'scores': [1],\n",
       "  'question_id': 393362001},\n",
       " {'image_id': 393362,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [1, 0.9],\n",
       "  'question_id': 393362002},\n",
       " {'image_id': 149, 'labels': [425], 'scores': [1], 'question_id': 149000},\n",
       " {'image_id': 149,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [0.9, 1],\n",
       "  'question_id': 149001},\n",
       " {'image_id': 149,\n",
       "  'labels': [2594, 1333],\n",
       "  'scores': [0.9, 1],\n",
       "  'question_id': 149002},\n",
       " {'image_id': 149, 'labels': [425], 'scores': [1], 'question_id': 149003},\n",
       " {'image_id': 149,\n",
       "  'labels': [444, 1403, 2785],\n",
       "  'scores': [1, 0.3, 0.3],\n",
       "  'question_id': 149004},\n",
       " {'image_id': 149,\n",
       "  'labels': [1537, 680, 436],\n",
       "  'scores': [0.6, 1, 0.6],\n",
       "  'question_id': 149005},\n",
       " {'image_id': 471373,\n",
       "  'labels': [1403],\n",
       "  'scores': [1],\n",
       "  'question_id': 471373000},\n",
       " {'image_id': 471373,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [0.9, 1],\n",
       "  'question_id': 471373001},\n",
       " {'image_id': 471373,\n",
       "  'labels': [1403],\n",
       "  'scores': [1],\n",
       "  'question_id': 471373002},\n",
       " {'image_id': 471373,\n",
       "  'labels': [425],\n",
       "  'scores': [1],\n",
       "  'question_id': 471373003},\n",
       " {'image_id': 471373,\n",
       "  'labels': [689],\n",
       "  'scores': [1],\n",
       "  'question_id': 471373004},\n",
       " {'image_id': 109986,\n",
       "  'labels': [1333],\n",
       "  'scores': [1],\n",
       "  'question_id': 109986000},\n",
       " {'image_id': 109986,\n",
       "  'labels': [2594, 1333],\n",
       "  'scores': [0.3, 1],\n",
       "  'question_id': 109986001},\n",
       " {'image_id': 109986,\n",
       "  'labels': [1333],\n",
       "  'scores': [1],\n",
       "  'question_id': 109986002},\n",
       " {'image_id': 131225, 'labels': [], 'scores': [], 'question_id': 131225000},\n",
       " {'image_id': 131225,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [0.3, 1],\n",
       "  'question_id': 131225001},\n",
       " {'image_id': 131225,\n",
       "  'labels': [411, 1427],\n",
       "  'scores': [0.3, 0.6],\n",
       "  'question_id': 131225002},\n",
       " {'image_id': 131225,\n",
       "  'labels': [735, 1403],\n",
       "  'scores': [0.3, 1],\n",
       "  'question_id': 131225003},\n",
       " {'image_id': 131225,\n",
       "  'labels': [1427, 1498],\n",
       "  'scores': [1, 0.6],\n",
       "  'question_id': 131225004},\n",
       " {'image_id': 131225,\n",
       "  'labels': [425],\n",
       "  'scores': [1],\n",
       "  'question_id': 131225005},\n",
       " {'image_id': 154,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [0.6, 1],\n",
       "  'question_id': 154000},\n",
       " {'image_id': 154,\n",
       "  'labels': [2195, 2621, 841],\n",
       "  'scores': [0.9, 1, 0.3],\n",
       "  'question_id': 154001},\n",
       " {'image_id': 154, 'labels': [2195], 'scores': [1], 'question_id': 154002},\n",
       " {'image_id': 154,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [0.6, 1],\n",
       "  'question_id': 154003},\n",
       " {'image_id': 154, 'labels': [2195], 'scores': [1], 'question_id': 154004},\n",
       " {'image_id': 154,\n",
       "  'labels': [2383, 2387, 383, 66],\n",
       "  'scores': [0.6, 1, 0.3, 0.3],\n",
       "  'question_id': 154005},\n",
       " {'image_id': 154, 'labels': [425], 'scores': [1], 'question_id': 154006},\n",
       " {'image_id': 154,\n",
       "  'labels': [1594, 1954],\n",
       "  'scores': [0.6, 1],\n",
       "  'question_id': 154007},\n",
       " {'image_id': 154,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [0.6, 1],\n",
       "  'question_id': 154008},\n",
       " {'image_id': 154, 'labels': [2621], 'scores': [1], 'question_id': 154009},\n",
       " {'image_id': 154, 'labels': [1403], 'scores': [1], 'question_id': 154010},\n",
       " {'image_id': 154,\n",
       "  'labels': [550, 783, 1418],\n",
       "  'scores': [0.3, 1, 0.6],\n",
       "  'question_id': 154011},\n",
       " {'image_id': 154, 'labels': [2621], 'scores': [1], 'question_id': 154012},\n",
       " {'image_id': 262299,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [0.3, 1],\n",
       "  'question_id': 262299000},\n",
       " {'image_id': 262299,\n",
       "  'labels': [759],\n",
       "  'scores': [1],\n",
       "  'question_id': 262299001},\n",
       " {'image_id': 262299,\n",
       "  'labels': [759],\n",
       "  'scores': [1],\n",
       "  'question_id': 262299002},\n",
       " {'image_id': 393242,\n",
       "  'labels': [2195, 2621, 841],\n",
       "  'scores': [1, 0.3, 0.3],\n",
       "  'question_id': 393242000},\n",
       " {'image_id': 393242,\n",
       "  'labels': [3031],\n",
       "  'scores': [1],\n",
       "  'question_id': 393242001},\n",
       " {'image_id': 393242,\n",
       "  'labels': [1403],\n",
       "  'scores': [1],\n",
       "  'question_id': 393242002},\n",
       " {'image_id': 393375,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [0.3, 1],\n",
       "  'question_id': 393375000},\n",
       " {'image_id': 393375,\n",
       "  'labels': [19, 2396],\n",
       "  'scores': [1, 1],\n",
       "  'question_id': 393375001},\n",
       " {'image_id': 393375,\n",
       "  'labels': [1824],\n",
       "  'scores': [1],\n",
       "  'question_id': 393375002},\n",
       " {'image_id': 393375, 'labels': [], 'scores': [], 'question_id': 393375003},\n",
       " {'image_id': 393379,\n",
       "  'labels': [2649],\n",
       "  'scores': [0.3],\n",
       "  'question_id': 393379000},\n",
       " {'image_id': 393379,\n",
       "  'labels': [2529],\n",
       "  'scores': [1],\n",
       "  'question_id': 393379001},\n",
       " {'image_id': 393379,\n",
       "  'labels': [1403],\n",
       "  'scores': [0.9],\n",
       "  'question_id': 393379002},\n",
       " {'image_id': 262308,\n",
       "  'labels': [411, 3110, 2505, 1250, 755, 3006],\n",
       "  'scores': [0.3, 0.6, 0.3, 0.3, 0.3, 0.3],\n",
       "  'question_id': 262308000},\n",
       " {'image_id': 262308,\n",
       "  'labels': [1403],\n",
       "  'scores': [1],\n",
       "  'question_id': 262308001},\n",
       " {'image_id': 262308,\n",
       "  'labels': [425],\n",
       "  'scores': [1],\n",
       "  'question_id': 262308002},\n",
       " {'image_id': 262308,\n",
       "  'labels': [1080, 1944, 2751],\n",
       "  'scores': [1, 0.3, 0.3],\n",
       "  'question_id': 262308003},\n",
       " {'image_id': 262308,\n",
       "  'labels': [3110, 3006, 1414],\n",
       "  'scores': [1, 0.3, 0.6],\n",
       "  'question_id': 262308004},\n",
       " {'image_id': 165, 'labels': [2903], 'scores': [0.6], 'question_id': 165000},\n",
       " {'image_id': 165, 'labels': [425], 'scores': [1], 'question_id': 165001},\n",
       " {'image_id': 165, 'labels': [425], 'scores': [1], 'question_id': 165002},\n",
       " {'image_id': 415089,\n",
       "  'labels': [2621, 841],\n",
       "  'scores': [1, 0.9],\n",
       "  'question_id': 415089000},\n",
       " {'image_id': 415089,\n",
       "  'labels': [2195, 444, 2621, 841],\n",
       "  'scores': [1, 0.3, 0.9, 0.3],\n",
       "  'question_id': 415089001},\n",
       " {'image_id': 415089,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [1, 1],\n",
       "  'question_id': 415089002},\n",
       " {'image_id': 415089,\n",
       "  'labels': [2811, 275],\n",
       "  'scores': [0.3, 1],\n",
       "  'question_id': 415089003},\n",
       " {'image_id': 415089,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [0.6, 1],\n",
       "  'question_id': 415089004},\n",
       " {'image_id': 393384,\n",
       "  'labels': [2056, 2608, 1805, 1725, 2838],\n",
       "  'scores': [0.3, 1, 0.3, 0.3, 0.3],\n",
       "  'question_id': 393384000},\n",
       " {'image_id': 393384,\n",
       "  'labels': [444, 2621, 841, 1239, 1618],\n",
       "  'scores': [0.3, 1, 0.9, 0.3, 0.3],\n",
       "  'question_id': 393384001},\n",
       " {'image_id': 393384,\n",
       "  'labels': [1403],\n",
       "  'scores': [1],\n",
       "  'question_id': 393384002},\n",
       " {'image_id': 393386,\n",
       "  'labels': [3031, 1239],\n",
       "  'scores': [1, 0.6],\n",
       "  'question_id': 393386000},\n",
       " {'image_id': 393386,\n",
       "  'labels': [2594, 1227],\n",
       "  'scores': [0.3, 1],\n",
       "  'question_id': 393386001},\n",
       " {'image_id': 393386,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [0.3, 1],\n",
       "  'question_id': 393386002},\n",
       " {'image_id': 131245,\n",
       "  'labels': [1820, 1001],\n",
       "  'scores': [1, 0.6],\n",
       "  'question_id': 131245000},\n",
       " {'image_id': 131245,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [0.3, 1],\n",
       "  'question_id': 131245001},\n",
       " {'image_id': 131245,\n",
       "  'labels': [595],\n",
       "  'scores': [1],\n",
       "  'question_id': 131245002},\n",
       " {'image_id': 137918,\n",
       "  'labels': [425],\n",
       "  'scores': [1],\n",
       "  'question_id': 137918000},\n",
       " {'image_id': 137918,\n",
       "  'labels': [2621],\n",
       "  'scores': [1],\n",
       "  'question_id': 137918001},\n",
       " {'image_id': 137918,\n",
       "  'labels': [3026, 1309],\n",
       "  'scores': [0.6, 1],\n",
       "  'question_id': 137918002},\n",
       " {'image_id': 393394, 'labels': [36], 'scores': [1], 'question_id': 393394000},\n",
       " {'image_id': 393394,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [1, 0.6],\n",
       "  'question_id': 393394001},\n",
       " {'image_id': 393394,\n",
       "  'labels': [254, 1678, 2287, 1309, 3026],\n",
       "  'scores': [0.3, 0.3, 0.9, 0.3, 0.3],\n",
       "  'question_id': 393394002},\n",
       " {'image_id': 393394,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [1, 0.3],\n",
       "  'question_id': 393394003},\n",
       " {'image_id': 438196,\n",
       "  'labels': [425],\n",
       "  'scores': [1],\n",
       "  'question_id': 438196000},\n",
       " {'image_id': 438196,\n",
       "  'labels': [425],\n",
       "  'scores': [1],\n",
       "  'question_id': 438196001},\n",
       " {'image_id': 438196,\n",
       "  'labels': [1598, 2172, 2174, 2269, 2170, 1805],\n",
       "  'scores': [0.3, 0.3, 0.6, 0.3, 0.3, 0.6],\n",
       "  'question_id': 438196002},\n",
       " {'image_id': 393396,\n",
       "  'labels': [425],\n",
       "  'scores': [1],\n",
       "  'question_id': 393396000},\n",
       " {'image_id': 393396,\n",
       "  'labels': [2531],\n",
       "  'scores': [1],\n",
       "  'question_id': 393396001},\n",
       " {'image_id': 393396,\n",
       "  'labels': [425],\n",
       "  'scores': [1],\n",
       "  'question_id': 393396002},\n",
       " {'image_id': 393396,\n",
       "  'labels': [1880, 2594, 1227, 1491, 1333],\n",
       "  'scores': [0.9, 0.6, 0.3, 0.3, 0.3],\n",
       "  'question_id': 393396003},\n",
       " {'image_id': 393396,\n",
       "  'labels': [1508],\n",
       "  'scores': [1],\n",
       "  'question_id': 393396004},\n",
       " {'image_id': 393396,\n",
       "  'labels': [1403],\n",
       "  'scores': [1],\n",
       "  'question_id': 393396005},\n",
       " {'image_id': 393396,\n",
       "  'labels': [1403],\n",
       "  'scores': [1],\n",
       "  'question_id': 393396006},\n",
       " {'image_id': 524470,\n",
       "  'labels': [425],\n",
       "  'scores': [1],\n",
       "  'question_id': 524470000},\n",
       " {'image_id': 524470,\n",
       "  'labels': [425],\n",
       "  'scores': [1],\n",
       "  'question_id': 524470001},\n",
       " {'image_id': 524470,\n",
       "  'labels': [1403],\n",
       "  'scores': [1],\n",
       "  'question_id': 524470002},\n",
       " {'image_id': 524471,\n",
       "  'labels': [301, 1084, 353, 2593, 2005],\n",
       "  'scores': [0.3, 0.3, 0.6, 0.3, 0.3],\n",
       "  'question_id': 524471000},\n",
       " {'image_id': 524471,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [1, 0.3],\n",
       "  'question_id': 524471001},\n",
       " {'image_id': 524471,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [1, 0.6],\n",
       "  'question_id': 524471002},\n",
       " {'image_id': 524471,\n",
       "  'labels': [1208, 1649, 3010, 1713],\n",
       "  'scores': [1, 0.3, 0.3, 0.3],\n",
       "  'question_id': 524471003},\n",
       " {'image_id': 524471,\n",
       "  'labels': [425, 750, 1403],\n",
       "  'scores': [0.3, 0.3, 1],\n",
       "  'question_id': 524471004},\n",
       " {'image_id': 524471,\n",
       "  'labels': [2195, 2621, 841, 3031, 1239],\n",
       "  'scores': [0.3, 0.9, 0.3, 0.3, 1],\n",
       "  'question_id': 524471005},\n",
       " {'image_id': 524471,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [0.9, 1],\n",
       "  'question_id': 524471006},\n",
       " {'image_id': 524471,\n",
       "  'labels': [425],\n",
       "  'scores': [1],\n",
       "  'question_id': 524471007},\n",
       " {'image_id': 262329,\n",
       "  'labels': [1204, 2542],\n",
       "  'scores': [1, 0.3],\n",
       "  'question_id': 262329000},\n",
       " {'image_id': 262329,\n",
       "  'labels': [1623, 2472, 1979],\n",
       "  'scores': [0.3, 0.3, 1],\n",
       "  'question_id': 262329001},\n",
       " {'image_id': 262329,\n",
       "  'labels': [2858, 2595, 3010, 2455, 1643],\n",
       "  'scores': [0.6, 0.3, 0.3, 0.3, 0.3],\n",
       "  'question_id': 262329002},\n",
       " {'image_id': 393403,\n",
       "  'labels': [2195, 841],\n",
       "  'scores': [1, 1],\n",
       "  'question_id': 393403000},\n",
       " {'image_id': 393403,\n",
       "  'labels': [425],\n",
       "  'scores': [1],\n",
       "  'question_id': 393403001},\n",
       " {'image_id': 393403,\n",
       "  'labels': [1403],\n",
       "  'scores': [1],\n",
       "  'question_id': 393403002},\n",
       " {'image_id': 393403,\n",
       "  'labels': [2489, 113, 1047],\n",
       "  'scores': [0.3, 0.6, 0.9],\n",
       "  'question_id': 393403003},\n",
       " {'image_id': 393403, 'labels': [], 'scores': [], 'question_id': 393403004},\n",
       " {'image_id': 393403,\n",
       "  'labels': [1353, 2494],\n",
       "  'scores': [0.6, 0.9],\n",
       "  'question_id': 393403005},\n",
       " {'image_id': 393403,\n",
       "  'labels': [1403],\n",
       "  'scores': [1],\n",
       "  'question_id': 393403006},\n",
       " {'image_id': 393403,\n",
       "  'labels': [841],\n",
       "  'scores': [1],\n",
       "  'question_id': 393403007},\n",
       " {'image_id': 524476,\n",
       "  'labels': [425],\n",
       "  'scores': [1],\n",
       "  'question_id': 524476000},\n",
       " {'image_id': 524476,\n",
       "  'labels': [775],\n",
       "  'scores': [1],\n",
       "  'question_id': 524476001},\n",
       " {'image_id': 524476,\n",
       "  'labels': [2330, 84, 1930],\n",
       "  'scores': [1, 0.3, 0.3],\n",
       "  'question_id': 524476002},\n",
       " {'image_id': 283700,\n",
       "  'labels': [2745, 2405, 2073],\n",
       "  'scores': [0.6, 1, 0.3],\n",
       "  'question_id': 283700000},\n",
       " {'image_id': 283700,\n",
       "  'labels': [1988, 2769, 3031, 311, 1618, 2063, 187],\n",
       "  'scores': [0.6, 0.3, 0.3, 0.3, 0.3, 0.6, 0.3],\n",
       "  'question_id': 283700001},\n",
       " {'image_id': 283700,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [0.9, 1],\n",
       "  'question_id': 283700002},\n",
       " {'image_id': 262336,\n",
       "  'labels': [425],\n",
       "  'scores': [1],\n",
       "  'question_id': 262336000},\n",
       " {'image_id': 262336,\n",
       "  'labels': [1403],\n",
       "  'scores': [1],\n",
       "  'question_id': 262336001},\n",
       " {'image_id': 262336,\n",
       "  'labels': [411, 1403],\n",
       "  'scores': [0.3, 1],\n",
       "  'question_id': 262336002},\n",
       " {'image_id': 194, 'labels': [3006], 'scores': [1], 'question_id': 194000},\n",
       " {'image_id': 194,\n",
       "  'labels': [806, 781, 1944],\n",
       "  'scores': [0.9, 0.9, 0.3],\n",
       "  'question_id': 194001},\n",
       " {'image_id': 194, 'labels': [425], 'scores': [1], 'question_id': 194002},\n",
       " {'image_id': 257513,\n",
       "  'labels': [1577, 1132, 445, 221],\n",
       "  'scores': [0.6, 0.3, 0.3, 1],\n",
       "  'question_id': 257513000},\n",
       " {'image_id': 257513,\n",
       "  'labels': [425, 3010],\n",
       "  'scores': [1, 0.3],\n",
       "  'question_id': 257513001},\n",
       " {'image_id': 257513,\n",
       "  'labels': [425],\n",
       "  'scores': [1],\n",
       "  'question_id': 257513002},\n",
       " {'image_id': 257513,\n",
       "  'labels': [2621, 841],\n",
       "  'scores': [1, 1],\n",
       "  'question_id': 257513003},\n",
       " {'image_id': 257513,\n",
       "  'labels': [2947],\n",
       "  'scores': [1],\n",
       "  'question_id': 257513004},\n",
       " {'image_id': 393412,\n",
       "  'labels': [425],\n",
       "  'scores': [1],\n",
       "  'question_id': 393412000},\n",
       " {'image_id': 393412,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [0.3, 1],\n",
       "  'question_id': 393412001},\n",
       " {'image_id': 393412,\n",
       "  'labels': [1491, 2052],\n",
       "  'scores': [1, 0.3],\n",
       "  'question_id': 393412002},\n",
       " {'image_id': 524486,\n",
       "  'labels': [3023],\n",
       "  'scores': [1],\n",
       "  'question_id': 524486000},\n",
       " {'image_id': 524486,\n",
       "  'labels': [2827, 3026, 425],\n",
       "  'scores': [0.3, 0.3, 0.3],\n",
       "  'question_id': 524486001},\n",
       " {'image_id': 524486,\n",
       "  'labels': [1854, 373, 872],\n",
       "  'scores': [0.3, 0.6, 0.3],\n",
       "  'question_id': 524486002},\n",
       " {'image_id': 458785,\n",
       "  'labels': [1403],\n",
       "  'scores': [0.3],\n",
       "  'question_id': 458785000},\n",
       " {'image_id': 458785,\n",
       "  'labels': [3059, 2385, 2472, 505, 1624, 2435, 148],\n",
       "  'scores': [0.3, 0.3, 0.9, 0.3, 0.3, 0.3, 0.3],\n",
       "  'question_id': 458785001},\n",
       " {'image_id': 458785,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [0.6, 1],\n",
       "  'question_id': 458785002},\n",
       " {'image_id': 201, 'labels': [425], 'scores': [1], 'question_id': 201000},\n",
       " {'image_id': 201,\n",
       "  'labels': [3031, 1618],\n",
       "  'scores': [1, 0.3],\n",
       "  'question_id': 201001},\n",
       " {'image_id': 201, 'labels': [2917], 'scores': [0.3], 'question_id': 201002},\n",
       " {'image_id': 393418, 'labels': [54], 'scores': [1], 'question_id': 393418000},\n",
       " {'image_id': 393418,\n",
       "  'labels': [226],\n",
       "  'scores': [1],\n",
       "  'question_id': 393418001},\n",
       " {'image_id': 393418,\n",
       "  'labels': [5, 157],\n",
       "  'scores': [1, 0.3],\n",
       "  'question_id': 393418002},\n",
       " {'image_id': 393419,\n",
       "  'labels': [2228, 266],\n",
       "  'scores': [0.3, 1],\n",
       "  'question_id': 393419000},\n",
       " {'image_id': 393419,\n",
       "  'labels': [1227, 3006, 2324],\n",
       "  'scores': [0.3, 0.3, 1],\n",
       "  'question_id': 393419001},\n",
       " {'image_id': 393419, 'labels': [], 'scores': [], 'question_id': 393419002},\n",
       " {'image_id': 393419,\n",
       "  'labels': [2387, 2785],\n",
       "  'scores': [0.6, 1],\n",
       "  'question_id': 393419003},\n",
       " {'image_id': 393419,\n",
       "  'labels': [2117, 2305, 3109],\n",
       "  'scores': [0.6, 0.3, 0.6],\n",
       "  'question_id': 393419004},\n",
       " {'image_id': 131277,\n",
       "  'labels': [1403],\n",
       "  'scores': [1],\n",
       "  'question_id': 131277000},\n",
       " {'image_id': 131277,\n",
       "  'labels': [425],\n",
       "  'scores': [1],\n",
       "  'question_id': 131277001},\n",
       " {'image_id': 131277,\n",
       "  'labels': [1403],\n",
       "  'scores': [1],\n",
       "  'question_id': 131277002},\n",
       " {'image_id': 131277,\n",
       "  'labels': [425],\n",
       "  'scores': [1],\n",
       "  'question_id': 131277003},\n",
       " {'image_id': 131277,\n",
       "  'labels': [1403],\n",
       "  'scores': [1],\n",
       "  'question_id': 131277004},\n",
       " {'image_id': 393422,\n",
       "  'labels': [425],\n",
       "  'scores': [1],\n",
       "  'question_id': 393422000},\n",
       " {'image_id': 393422,\n",
       "  'labels': [1403],\n",
       "  'scores': [1],\n",
       "  'question_id': 393422001},\n",
       " {'image_id': 393422,\n",
       "  'labels': [935],\n",
       "  'scores': [1],\n",
       "  'question_id': 393422002},\n",
       " {'image_id': 393422,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [1, 0.3],\n",
       "  'question_id': 393422003},\n",
       " {'image_id': 131279,\n",
       "  'labels': [2671, 2387, 1403, 1141, 425, 2785],\n",
       "  'scores': [0.3, 0.3, 0.3, 0.9, 0.3, 0.3],\n",
       "  'question_id': 131279000},\n",
       " {'image_id': 131279,\n",
       "  'labels': [466, 1015, 2079, 1598, 1805, 1908],\n",
       "  'scores': [0.3, 0.3, 0.3, 0.6, 0.3, 0.6],\n",
       "  'question_id': 131279001},\n",
       " {'image_id': 131279,\n",
       "  'labels': [1403],\n",
       "  'scores': [1],\n",
       "  'question_id': 131279002},\n",
       " {'image_id': 131279,\n",
       "  'labels': [425, 187, 1403],\n",
       "  'scores': [1, 0.3, 0.9],\n",
       "  'question_id': 131279003},\n",
       " {'image_id': 131279,\n",
       "  'labels': [2621, 841],\n",
       "  'scores': [0.3, 1],\n",
       "  'question_id': 131279004},\n",
       " {'image_id': 131279,\n",
       "  'labels': [1403],\n",
       "  'scores': [1],\n",
       "  'question_id': 131279005},\n",
       " {'image_id': 131279,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [0.6, 1],\n",
       "  'question_id': 131279006},\n",
       " {'image_id': 131279,\n",
       "  'labels': [411],\n",
       "  'scores': [1],\n",
       "  'question_id': 131279007},\n",
       " {'image_id': 131279,\n",
       "  'labels': [2081, 2810, 2456, 1174, 564],\n",
       "  'scores': [0.6, 0.3, 0.3, 0.3, 1],\n",
       "  'question_id': 131279008},\n",
       " {'image_id': 131279,\n",
       "  'labels': [411],\n",
       "  'scores': [1],\n",
       "  'question_id': 131279009},\n",
       " {'image_id': 131279,\n",
       "  'labels': [1403],\n",
       "  'scores': [1],\n",
       "  'question_id': 131279010},\n",
       " {'image_id': 131279, 'labels': [75], 'scores': [1], 'question_id': 131279011},\n",
       " {'image_id': 448671,\n",
       "  'labels': [2730, 259, 2786, 1309],\n",
       "  'scores': [0.3, 0.3, 0.3, 0.9],\n",
       "  'question_id': 448671000},\n",
       " {'image_id': 448671,\n",
       "  'labels': [2976, 425],\n",
       "  'scores': [1, 0.3],\n",
       "  'question_id': 448671001},\n",
       " {'image_id': 448671,\n",
       "  'labels': [1403],\n",
       "  'scores': [1],\n",
       "  'question_id': 448671002},\n",
       " {'image_id': 393428,\n",
       "  'labels': [158],\n",
       "  'scores': [1],\n",
       "  'question_id': 393428000},\n",
       " {'image_id': 393428,\n",
       "  'labels': [2594, 3090, 1892],\n",
       "  'scores': [1, 0.6, 0.3],\n",
       "  'question_id': 393428001},\n",
       " {'image_id': 393428,\n",
       "  'labels': [2730, 1177, 1309, 3026, 2785],\n",
       "  'scores': [0.3, 0.3, 0.9, 0.9, 0.3],\n",
       "  'question_id': 393428002},\n",
       " {'image_id': 393428,\n",
       "  'labels': [2195, 2274, 187],\n",
       "  'scores': [0.6, 0.3, 0.3],\n",
       "  'question_id': 393428003},\n",
       " {'image_id': 554301,\n",
       "  'labels': [554, 2440, 956, 733],\n",
       "  'scores': [0.6, 0.3, 0.3, 1],\n",
       "  'question_id': 554301000},\n",
       " {'image_id': 554301,\n",
       "  'labels': [841, 3031, 311, 1618],\n",
       "  'scores': [0.3, 0.3, 0.3, 1],\n",
       "  'question_id': 554301001},\n",
       " {'image_id': 554301,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [1, 0.3],\n",
       "  'question_id': 554301002},\n",
       " {'image_id': 262359,\n",
       "  'labels': [425],\n",
       "  'scores': [1],\n",
       "  'question_id': 262359000},\n",
       " {'image_id': 262359,\n",
       "  'labels': [1040, 2520, 589],\n",
       "  'scores': [0.3, 0.9, 0.6],\n",
       "  'question_id': 262359001},\n",
       " {'image_id': 262359,\n",
       "  'labels': [515],\n",
       "  'scores': [1],\n",
       "  'question_id': 262359002},\n",
       " {'image_id': 262359,\n",
       "  'labels': [775],\n",
       "  'scores': [1],\n",
       "  'question_id': 262359003},\n",
       " {'image_id': 262359,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [1, 0.6],\n",
       "  'question_id': 262359004},\n",
       " {'image_id': 262359,\n",
       "  'labels': [1403],\n",
       "  'scores': [1],\n",
       "  'question_id': 262359005},\n",
       " {'image_id': 262359,\n",
       "  'labels': [2621, 841, 1994],\n",
       "  'scores': [0.3, 1, 0.3],\n",
       "  'question_id': 262359006},\n",
       " {'image_id': 262359,\n",
       "  'labels': [1403],\n",
       "  'scores': [1],\n",
       "  'question_id': 262359007},\n",
       " {'image_id': 262359,\n",
       "  'labels': [1557, 1188, 515],\n",
       "  'scores': [0.6, 0.6, 1],\n",
       "  'question_id': 262359008},\n",
       " {'image_id': 393432,\n",
       "  'labels': [1770],\n",
       "  'scores': [1],\n",
       "  'question_id': 393432000},\n",
       " {'image_id': 393432,\n",
       "  'labels': [728, 1132],\n",
       "  'scores': [1, 1],\n",
       "  'question_id': 393432001},\n",
       " {'image_id': 393432,\n",
       "  'labels': [425],\n",
       "  'scores': [1],\n",
       "  'question_id': 393432002},\n",
       " {'image_id': 393432,\n",
       "  'labels': [411, 1880, 990, 1227],\n",
       "  'scores': [1, 0.3, 1, 0.3],\n",
       "  'question_id': 393432003},\n",
       " {'image_id': 36, 'labels': [425], 'scores': [1], 'question_id': 36000},\n",
       " {'image_id': 36, 'labels': [1204], 'scores': [1], 'question_id': 36001},\n",
       " {'image_id': 36, 'labels': [668], 'scores': [0.6], 'question_id': 36002},\n",
       " {'image_id': 524508,\n",
       "  'labels': [2621],\n",
       "  'scores': [1],\n",
       "  'question_id': 524508000},\n",
       " {'image_id': 524508,\n",
       "  'labels': [2621],\n",
       "  'scores': [1],\n",
       "  'question_id': 524508001},\n",
       " {'image_id': 524508,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [1, 0.3],\n",
       "  'question_id': 524508002},\n",
       " {'image_id': 524508,\n",
       "  'labels': [2984, 425, 1403],\n",
       "  'scores': [0.3, 1, 0.3],\n",
       "  'question_id': 524508003},\n",
       " {'image_id': 474858,\n",
       "  'labels': [89, 1725, 1751],\n",
       "  'scores': [1, 0.6, 0.3],\n",
       "  'question_id': 474858000},\n",
       " {'image_id': 474858,\n",
       "  'labels': [1403],\n",
       "  'scores': [1],\n",
       "  'question_id': 474858001},\n",
       " {'image_id': 474858,\n",
       "  'labels': [3006, 1227, 3090, 893],\n",
       "  'scores': [1, 0.3, 0.3, 0.3],\n",
       "  'question_id': 474858002},\n",
       " {'image_id': 474858,\n",
       "  'labels': [1962, 689, 604, 2984],\n",
       "  'scores': [0.3, 0.6, 1, 0.3],\n",
       "  'question_id': 474858003},\n",
       " {'image_id': 474858,\n",
       "  'labels': [2170, 2269, 1912, 2273, 2354, 1025, 2188],\n",
       "  'scores': [0.3, 0.3, 0.3, 0.3, 0.3, 0.6, 0.6],\n",
       "  'question_id': 474858004},\n",
       " {'image_id': 474858,\n",
       "  'labels': [425, 750, 1403],\n",
       "  'scores': [1, 0.3, 0.3],\n",
       "  'question_id': 474858005},\n",
       " {'image_id': 474858,\n",
       "  'labels': [1403],\n",
       "  'scores': [1],\n",
       "  'question_id': 474858006},\n",
       " {'image_id': 474858,\n",
       "  'labels': [89, 1725],\n",
       "  'scores': [1, 1],\n",
       "  'question_id': 474858007},\n",
       " {'image_id': 474858,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [0.9, 1],\n",
       "  'question_id': 474858008},\n",
       " {'image_id': 474858,\n",
       "  'labels': [631, 89, 2425, 689],\n",
       "  'scores': [0.3, 0.3, 0.6, 1],\n",
       "  'question_id': 474858009},\n",
       " {'image_id': 474858,\n",
       "  'labels': [2873],\n",
       "  'scores': [1],\n",
       "  'question_id': 474858010},\n",
       " {'image_id': 474858,\n",
       "  'labels': [2014, 603, 735, 82, 999],\n",
       "  'scores': [0.3, 0.3, 0.3, 0.3, 0.3],\n",
       "  'question_id': 474858011},\n",
       " {'image_id': 474858,\n",
       "  'labels': [425],\n",
       "  'scores': [1],\n",
       "  'question_id': 474858012},\n",
       " {'image_id': 474858,\n",
       "  'labels': [425],\n",
       "  'scores': [1],\n",
       "  'question_id': 474858013},\n",
       " {'image_id': 474858,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [1, 1],\n",
       "  'question_id': 474858014},\n",
       " {'image_id': 474858,\n",
       "  'labels': [1403],\n",
       "  'scores': [1],\n",
       "  'question_id': 474858015},\n",
       " {'image_id': 474858,\n",
       "  'labels': [425],\n",
       "  'scores': [1],\n",
       "  'question_id': 474858016},\n",
       " {'image_id': 474858,\n",
       "  'labels': [1403],\n",
       "  'scores': [1],\n",
       "  'question_id': 474858017},\n",
       " {'image_id': 474858,\n",
       "  'labels': [931, 387, 444, 1403, 2195, 1725, 1968],\n",
       "  'scores': [0.3, 0.3, 0.3, 0.9, 0.3, 0.3, 0.3],\n",
       "  'question_id': 474858018},\n",
       " {'image_id': 474858,\n",
       "  'labels': [2880, 1403, 2705, 462],\n",
       "  'scores': [0.3, 0.6, 0.3, 0.3],\n",
       "  'question_id': 474858019},\n",
       " {'image_id': 474858,\n",
       "  'labels': [425],\n",
       "  'scores': [1],\n",
       "  'question_id': 474858020},\n",
       " {'image_id': 474858,\n",
       "  'labels': [681, 1607, 3069, 2511, 3006],\n",
       "  'scores': [0.3, 0.3, 0.9, 0.3, 0.3],\n",
       "  'question_id': 474858021},\n",
       " {'image_id': 474858,\n",
       "  'labels': [931, 51, 2321, 1783],\n",
       "  'scores': [0.6, 0.6, 0.3, 0.6],\n",
       "  'question_id': 474858022},\n",
       " {'image_id': 474858,\n",
       "  'labels': [2456],\n",
       "  'scores': [1],\n",
       "  'question_id': 474858023},\n",
       " {'image_id': 474858,\n",
       "  'labels': [387],\n",
       "  'scores': [1],\n",
       "  'question_id': 474858024},\n",
       " {'image_id': 474858,\n",
       "  'labels': [1227],\n",
       "  'scores': [1],\n",
       "  'question_id': 474858025},\n",
       " {'image_id': 474858,\n",
       "  'labels': [2241, 2489, 3006],\n",
       "  'scores': [0.3, 0.6, 1],\n",
       "  'question_id': 474858026},\n",
       " {'image_id': 393438,\n",
       "  'labels': [2195, 1239],\n",
       "  'scores': [1, 0.3],\n",
       "  'question_id': 393438000},\n",
       " {'image_id': 393438, 'labels': [], 'scores': [], 'question_id': 393438001},\n",
       " {'image_id': 393438,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [0.3, 1],\n",
       "  'question_id': 393438002},\n",
       " {'image_id': 165859,\n",
       "  'labels': [1491, 1333],\n",
       "  'scores': [0.6, 1],\n",
       "  'question_id': 165859000},\n",
       " {'image_id': 165859,\n",
       "  'labels': [425],\n",
       "  'scores': [1],\n",
       "  'question_id': 165859001},\n",
       " {'image_id': 165859,\n",
       "  'labels': [299, 1095],\n",
       "  'scores': [1, 0.3],\n",
       "  'question_id': 165859002},\n",
       " {'image_id': 39288,\n",
       "  'labels': [526, 2305, 2104],\n",
       "  'scores': [0.9, 1, 0.3],\n",
       "  'question_id': 39288000},\n",
       " {'image_id': 39288,\n",
       "  'labels': [1808, 1831, 960],\n",
       "  'scores': [1, 1, 0.3],\n",
       "  'question_id': 39288001},\n",
       " {'image_id': 39288,\n",
       "  'labels': [1756],\n",
       "  'scores': [0.3],\n",
       "  'question_id': 39288002},\n",
       " {'image_id': 393442,\n",
       "  'labels': [1491, 1333],\n",
       "  'scores': [1, 0.9],\n",
       "  'question_id': 393442000},\n",
       " {'image_id': 393442,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [1, 0.3],\n",
       "  'question_id': 393442001},\n",
       " {'image_id': 393442,\n",
       "  'labels': [2195, 444, 2621, 841],\n",
       "  'scores': [0.6, 0.3, 1, 0.3],\n",
       "  'question_id': 393442002},\n",
       " {'image_id': 131299,\n",
       "  'labels': [1768, 1265],\n",
       "  'scores': [0.9, 0.9],\n",
       "  'question_id': 131299000},\n",
       " {'image_id': 131299,\n",
       "  'labels': [425],\n",
       "  'scores': [1],\n",
       "  'question_id': 131299001},\n",
       " {'image_id': 131299,\n",
       "  'labels': [2621, 1239, 1618],\n",
       "  'scores': [0.3, 1, 0.6],\n",
       "  'question_id': 131299002},\n",
       " {'image_id': 131300,\n",
       "  'labels': [1983, 2529, 2511, 2365],\n",
       "  'scores': [1, 0.3, 0.3, 0.3],\n",
       "  'question_id': 131300000},\n",
       " {'image_id': 131300,\n",
       "  'labels': [1403],\n",
       "  'scores': [1],\n",
       "  'question_id': 131300001},\n",
       " {'image_id': 131300,\n",
       "  'labels': [1403],\n",
       "  'scores': [1],\n",
       "  'question_id': 131300002},\n",
       " {'image_id': 131300,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [1, 0.6],\n",
       "  'question_id': 131300003},\n",
       " {'image_id': 131300,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [1, 1],\n",
       "  'question_id': 131300004},\n",
       " {'image_id': 393445,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [1, 0.3],\n",
       "  'question_id': 393445000},\n",
       " {'image_id': 393445,\n",
       "  'labels': [3006],\n",
       "  'scores': [1],\n",
       "  'question_id': 393445001},\n",
       " {'image_id': 393445,\n",
       "  'labels': [1414],\n",
       "  'scores': [1],\n",
       "  'question_id': 393445002},\n",
       " {'image_id': 524518,\n",
       "  'labels': [2665, 3006, 445],\n",
       "  'scores': [0.9, 0.3, 1],\n",
       "  'question_id': 524518000},\n",
       " {'image_id': 524518,\n",
       "  'labels': [425],\n",
       "  'scores': [1],\n",
       "  'question_id': 524518001},\n",
       " {'image_id': 524518,\n",
       "  'labels': [157, 1553, 6],\n",
       "  'scores': [0.3, 0.3, 0.3],\n",
       "  'question_id': 524518002},\n",
       " {'image_id': 524518,\n",
       "  'labels': [425],\n",
       "  'scores': [1],\n",
       "  'question_id': 524518003},\n",
       " {'image_id': 524518,\n",
       "  'labels': [589, 2520],\n",
       "  'scores': [0.9, 0.9],\n",
       "  'question_id': 524518004},\n",
       " {'image_id': 524518,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [0.3, 1],\n",
       "  'question_id': 524518005},\n",
       " {'image_id': 524520,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [0.9, 1],\n",
       "  'question_id': 524520000},\n",
       " {'image_id': 524520,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [0.3, 1],\n",
       "  'question_id': 524520001},\n",
       " {'image_id': 524520,\n",
       "  'labels': [935],\n",
       "  'scores': [0.6],\n",
       "  'question_id': 524520002},\n",
       " {'image_id': 524520,\n",
       "  'labels': [1076, 261],\n",
       "  'scores': [1, 0.3],\n",
       "  'question_id': 524520003},\n",
       " {'image_id': 524520,\n",
       "  'labels': [2387, 935, 1333],\n",
       "  'scores': [0.3, 0.3, 1],\n",
       "  'question_id': 524520004},\n",
       " {'image_id': 524522,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [0.3, 1],\n",
       "  'question_id': 524522000},\n",
       " {'image_id': 524522,\n",
       "  'labels': [1988],\n",
       "  'scores': [1],\n",
       "  'question_id': 524522001},\n",
       " {'image_id': 524522,\n",
       "  'labels': [3059, 3047, 2585, 735, 3067, 2677],\n",
       "  'scores': [0.3, 0.3, 0.3, 0.3, 0.3, 0.6],\n",
       "  'question_id': 524522002},\n",
       " {'image_id': 524522,\n",
       "  'labels': [444, 841],\n",
       "  'scores': [0.3, 1],\n",
       "  'question_id': 524522003},\n",
       " {'image_id': 524525,\n",
       "  'labels': [3006],\n",
       "  'scores': [1],\n",
       "  'question_id': 524525000},\n",
       " {'image_id': 524525,\n",
       "  'labels': [2621, 841],\n",
       "  'scores': [1, 0.3],\n",
       "  'question_id': 524525001},\n",
       " {'image_id': 524525,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [1, 0.3],\n",
       "  'question_id': 524525002},\n",
       " {'image_id': 131312,\n",
       "  'labels': [1553, 2836, 2168],\n",
       "  'scores': [0.3, 0.3, 0.3],\n",
       "  'question_id': 131312000},\n",
       " {'image_id': 131312,\n",
       "  'labels': [1403],\n",
       "  'scores': [1],\n",
       "  'question_id': 131312001},\n",
       " {'image_id': 131312,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [1, 0.3],\n",
       "  'question_id': 131312002},\n",
       " {'image_id': 131312,\n",
       "  'labels': [325],\n",
       "  'scores': [1],\n",
       "  'question_id': 131312003},\n",
       " {'image_id': 131315,\n",
       "  'labels': [1403],\n",
       "  'scores': [1],\n",
       "  'question_id': 131315000},\n",
       " {'image_id': 131315,\n",
       "  'labels': [1551, 1595, 2324, 2239],\n",
       "  'scores': [0.9, 0.6, 0.3, 0.3],\n",
       "  'question_id': 131315001},\n",
       " {'image_id': 131315,\n",
       "  'labels': [1403],\n",
       "  'scores': [1],\n",
       "  'question_id': 131315002},\n",
       " {'image_id': 262389,\n",
       "  'labels': [425],\n",
       "  'scores': [1],\n",
       "  'question_id': 262389000},\n",
       " {'image_id': 262389,\n",
       "  'labels': [927, 2941],\n",
       "  'scores': [1, 0.6],\n",
       "  'question_id': 262389001},\n",
       " {'image_id': 262389,\n",
       "  'labels': [2941],\n",
       "  'scores': [1],\n",
       "  'question_id': 262389002},\n",
       " {'image_id': 247,\n",
       "  'labels': [2234, 2075, 337],\n",
       "  'scores': [0.3, 0.3, 0.3],\n",
       "  'question_id': 247000},\n",
       " {'image_id': 247,\n",
       "  'labels': [835, 648, 1968],\n",
       "  'scores': [0.3, 0.3, 0.9],\n",
       "  'question_id': 247001},\n",
       " {'image_id': 247,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [1, 1],\n",
       "  'question_id': 247002},\n",
       " {'image_id': 393464,\n",
       "  'labels': [1403],\n",
       "  'scores': [1],\n",
       "  'question_id': 393464000},\n",
       " {'image_id': 393464,\n",
       "  'labels': [3031],\n",
       "  'scores': [1],\n",
       "  'question_id': 393464001},\n",
       " {'image_id': 393464,\n",
       "  'labels': [425],\n",
       "  'scores': [1],\n",
       "  'question_id': 393464002},\n",
       " {'image_id': 262393,\n",
       "  'labels': [444, 841],\n",
       "  'scores': [0.6, 1],\n",
       "  'question_id': 262393000},\n",
       " {'image_id': 262393,\n",
       "  'labels': [1842, 2525, 2960, 68],\n",
       "  'scores': [0.3, 0.9, 1, 0.3],\n",
       "  'question_id': 262393001},\n",
       " {'image_id': 262393,\n",
       "  'labels': [425, 841, 1403],\n",
       "  'scores': [0.6, 0.3, 1],\n",
       "  'question_id': 262393002},\n",
       " {'image_id': 262393,\n",
       "  'labels': [841],\n",
       "  'scores': [1],\n",
       "  'question_id': 262393003},\n",
       " {'image_id': 250,\n",
       "  'labels': [2093, 20, 2131, 2174, 2312],\n",
       "  'scores': [0.3, 0.3, 0.3, 1, 0.3],\n",
       "  'question_id': 250000},\n",
       " {'image_id': 250, 'labels': [1403], 'scores': [1], 'question_id': 250001},\n",
       " {'image_id': 250, 'labels': [], 'scores': [], 'question_id': 250002},\n",
       " {'image_id': 131323,\n",
       "  'labels': [425, 841, 1403],\n",
       "  'scores': [1, 0.3, 0.3],\n",
       "  'question_id': 131323000},\n",
       " {'image_id': 131323,\n",
       "  'labels': [1403],\n",
       "  'scores': [1],\n",
       "  'question_id': 131323001},\n",
       " {'image_id': 131323,\n",
       "  'labels': [2515, 2643],\n",
       "  'scores': [0.3, 1],\n",
       "  'question_id': 131323002},\n",
       " {'image_id': 262399, 'labels': [], 'scores': [], 'question_id': 262399000},\n",
       " {'image_id': 262399,\n",
       "  'labels': [158, 36, 1126, 464],\n",
       "  'scores': [0.3, 0.9, 0.6, 0.3],\n",
       "  'question_id': 262399001},\n",
       " {'image_id': 262399,\n",
       "  'labels': [1333],\n",
       "  'scores': [1],\n",
       "  'question_id': 262399002},\n",
       " {'image_id': 131330,\n",
       "  'labels': [425],\n",
       "  'scores': [1],\n",
       "  'question_id': 131330000},\n",
       " {'image_id': 131330,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [1, 0.3],\n",
       "  'question_id': 131330001},\n",
       " {'image_id': 131330,\n",
       "  'labels': [742],\n",
       "  'scores': [0.6],\n",
       "  'question_id': 131330002},\n",
       " {'image_id': 524547,\n",
       "  'labels': [2526, 2142, 684],\n",
       "  'scores': [0.3, 0.3, 0.9],\n",
       "  'question_id': 524547000},\n",
       " {'image_id': 524547,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [1, 0.3],\n",
       "  'question_id': 524547001},\n",
       " {'image_id': 524547,\n",
       "  'labels': [366],\n",
       "  'scores': [0.6],\n",
       "  'question_id': 524547002},\n",
       " {'image_id': 260, 'labels': [411], 'scores': [1], 'question_id': 260000},\n",
       " {'image_id': 260,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [1, 0.9],\n",
       "  'question_id': 260001},\n",
       " {'image_id': 260,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [1, 0.3],\n",
       "  'question_id': 260002},\n",
       " {'image_id': 524551,\n",
       "  'labels': [425],\n",
       "  'scores': [1],\n",
       "  'question_id': 524551000},\n",
       " {'image_id': 524551,\n",
       "  'labels': [931, 684, 1561],\n",
       "  'scores': [0.3, 1, 0.9],\n",
       "  'question_id': 524551001},\n",
       " {'image_id': 524551,\n",
       "  'labels': [1923, 684, 2142, 1561],\n",
       "  'scores': [0.3, 1, 0.3, 0.3],\n",
       "  'question_id': 524551002},\n",
       " {'image_id': 524551, 'labels': [], 'scores': [], 'question_id': 524551003},\n",
       " {'image_id': 393480,\n",
       "  'labels': [1403, 1299, 1141],\n",
       "  'scores': [0.9, 0.6, 0.6],\n",
       "  'question_id': 393480000},\n",
       " {'image_id': 393480,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [1, 0.3],\n",
       "  'question_id': 393480001},\n",
       " {'image_id': 393480,\n",
       "  'labels': [425],\n",
       "  'scores': [1],\n",
       "  'question_id': 393480002},\n",
       " {'image_id': 393480,\n",
       "  'labels': [1207, 462],\n",
       "  'scores': [1, 0.3],\n",
       "  'question_id': 393480003},\n",
       " {'image_id': 393480,\n",
       "  'labels': [2154, 858],\n",
       "  'scores': [1, 0.3],\n",
       "  'question_id': 393480004},\n",
       " {'image_id': 131339,\n",
       "  'labels': [2241, 1333],\n",
       "  'scores': [0.3, 1],\n",
       "  'question_id': 131339000},\n",
       " {'image_id': 131339,\n",
       "  'labels': [1449, 1693, 893],\n",
       "  'scores': [1, 1, 0.3],\n",
       "  'question_id': 131339001},\n",
       " {'image_id': 131339,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [1, 1],\n",
       "  'question_id': 131339002},\n",
       " {'image_id': 131339,\n",
       "  'labels': [425],\n",
       "  'scores': [1],\n",
       "  'question_id': 131339003},\n",
       " {'image_id': 131339,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [1, 1],\n",
       "  'question_id': 131339004},\n",
       " {'image_id': 131339,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [0.3, 1],\n",
       "  'question_id': 131339005},\n",
       " {'image_id': 131339,\n",
       "  'labels': [2195],\n",
       "  'scores': [1],\n",
       "  'question_id': 131339006},\n",
       " {'image_id': 131339,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [1, 1],\n",
       "  'question_id': 131339007},\n",
       " {'image_id': 131339,\n",
       "  'labels': [285, 1128, 1693, 893, 1449, 90, 177],\n",
       "  'scores': [0.9, 0.3, 0.3, 0.3, 0.6, 0.3, 0.3],\n",
       "  'question_id': 131339008},\n",
       " {'image_id': 524557,\n",
       "  'labels': [680],\n",
       "  'scores': [1],\n",
       "  'question_id': 524557000},\n",
       " {'image_id': 524557,\n",
       "  'labels': [3006, 2697, 759],\n",
       "  'scores': [1, 0.3, 1],\n",
       "  'question_id': 524557001},\n",
       " {'image_id': 524557,\n",
       "  'labels': [868, 702, 2377, 2210, 2785],\n",
       "  'scores': [0.3, 0.3, 0.3, 0.3, 0.9],\n",
       "  'question_id': 524557002},\n",
       " {'image_id': 524557,\n",
       "  'labels': [841, 3031, 1618],\n",
       "  'scores': [0.3, 1, 1],\n",
       "  'question_id': 524557003},\n",
       " {'image_id': 524557,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [0.3, 1],\n",
       "  'question_id': 524557004},\n",
       " {'image_id': 524557,\n",
       "  'labels': [1403],\n",
       "  'scores': [1],\n",
       "  'question_id': 524557005},\n",
       " {'image_id': 131342,\n",
       "  'labels': [444],\n",
       "  'scores': [1],\n",
       "  'question_id': 131342000},\n",
       " {'image_id': 131342,\n",
       "  'labels': [425],\n",
       "  'scores': [1],\n",
       "  'question_id': 131342001},\n",
       " {'image_id': 131342,\n",
       "  'labels': [425],\n",
       "  'scores': [0.3],\n",
       "  'question_id': 131342002},\n",
       " {'image_id': 131342,\n",
       "  'labels': [772],\n",
       "  'scores': [1],\n",
       "  'question_id': 131342003},\n",
       " {'image_id': 131342,\n",
       "  'labels': [2211, 2739],\n",
       "  'scores': [0.6, 1],\n",
       "  'question_id': 131342004},\n",
       " {'image_id': 262415,\n",
       "  'labels': [2419, 2157, 886],\n",
       "  'scores': [0.3, 0.3, 0.6],\n",
       "  'question_id': 262415000},\n",
       " {'image_id': 262415,\n",
       "  'labels': [759],\n",
       "  'scores': [1],\n",
       "  'question_id': 262415001},\n",
       " {'image_id': 262415,\n",
       "  'labels': [1353, 134, 155, 2838],\n",
       "  'scores': [1, 0.3, 0.9, 0.3],\n",
       "  'question_id': 262415002},\n",
       " {'image_id': 262415,\n",
       "  'labels': [7, 2844],\n",
       "  'scores': [0.9, 1],\n",
       "  'question_id': 262415003},\n",
       " {'image_id': 393488,\n",
       "  'labels': [1076],\n",
       "  'scores': [1],\n",
       "  'question_id': 393488000},\n",
       " {'image_id': 393488,\n",
       "  'labels': [425],\n",
       "  'scores': [1],\n",
       "  'question_id': 393488001},\n",
       " {'image_id': 393488,\n",
       "  'labels': [3101, 2570, 625, 1387],\n",
       "  'scores': [0.6, 0.3, 0.3, 1],\n",
       "  'question_id': 393488002},\n",
       " {'image_id': 393488,\n",
       "  'labels': [425],\n",
       "  'scores': [1],\n",
       "  'question_id': 393488003},\n",
       " {'image_id': 393489,\n",
       "  'labels': [707, 200, 1231],\n",
       "  'scores': [1, 1, 0.3],\n",
       "  'question_id': 393489000},\n",
       " {'image_id': 393489,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [1, 1],\n",
       "  'question_id': 393489001},\n",
       " {'image_id': 393489,\n",
       "  'labels': [1496, 707, 1196],\n",
       "  'scores': [0.3, 0.3, 0.3],\n",
       "  'question_id': 393489002},\n",
       " {'image_id': 393489,\n",
       "  'labels': [1880, 775],\n",
       "  'scores': [1, 1],\n",
       "  'question_id': 393489003},\n",
       " {'image_id': 393489,\n",
       "  'labels': [1403],\n",
       "  'scores': [1],\n",
       "  'question_id': 393489004},\n",
       " {'image_id': 393489,\n",
       "  'labels': [3115],\n",
       "  'scores': [1],\n",
       "  'question_id': 393489005},\n",
       " {'image_id': 393489,\n",
       "  'labels': [2195, 444, 841, 1239],\n",
       "  'scores': [1, 0.3, 0.3, 0.6],\n",
       "  'question_id': 393489006},\n",
       " {'image_id': 393489,\n",
       "  'labels': [707, 200],\n",
       "  'scores': [1, 1],\n",
       "  'question_id': 393489007},\n",
       " {'image_id': 393489,\n",
       "  'labels': [2388, 2661, 2076, 3004, 775],\n",
       "  'scores': [0.3, 0.3, 0.3, 0.3, 1],\n",
       "  'question_id': 393489008},\n",
       " {'image_id': 393489, 'labels': [], 'scores': [], 'question_id': 393489009},\n",
       " {'image_id': 393489,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [0.6, 1],\n",
       "  'question_id': 393489010},\n",
       " {'image_id': 393489,\n",
       "  'labels': [1614, 707, 2274],\n",
       "  'scores': [0.3, 0.9, 0.3],\n",
       "  'question_id': 393489011},\n",
       " {'image_id': 393489,\n",
       "  'labels': [1403],\n",
       "  'scores': [1],\n",
       "  'question_id': 393489012},\n",
       " {'image_id': 393489,\n",
       "  'labels': [2387, 2785],\n",
       "  'scores': [0.3, 1],\n",
       "  'question_id': 393489013},\n",
       " {'image_id': 393489,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [0.3, 1],\n",
       "  'question_id': 393489014},\n",
       " {'image_id': 393489,\n",
       "  'labels': [1403],\n",
       "  'scores': [1],\n",
       "  'question_id': 393489015},\n",
       " {'image_id': 393489,\n",
       "  'labels': [2195],\n",
       "  'scores': [1],\n",
       "  'question_id': 393489016},\n",
       " {'image_id': 393489,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [0.3, 1],\n",
       "  'question_id': 393489017},\n",
       " {'image_id': 393489,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [1, 1],\n",
       "  'question_id': 393489018},\n",
       " {'image_id': 393489, 'labels': [], 'scores': [], 'question_id': 393489019},\n",
       " {'image_id': 393489,\n",
       "  'labels': [2647],\n",
       "  'scores': [0.3],\n",
       "  'question_id': 393489020},\n",
       " {'image_id': 393489,\n",
       "  'labels': [707, 200],\n",
       "  'scores': [0.6, 1],\n",
       "  'question_id': 393489021},\n",
       " {'image_id': 393489,\n",
       "  'labels': [707],\n",
       "  'scores': [1],\n",
       "  'question_id': 393489022},\n",
       " {'image_id': 336077,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [1, 0.9],\n",
       "  'question_id': 336077000},\n",
       " {'image_id': 336077,\n",
       "  'labels': [425, 1423],\n",
       "  'scores': [1, 0.3],\n",
       "  'question_id': 336077001},\n",
       " {'image_id': 336077,\n",
       "  'labels': [425],\n",
       "  'scores': [1],\n",
       "  'question_id': 336077002},\n",
       " {'image_id': 336077,\n",
       "  'labels': [425],\n",
       "  'scores': [1],\n",
       "  'question_id': 336077003},\n",
       " {'image_id': 546179,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [0.6, 1],\n",
       "  'question_id': 546179000},\n",
       " {'image_id': 546179,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [0.6, 1],\n",
       "  'question_id': 546179001},\n",
       " {'image_id': 546179,\n",
       "  'labels': [2418, 1540, 781, 103, 1077],\n",
       "  'scores': [0.3, 0.9, 0.3, 0.3, 0.9],\n",
       "  'question_id': 546179002},\n",
       " {'image_id': 546179,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [0.3, 1],\n",
       "  'question_id': 546179003},\n",
       " {'image_id': 546179,\n",
       "  'labels': [3006],\n",
       "  'scores': [1],\n",
       "  'question_id': 546179004},\n",
       " {'image_id': 546179,\n",
       "  'labels': [425],\n",
       "  'scores': [1],\n",
       "  'question_id': 546179005},\n",
       " {'image_id': 546179,\n",
       "  'labels': [2969, 1299, 1077, 1232],\n",
       "  'scores': [0.3, 0.3, 0.3, 0.3],\n",
       "  'question_id': 546179006},\n",
       " {'image_id': 546179,\n",
       "  'labels': [1403],\n",
       "  'scores': [1],\n",
       "  'question_id': 546179007},\n",
       " {'image_id': 9, 'labels': [841], 'scores': [1], 'question_id': 9000},\n",
       " {'image_id': 9, 'labels': [2542], 'scores': [0.9], 'question_id': 9001},\n",
       " {'image_id': 9, 'labels': [2529], 'scores': [1], 'question_id': 9002},\n",
       " {'image_id': 393493,\n",
       "  'labels': [425],\n",
       "  'scores': [1],\n",
       "  'question_id': 393493000},\n",
       " {'image_id': 393493,\n",
       "  'labels': [2195, 841],\n",
       "  'scores': [1, 1],\n",
       "  'question_id': 393493001},\n",
       " {'image_id': 393493,\n",
       "  'labels': [425],\n",
       "  'scores': [1],\n",
       "  'question_id': 393493002},\n",
       " {'image_id': 131351,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [0.3, 1],\n",
       "  'question_id': 131351000},\n",
       " {'image_id': 131351,\n",
       "  'labels': [2195, 2621, 841],\n",
       "  'scores': [1, 0.3, 0.6],\n",
       "  'question_id': 131351001},\n",
       " {'image_id': 131351,\n",
       "  'labels': [1208, 2019],\n",
       "  'scores': [1, 0.3],\n",
       "  'question_id': 131351002},\n",
       " {'image_id': 131351,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [1, 1],\n",
       "  'question_id': 131351003},\n",
       " {'image_id': 131351,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [0.3, 1],\n",
       "  'question_id': 131351004},\n",
       " {'image_id': 131351,\n",
       "  'labels': [2661, 3006],\n",
       "  'scores': [1, 0.9],\n",
       "  'question_id': 131351005},\n",
       " {'image_id': 131351,\n",
       "  'labels': [1403],\n",
       "  'scores': [1],\n",
       "  'question_id': 131351006},\n",
       " {'image_id': 131351,\n",
       "  'labels': [735],\n",
       "  'scores': [0.3],\n",
       "  'question_id': 131351007},\n",
       " {'image_id': 131351,\n",
       "  'labels': [1403],\n",
       "  'scores': [1],\n",
       "  'question_id': 131351008},\n",
       " {'image_id': 131351, 'labels': [], 'scores': [], 'question_id': 131351009},\n",
       " {'image_id': 131351,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [0.9, 1],\n",
       "  'question_id': 131351010},\n",
       " {'image_id': 131352,\n",
       "  'labels': [1250, 384, 416, 2155],\n",
       "  'scores': [0.3, 0.3, 0.9, 0.3],\n",
       "  'question_id': 131352000},\n",
       " {'image_id': 131352,\n",
       "  'labels': [2241, 3006, 1333],\n",
       "  'scores': [0.3, 0.9, 0.9],\n",
       "  'question_id': 131352001},\n",
       " {'image_id': 131352,\n",
       "  'labels': [2522],\n",
       "  'scores': [1],\n",
       "  'question_id': 131352002},\n",
       " {'image_id': 524572,\n",
       "  'labels': [2210],\n",
       "  'scores': [0.3],\n",
       "  'question_id': 524572000},\n",
       " {'image_id': 524572,\n",
       "  'labels': [781, 349, 2387, 927],\n",
       "  'scores': [0.3, 0.3, 0.3, 1],\n",
       "  'question_id': 524572001},\n",
       " {'image_id': 524572,\n",
       "  'labels': [1542, 425, 1403],\n",
       "  'scores': [0.3, 0.9, 1],\n",
       "  'question_id': 524572002},\n",
       " {'image_id': 112497,\n",
       "  'labels': [1040],\n",
       "  'scores': [1],\n",
       "  'question_id': 112497000},\n",
       " {'image_id': 112497,\n",
       "  'labels': [1388, 772],\n",
       "  'scores': [1, 0.3],\n",
       "  'question_id': 112497001},\n",
       " {'image_id': 112497,\n",
       "  'labels': [1726],\n",
       "  'scores': [1],\n",
       "  'question_id': 112497002},\n",
       " {'image_id': 393503,\n",
       "  'labels': [411, 1598, 3006, 2324],\n",
       "  'scores': [0.3, 0.3, 0.9, 0.6],\n",
       "  'question_id': 393503000},\n",
       " {'image_id': 393503,\n",
       "  'labels': [1403],\n",
       "  'scores': [1],\n",
       "  'question_id': 393503001},\n",
       " {'image_id': 393503,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [1, 1],\n",
       "  'question_id': 393503002},\n",
       " {'image_id': 393503,\n",
       "  'labels': [1930, 1001],\n",
       "  'scores': [0.3, 1],\n",
       "  'question_id': 393503003},\n",
       " {'image_id': 393508,\n",
       "  'labels': [226],\n",
       "  'scores': [1],\n",
       "  'question_id': 393508000},\n",
       " {'image_id': 393508,\n",
       "  'labels': [3010],\n",
       "  'scores': [1],\n",
       "  'question_id': 393508001},\n",
       " {'image_id': 393508,\n",
       "  'labels': [2187, 5],\n",
       "  'scores': [0.9, 1],\n",
       "  'question_id': 393508002},\n",
       " {'image_id': 414639,\n",
       "  'labels': [563, 1181, 2471],\n",
       "  'scores': [0.3, 0.3, 0.3],\n",
       "  'question_id': 414639000},\n",
       " {'image_id': 414639,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [1, 0.9],\n",
       "  'question_id': 414639001},\n",
       " {'image_id': 414639,\n",
       "  'labels': [2588, 1840],\n",
       "  'scores': [0.6, 1],\n",
       "  'question_id': 414639002},\n",
       " {'image_id': 131366,\n",
       "  'labels': [841, 1239],\n",
       "  'scores': [0.3, 1],\n",
       "  'question_id': 131366000},\n",
       " {'image_id': 131366,\n",
       "  'labels': [733, 2267, 1484],\n",
       "  'scores': [0.3, 1, 1],\n",
       "  'question_id': 131366001},\n",
       " {'image_id': 131366,\n",
       "  'labels': [2267, 1484],\n",
       "  'scores': [1, 1],\n",
       "  'question_id': 131366002},\n",
       " {'image_id': 131366,\n",
       "  'labels': [2063, 1239, 311, 1618],\n",
       "  'scores': [1, 0.6, 0.3, 0.6],\n",
       "  'question_id': 131366003},\n",
       " {'image_id': 131366,\n",
       "  'labels': [1239],\n",
       "  'scores': [1],\n",
       "  'question_id': 131366004},\n",
       " {'image_id': 131366,\n",
       "  'labels': [2274, 2306, 1455, 2519],\n",
       "  'scores': [0.9, 0.6, 1, 0.3],\n",
       "  'question_id': 131366005},\n",
       " {'image_id': 131366,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [1, 0.3],\n",
       "  'question_id': 131366006},\n",
       " {'image_id': 131366,\n",
       "  'labels': [436],\n",
       "  'scores': [1],\n",
       "  'question_id': 131366007},\n",
       " {'image_id': 131366,\n",
       "  'labels': [3068, 1781],\n",
       "  'scores': [0.6, 0.3],\n",
       "  'question_id': 131366008},\n",
       " {'image_id': 131366,\n",
       "  'labels': [1239],\n",
       "  'scores': [1],\n",
       "  'question_id': 131366009},\n",
       " {'image_id': 131366,\n",
       "  'labels': [1441, 436, 444, 2387],\n",
       "  'scores': [0.3, 0.3, 0.9, 0.3],\n",
       "  'question_id': 131366010},\n",
       " {'image_id': 131366,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [1, 0.3],\n",
       "  'question_id': 131366011},\n",
       " {'image_id': 131366,\n",
       "  'labels': [425],\n",
       "  'scores': [1],\n",
       "  'question_id': 131366012},\n",
       " {'image_id': 131366,\n",
       "  'labels': [1403],\n",
       "  'scores': [1],\n",
       "  'question_id': 131366013},\n",
       " {'image_id': 131366,\n",
       "  'labels': [1022, 105, 436, 2604],\n",
       "  'scores': [0.9, 0.6, 0.9, 0.6],\n",
       "  'question_id': 131366014},\n",
       " {'image_id': 131366,\n",
       "  'labels': [524, 2212, 2984, 444, 1771, 177],\n",
       "  'scores': [0.3, 0.3, 0.3, 0.3, 0.3, 0.3],\n",
       "  'question_id': 131366015},\n",
       " {'image_id': 131366,\n",
       "  'labels': [2274, 1553],\n",
       "  'scores': [1, 0.3],\n",
       "  'question_id': 131366016},\n",
       " {'image_id': 131366,\n",
       "  'labels': [1403],\n",
       "  'scores': [1],\n",
       "  'question_id': 131366017},\n",
       " {'image_id': 131366,\n",
       "  'labels': [425],\n",
       "  'scores': [1],\n",
       "  'question_id': 131366018},\n",
       " {'image_id': 131366,\n",
       "  'labels': [425],\n",
       "  'scores': [1],\n",
       "  'question_id': 131366019},\n",
       " {'image_id': 131366,\n",
       "  'labels': [1239],\n",
       "  'scores': [1],\n",
       "  'question_id': 131366020},\n",
       " {'image_id': 131366,\n",
       "  'labels': [444],\n",
       "  'scores': [1],\n",
       "  'question_id': 131366021},\n",
       " {'image_id': 131366,\n",
       "  'labels': [2063, 1239, 1618],\n",
       "  'scores': [1, 0.6, 0.3],\n",
       "  'question_id': 131366022},\n",
       " {'image_id': 131366,\n",
       "  'labels': [1866],\n",
       "  'scores': [0.9],\n",
       "  'question_id': 131366023},\n",
       " {'image_id': 131366,\n",
       "  'labels': [436, 2324],\n",
       "  'scores': [0.3, 1],\n",
       "  'question_id': 131366024},\n",
       " {'image_id': 131366,\n",
       "  'labels': [1403],\n",
       "  'scores': [1],\n",
       "  'question_id': 131366025},\n",
       " {'image_id': 131366,\n",
       "  'labels': [436],\n",
       "  'scores': [1],\n",
       "  'question_id': 131366026},\n",
       " {'image_id': 131366,\n",
       "  'labels': [554, 733, 2267],\n",
       "  'scores': [0.3, 0.3, 1],\n",
       "  'question_id': 131366027},\n",
       " {'image_id': 131366,\n",
       "  'labels': [2063],\n",
       "  'scores': [1],\n",
       "  'question_id': 131366028},\n",
       " {'image_id': 131366,\n",
       "  'labels': [554, 2267, 1484],\n",
       "  'scores': [0.3, 0.9, 0.6],\n",
       "  'question_id': 131366029},\n",
       " {'image_id': 131366,\n",
       "  'labels': [425],\n",
       "  'scores': [1],\n",
       "  'question_id': 131366030},\n",
       " {'image_id': 131366,\n",
       "  'labels': [1787, 1141, 1403],\n",
       "  'scores': [0.3, 0.6, 0.6],\n",
       "  'question_id': 131366031},\n",
       " {'image_id': 497565,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [1, 1],\n",
       "  'question_id': 497565000},\n",
       " {'image_id': 497565,\n",
       "  'labels': [1227],\n",
       "  'scores': [1],\n",
       "  'question_id': 497565001},\n",
       " {'image_id': 497565,\n",
       "  'labels': [425],\n",
       "  'scores': [1],\n",
       "  'question_id': 497565002},\n",
       " {'image_id': 101431,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [1, 0.3],\n",
       "  'question_id': 101431000},\n",
       " {'image_id': 101431,\n",
       "  'labels': [1491, 411, 1333],\n",
       "  'scores': [1, 0.3, 0.3],\n",
       "  'question_id': 101431001},\n",
       " {'image_id': 101431,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [1, 0.9],\n",
       "  'question_id': 101431002},\n",
       " {'image_id': 262442,\n",
       "  'labels': [2093, 1015, 2091, 2172, 2174, 2134, 444, 1805, 2131],\n",
       "  'scores': [0.6, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3],\n",
       "  'question_id': 262442000},\n",
       " {'image_id': 262442,\n",
       "  'labels': [425],\n",
       "  'scores': [1],\n",
       "  'question_id': 262442001},\n",
       " {'image_id': 262442, 'labels': [], 'scores': [], 'question_id': 262442002},\n",
       " {'image_id': 262442,\n",
       "  'labels': [2387, 383, 2785],\n",
       "  'scores': [1, 0.3, 0.3],\n",
       "  'question_id': 262442003},\n",
       " {'image_id': 21895,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [1, 1],\n",
       "  'question_id': 21895000},\n",
       " {'image_id': 21895, 'labels': [425], 'scores': [1], 'question_id': 21895001},\n",
       " {'image_id': 21895,\n",
       "  'labels': [1551, 830, 2239],\n",
       "  'scores': [0.6, 1, 1],\n",
       "  'question_id': 21895002},\n",
       " {'image_id': 131373,\n",
       "  'labels': [1725, 604],\n",
       "  'scores': [1, 0.3],\n",
       "  'question_id': 131373000},\n",
       " {'image_id': 131373,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [1, 1],\n",
       "  'question_id': 131373001},\n",
       " {'image_id': 131373,\n",
       "  'labels': [315],\n",
       "  'scores': [1],\n",
       "  'question_id': 131373002},\n",
       " {'image_id': 131373,\n",
       "  'labels': [315],\n",
       "  'scores': [1],\n",
       "  'question_id': 131373003},\n",
       " {'image_id': 131374,\n",
       "  'labels': [2621, 1239],\n",
       "  'scores': [1, 0.9],\n",
       "  'question_id': 131374000},\n",
       " {'image_id': 131374,\n",
       "  'labels': [2621, 3031, 1239],\n",
       "  'scores': [1, 0.6, 0.9],\n",
       "  'question_id': 131374001},\n",
       " {'image_id': 131374,\n",
       "  'labels': [912, 301],\n",
       "  'scores': [0.6, 1],\n",
       "  'question_id': 131374002},\n",
       " {'image_id': 131374,\n",
       "  'labels': [2621, 1239, 311],\n",
       "  'scores': [1, 1, 0.3],\n",
       "  'question_id': 131374003},\n",
       " {'image_id': 109277,\n",
       "  'labels': [2111, 1227, 2807],\n",
       "  'scores': [0.9, 0.9, 0.9],\n",
       "  'question_id': 109277000},\n",
       " {'image_id': 109277,\n",
       "  'labels': [411, 1504],\n",
       "  'scores': [1, 0.3],\n",
       "  'question_id': 109277001},\n",
       " {'image_id': 109277,\n",
       "  'labels': [1403],\n",
       "  'scores': [1],\n",
       "  'question_id': 109277002},\n",
       " {'image_id': 131376,\n",
       "  'labels': [2594, 1227],\n",
       "  'scores': [0.3, 1],\n",
       "  'question_id': 131376000},\n",
       " {'image_id': 131376,\n",
       "  'labels': [1227, 1333],\n",
       "  'scores': [1, 1],\n",
       "  'question_id': 131376001},\n",
       " {'image_id': 131376,\n",
       "  'labels': [3107, 1693],\n",
       "  'scores': [0.9, 1],\n",
       "  'question_id': 131376002},\n",
       " {'image_id': 131376,\n",
       "  'labels': [1403],\n",
       "  'scores': [1],\n",
       "  'question_id': 131376003},\n",
       " {'image_id': 131376,\n",
       "  'labels': [1403],\n",
       "  'scores': [1],\n",
       "  'question_id': 131376004},\n",
       " {'image_id': 131376,\n",
       "  'labels': [435, 2705, 545, 1310],\n",
       "  'scores': [0.9, 0.3, 0.6, 0.9],\n",
       "  'question_id': 131376005},\n",
       " {'image_id': 131376,\n",
       "  'labels': [2324, 3006, 1851, 2697],\n",
       "  'scores': [0.6, 0.9, 0.3, 0.9],\n",
       "  'question_id': 131376006},\n",
       " ...]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = cPickle.load(open('datasets/VQA/cache/VQA_test_23_cleaned.pkl', \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "val = cPickle.load(open('datasets/VQA/cache/VQA_minval_23_cleaned.pkl', \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = cPickle.load(open('datasets/VQA/cache/VQA_trainval_23_cleaned.pkl', \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(542104, 3000, 447793)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train), len(val), len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'image_id': 1,\n",
       " 'question': 'What is the fence made of?',\n",
       " 'question_id': 1000,\n",
       " 'q_token': tensor([ 101, 2054, 2003, 1996, 8638, 2081, 1997, 1029,  102,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0]),\n",
       " 'q_input_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 'q_segment_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question_id': 573843005,\n",
       " 'image_id': 573843,\n",
       " 'question': 'Are there clouds?',\n",
       " 'answer': {'labels': tensor([ 425, 1403]),\n",
       "  'scores': tensor([1.0000, 0.3000])},\n",
       " 'q_token': tensor([ 101, 2024, 2045, 8044, 1029,  102,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0]),\n",
       " 'q_input_mask': tensor([1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 'q_segment_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/30/2020 11:24:11 - INFO - pytorch_transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/aloui/.cache/torch/pytorch_transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
      "07/30/2020 11:24:11 - INFO - vilbert.task_utils -   Loading VQA Dataset with batch size 30\n",
      "07/30/2020 11:24:11 - INFO - vilbert.datasets.vqa_dataset -   Loading from datasets/VQA/cache/VQA_test_23_cleaned.pkl\n"
     ]
    }
   ],
   "source": [
    "ds = LoadDatasetEval(args, task_cfg, args.tasks.split(\"-\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "b'1' is not in list",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-283a58d898c7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'TASK1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/aloui/vilbert-multi-task/vilbert/datasets/vqa_dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    273\u001b[0m         \u001b[0mimage_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mentry\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"image_id\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m         \u001b[0mquestion_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mentry\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"question_id\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 275\u001b[0;31m         \u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_boxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mboxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_image_features_reader\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mimage_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    276\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m         \u001b[0mmix_num_boxes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_boxes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_max_region_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/aloui/vilbert-multi-task/vilbert/datasets/_image_features_reader.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, image_id)\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0mimage_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_image_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m             \u001b[0;31m# Load features during first epoch, all not loaded together as it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: b'1' is not in list"
     ]
    }
   ],
   "source": [
    "for d in ds[-2]['TASK1']:\n",
    "    print(type(d))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans2label = cPickle.load(open('datasets/VQA/cache/trainval_ans2label.pkl', \"rb\"))\n",
    "label2ans = cPickle.load(open('datasets/VQA/cache/trainval_label2ans.pkl', \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'': 0,\n",
       " 'raining': 1523,\n",
       " 'pedestrian crossing': 1841,\n",
       " 'hats': 1361,\n",
       " 'bear': 2914,\n",
       " 'swirls': 2244,\n",
       " 'yellow': 759,\n",
       " 'protest': 2979,\n",
       " 'woods': 1,\n",
       " 'sleep': 2936,\n",
       " 'trash can': 2,\n",
       " 'hanging': 3,\n",
       " 'onions': 3091,\n",
       " 'zig zag': 2543,\n",
       " 'lace': 3033,\n",
       " 'trolley': 1362,\n",
       " 'feeding': 2937,\n",
       " 'chinese': 2245,\n",
       " 'electricity': 760,\n",
       " 'swan': 2351,\n",
       " 'cocker spaniel': 570,\n",
       " 'bike': 1716,\n",
       " 'under': 396,\n",
       " 'dog show': 1363,\n",
       " 'flip flops': 1903,\n",
       " 'wreath': 981,\n",
       " 'by window': 188,\n",
       " 'deli': 761,\n",
       " 'blanket': 982,\n",
       " 'dell': 762,\n",
       " \"women's\": 983,\n",
       " 'home plate': 984,\n",
       " 'fireplace': 2940,\n",
       " 'icing': 1564,\n",
       " 'blue and pink': 1159,\n",
       " 'school': 571,\n",
       " 'baking': 1905,\n",
       " 'snowflakes': 1160,\n",
       " 'parrot': 2941,\n",
       " 'wooden': 4,\n",
       " 'formica': 2137,\n",
       " 'ups': 1161,\n",
       " 'triumph': 1718,\n",
       " 'clothes': 1162,\n",
       " \"can't see\": 1906,\n",
       " 'bicycle': 2138,\n",
       " 'bus driver': 1538,\n",
       " 'tired': 2345,\n",
       " 'phones': 2544,\n",
       " 'railing': 2343,\n",
       " 'feathers': 572,\n",
       " 'japanese': 2743,\n",
       " 'frosted': 408,\n",
       " 'chef': 1719,\n",
       " 'second': 2348,\n",
       " 'street': 1364,\n",
       " 'chairs': 1709,\n",
       " 'air': 1747,\n",
       " 'panda': 190,\n",
       " 'on counter': 2203,\n",
       " 'blue': 411,\n",
       " 'rope': 1842,\n",
       " 'straight ahead': 2139,\n",
       " 'at camera': 2077,\n",
       " 'cooking': 5,\n",
       " 'tow truck': 2745,\n",
       " 'hazy': 1907,\n",
       " 'lights': 2747,\n",
       " 'above': 986,\n",
       " 'sideways': 1978,\n",
       " 'new': 1163,\n",
       " 'net': 1164,\n",
       " 'disney': 1365,\n",
       " 'helmets': 390,\n",
       " 'pancakes': 2748,\n",
       " 'wakeboard': 391,\n",
       " 'men': 392,\n",
       " 'hundreds': 1366,\n",
       " 'on train': 2749,\n",
       " 'remote control': 1166,\n",
       " 'china': 6,\n",
       " 'parking lot': 2608,\n",
       " 'behind woman': 764,\n",
       " '100': 1908,\n",
       " 'ski slope': 192,\n",
       " '106': 1910,\n",
       " 'mozzarella': 420,\n",
       " 'dry': 1911,\n",
       " 'kids': 7,\n",
       " 'luggage': 574,\n",
       " 'leaves': 575,\n",
       " 'qantas': 663,\n",
       " 'smoke': 987,\n",
       " 'military': 765,\n",
       " 'joshua': 393,\n",
       " 'bike rack': 8,\n",
       " 'straw': 2140,\n",
       " 'strap': 426,\n",
       " 'sliced': 394,\n",
       " 'jackets': 395,\n",
       " 'on phone': 9,\n",
       " 'landscape': 2750,\n",
       " 'star wars': 2943,\n",
       " 'plow': 193,\n",
       " 'headband': 1981,\n",
       " 'army': 2751,\n",
       " 'alligator': 1721,\n",
       " 'sweater': 194,\n",
       " 'coins': 195,\n",
       " 'suit': 1659,\n",
       " 'music': 10,\n",
       " 'comcast': 196,\n",
       " 'riding horses': 1525,\n",
       " 'very fast': 2752,\n",
       " 'strike': 1526,\n",
       " 'dairy': 665,\n",
       " 'blueberry': 2545,\n",
       " 'ram': 2958,\n",
       " 'fake': 1569,\n",
       " 'sony ericsson': 2753,\n",
       " 'street name': 1722,\n",
       " '99': 2352,\n",
       " 'to left': 576,\n",
       " 'warm': 1912,\n",
       " 'for fun': 397,\n",
       " 'siblings': 3034,\n",
       " 'organic': 731,\n",
       " 'me': 1367,\n",
       " '1990': 197,\n",
       " 'room': 398,\n",
       " 'work': 2546,\n",
       " 'roof': 399,\n",
       " 'black and blue': 1368,\n",
       " 'plunger': 1528,\n",
       " 'decorative': 2944,\n",
       " \"it's not\": 2355,\n",
       " 'florida': 2709,\n",
       " 'floor': 2391,\n",
       " 'india': 2547,\n",
       " 'honey': 2754,\n",
       " 'green beans': 1529,\n",
       " 'caution': 1530,\n",
       " 'veggies': 1723,\n",
       " 'woodpecker': 2945,\n",
       " 'garbage': 2495,\n",
       " 'motion': 3002,\n",
       " 'end': 1369,\n",
       " '4 feet': 2755,\n",
       " 'in suitcase': 2946,\n",
       " 'travel': 11,\n",
       " 'drying': 2356,\n",
       " 'nuts': 198,\n",
       " '6 inches': 1531,\n",
       " 'happy birthday': 1724,\n",
       " 'machine': 767,\n",
       " 'far': 3035,\n",
       " 'bricks': 2211,\n",
       " 'bunt': 1972,\n",
       " 'boats': 989,\n",
       " 'gate': 2948,\n",
       " 'chase': 2487,\n",
       " 'beach': 1725,\n",
       " 'charging': 1370,\n",
       " 'pizza': 1726,\n",
       " 'gaming': 768,\n",
       " 'briefcase': 2756,\n",
       " 'cadillac': 2757,\n",
       " 'ladder': 199,\n",
       " 'after': 1727,\n",
       " 'lab': 2548,\n",
       " 'jumping': 2142,\n",
       " 'on skateboard': 1435,\n",
       " 'cell phone': 200,\n",
       " 'vase': 1904,\n",
       " 'arch': 201,\n",
       " 'fedora': 1845,\n",
       " 'man on right': 2758,\n",
       " 'in bowl': 1371,\n",
       " 'croissant': 1372,\n",
       " 'harley': 2143,\n",
       " 'tulip': 12,\n",
       " 'checkerboard': 400,\n",
       " 'green': 990,\n",
       " 'jungle': 465,\n",
       " 'ambulance': 2550,\n",
       " '1 foot': 202,\n",
       " '1000': 1419,\n",
       " 'wing': 770,\n",
       " 'wind': 771,\n",
       " 'wine': 772,\n",
       " 'salon': 1730,\n",
       " 'toaster': 2378,\n",
       " 'office': 2551,\n",
       " 'deck': 2760,\n",
       " 'walgreens': 1731,\n",
       " 'over': 2949,\n",
       " 'baseball uniform': 773,\n",
       " 'london': 1963,\n",
       " 'oven': 2005,\n",
       " 'keyboard': 1168,\n",
       " 'plastic wrap': 2358,\n",
       " 'japan': 1732,\n",
       " 'before': 401,\n",
       " 'chihuahua': 1914,\n",
       " '4 inches': 2553,\n",
       " '2:00': 472,\n",
       " 'backpack': 2359,\n",
       " 'avocado': 1733,\n",
       " '2:05': 577,\n",
       " 'writing': 2950,\n",
       " 'new orleans': 774,\n",
       " '400': 578,\n",
       " 'savory': 1734,\n",
       " '3:15': 579,\n",
       " '3:10': 580,\n",
       " 'swans': 2996,\n",
       " 'coffee': 203,\n",
       " 'carnation': 1389,\n",
       " '1 in back': 204,\n",
       " 'white and blue': 205,\n",
       " 'safe': 206,\n",
       " 'band': 1735,\n",
       " 'mercedes benz': 1374,\n",
       " 'giraffe': 991,\n",
       " 'glazed': 402,\n",
       " 'silver': 775,\n",
       " 'bank': 1736,\n",
       " 'bread': 2554,\n",
       " 'shadows': 2145,\n",
       " '1.00': 2835,\n",
       " 'brushing teeth': 2360,\n",
       " 'rocky': 1737,\n",
       " 'potatoes': 2146,\n",
       " 'on tray': 992,\n",
       " 'wii remotes': 482,\n",
       " 'l': 207,\n",
       " 'detroit': 581,\n",
       " 'rocks': 1738,\n",
       " 'side of road': 2761,\n",
       " 'arrow': 13,\n",
       " 'crocs': 1739,\n",
       " 'bone': 1917,\n",
       " 'lying down': 993,\n",
       " 'hanger': 2951,\n",
       " 'turn right': 208,\n",
       " 'under table': 1918,\n",
       " 'spider': 2361,\n",
       " 'bowls': 776,\n",
       " 'waffle': 2147,\n",
       " 'british airways': 2879,\n",
       " 'blueberries': 2642,\n",
       " 'magnets': 2024,\n",
       " 'navy': 1919,\n",
       " 'logo': 1741,\n",
       " 'dawn': 1169,\n",
       " 'in vase': 994,\n",
       " 'enclosure': 1170,\n",
       " 'large': 1616,\n",
       " 'rv': 1534,\n",
       " 'lemons': 2034,\n",
       " 'driving': 2952,\n",
       " 'motel': 2148,\n",
       " 'cameras': 2556,\n",
       " 'diesel': 2557,\n",
       " '9:25': 3038,\n",
       " 'surprise': 1171,\n",
       " 'millions': 1421,\n",
       " 'sliding': 995,\n",
       " 'green and orange': 2953,\n",
       " '3:50': 2205,\n",
       " 'arizona': 2954,\n",
       " 'turning': 2762,\n",
       " 'barrier': 210,\n",
       " '9:20': 3039,\n",
       " 'blue and green': 2955,\n",
       " 'free': 2956,\n",
       " 'ascending': 403,\n",
       " 'small': 583,\n",
       " 'using laptop': 877,\n",
       " 'hoodie': 404,\n",
       " 'lacoste': 2907,\n",
       " 'blinders': 405,\n",
       " 'tree branch': 211,\n",
       " 'on chair': 212,\n",
       " 'shelves': 2363,\n",
       " 'atv': 2364,\n",
       " 'bears': 2711,\n",
       " 'soda': 584,\n",
       " 'moving': 3070,\n",
       " 'cleaning': 2675,\n",
       " 'behind clouds': 1172,\n",
       " 'elmo': 1535,\n",
       " 'in street': 406,\n",
       " 'veggie': 2365,\n",
       " 'on pole': 1536,\n",
       " 'lettuce': 407,\n",
       " 'chevron': 15,\n",
       " 'fire truck': 585,\n",
       " 'comforter': 1920,\n",
       " 'scissors': 2957,\n",
       " 'thick': 1742,\n",
       " 'tusks': 2611,\n",
       " 'tuna': 2380,\n",
       " 'hood': 1173,\n",
       " 'basketball': 1537,\n",
       " 'hydrant': 898,\n",
       " 'lego': 777,\n",
       " 'top': 501,\n",
       " 'girls': 1174,\n",
       " 'tow': 2150,\n",
       " 'boating': 2764,\n",
       " 'guitar hero': 778,\n",
       " 'hollywood': 1921,\n",
       " 'john': 213,\n",
       " 'dogs': 214,\n",
       " 'kiwi': 2558,\n",
       " 'urban': 503,\n",
       " 'ceiling': 1375,\n",
       " 'on grass': 215,\n",
       " 'bacon': 2346,\n",
       " 'gym': 1922,\n",
       " 'serve': 1376,\n",
       " 'blue jay': 1175,\n",
       " 'no left turn': 1176,\n",
       " 'western': 1377,\n",
       " 'cereal': 216,\n",
       " 'crosstown': 217,\n",
       " 'schnauzer': 587,\n",
       " 'distance': 1924,\n",
       " 'target': 2560,\n",
       " 'tree': 1539,\n",
       " 'french fries': 1379,\n",
       " 'shower': 1540,\n",
       " 'iron': 2561,\n",
       " 'man on left': 780,\n",
       " 'beard': 2713,\n",
       " 'persian': 2998,\n",
       " 'bridge': 846,\n",
       " 'donkey': 1380,\n",
       " 'fashion': 1381,\n",
       " 'very big': 517,\n",
       " 'giraffes': 218,\n",
       " 'boston': 2366,\n",
       " 'modern': 1925,\n",
       " 'ginger': 409,\n",
       " 'talking': 1382,\n",
       " 'shell': 2315,\n",
       " 'no grass': 3071,\n",
       " 'mint': 1926,\n",
       " 'alive': 2926,\n",
       " 'cactus': 2744,\n",
       " 'concrete': 1649,\n",
       " 'bleachers': 1541,\n",
       " 'san diego': 410,\n",
       " 'snow': 2154,\n",
       " 'in stands': 782,\n",
       " 'chest': 2767,\n",
       " '101': 1909,\n",
       " 'shelf': 2316,\n",
       " 'circles': 2562,\n",
       " 'gravy': 219,\n",
       " 'shallow': 1497,\n",
       " 'thumb': 2406,\n",
       " 'zebras': 783,\n",
       " '5 ft': 2349,\n",
       " '6 feet': 3098,\n",
       " 'victoria': 784,\n",
       " 'mario': 412,\n",
       " 'no cat': 413,\n",
       " 'germany': 220,\n",
       " 'x': 2668,\n",
       " 'm': 1929,\n",
       " 'dog': 1930,\n",
       " 'camo': 1543,\n",
       " 'pineapple': 2155,\n",
       " 'queen': 2961,\n",
       " 'birthday party': 2934,\n",
       " 'north america': 2962,\n",
       " 'chandelier': 2564,\n",
       " 'radio': 2156,\n",
       " 'asia': 2746,\n",
       " 'fork and knife': 589,\n",
       " 'recliner': 786,\n",
       " 'toast': 2565,\n",
       " 'busy': 2367,\n",
       " 'on bike': 2566,\n",
       " 'menu': 787,\n",
       " 'train tracks': 997,\n",
       " 'on right': 17,\n",
       " 'sugar': 2505,\n",
       " 'celery': 415,\n",
       " 'bush': 2368,\n",
       " 'rice': 18,\n",
       " 'goalie': 998,\n",
       " 'rectangle': 221,\n",
       " 'plate': 19,\n",
       " 'tiles': 1932,\n",
       " 'sunglasses': 1383,\n",
       " 'wide': 3007,\n",
       " 'girl on right': 2158,\n",
       " 'honda': 1544,\n",
       " 'stop': 935,\n",
       " 'dc': 999,\n",
       " 'cardinals': 1743,\n",
       " 'pocket': 141,\n",
       " 'amazon': 2160,\n",
       " 'watermelon': 416,\n",
       " 'roundabout': 1327,\n",
       " 'cushion': 2369,\n",
       " 'wedding': 590,\n",
       " '15': 1991,\n",
       " 'relish': 1545,\n",
       " 'beads': 591,\n",
       " 'bar': 2771,\n",
       " 'sailing': 1993,\n",
       " 'noon': 2435,\n",
       " 'rowing': 2964,\n",
       " '16': 1994,\n",
       " '2:15': 2569,\n",
       " 'bag': 2773,\n",
       " 'bad': 2774,\n",
       " 'grilled': 1934,\n",
       " 'steak': 2570,\n",
       " 'steam': 2571,\n",
       " '90': 2354,\n",
       " 'ears': 417,\n",
       " 'playstation': 1178,\n",
       " '10:05': 1038,\n",
       " 'human': 1944,\n",
       " 'fair': 788,\n",
       " 'liquor': 1384,\n",
       " 'lemonade': 1000,\n",
       " '10:00': 1039,\n",
       " 'each other': 2161,\n",
       " 'noodles': 2162,\n",
       " 'game controller': 2370,\n",
       " 'brazil': 2775,\n",
       " 'cat and dog': 185,\n",
       " 'glass': 2353,\n",
       " 'lots': 20,\n",
       " 'away': 223,\n",
       " 'sail': 2776,\n",
       " \"they aren't\": 1385,\n",
       " 'shaved': 2777,\n",
       " 'salt and pepper': 2371,\n",
       " 'wetsuit': 1936,\n",
       " 'mud': 592,\n",
       " 'mug': 593,\n",
       " 'olympics': 2779,\n",
       " 'finger': 594,\n",
       " 'yogurt': 1547,\n",
       " 'looking out window': 789,\n",
       " 'laying down': 1179,\n",
       " 'herding': 595,\n",
       " 'never': 1165,\n",
       " 'nature': 21,\n",
       " 'metal': 2960,\n",
       " 'lotion': 418,\n",
       " 'on top': 1937,\n",
       " 'loading': 1465,\n",
       " 'playing game': 224,\n",
       " 'skull and crossbones': 225,\n",
       " 'news': 596,\n",
       " 'behind fence': 597,\n",
       " 'kitchen': 226,\n",
       " 'accident': 2372,\n",
       " 'cow': 1001,\n",
       " 'country': 1548,\n",
       " 'yamaha': 234,\n",
       " 'on bench': 1745,\n",
       " 'players': 2968,\n",
       " 'protection': 1181,\n",
       " 'throwing frisbee': 23,\n",
       " 'give way': 843,\n",
       " 'flying kite': 1946,\n",
       " 'no hat': 2573,\n",
       " 't shirt and jeans': 599,\n",
       " 'sheepdog': 2373,\n",
       " 'legs': 779,\n",
       " 'vaio': 791,\n",
       " 'zebra and giraffe': 1587,\n",
       " '2nd': 2374,\n",
       " 'towels': 1386,\n",
       " 'blending': 2375,\n",
       " 'blonde': 24,\n",
       " 'grazing': 1549,\n",
       " 'conference': 600,\n",
       " 'lighthouse': 2376,\n",
       " 'cardboard': 1167,\n",
       " 'beef': 1387,\n",
       " 'hay': 27,\n",
       " 'chrome': 792,\n",
       " 'on couch': 2574,\n",
       " 'parsley': 419,\n",
       " '1 4': 2163,\n",
       " 'beer': 1388,\n",
       " 'grapefruit': 2492,\n",
       " 'stadium': 1550,\n",
       " 'basil': 421,\n",
       " 'private': 2386,\n",
       " 'warmth': 1746,\n",
       " 'dots': 1551,\n",
       " 'life': 793,\n",
       " 'banana peel': 1552,\n",
       " 'sprite': 2164,\n",
       " 'mushroom': 976,\n",
       " 'not sure': 1553,\n",
       " 'lift': 794,\n",
       " 'coffee table': 2165,\n",
       " 'child': 795,\n",
       " 'catch': 2970,\n",
       " 'bunny': 1748,\n",
       " 'chili': 796,\n",
       " '3 feet': 227,\n",
       " 'stuffed animals': 2449,\n",
       " 'orange and blue': 1182,\n",
       " 'tank': 1183,\n",
       " 'n': 602,\n",
       " 'lizard': 985,\n",
       " 'onion rings': 228,\n",
       " 'ski lift': 2576,\n",
       " 'life jacket': 25,\n",
       " 'stopping': 2166,\n",
       " 'above toilet': 797,\n",
       " 'balance': 2780,\n",
       " 'hot sauce': 422,\n",
       " 'cylinder': 229,\n",
       " 'cane': 423,\n",
       " 'mexico': 2781,\n",
       " 'sticker': 2577,\n",
       " 'sushi': 2782,\n",
       " 'player': 2377,\n",
       " 'tissue': 230,\n",
       " 'cone': 231,\n",
       " 'in': 1184,\n",
       " 'cook': 2187,\n",
       " 'seattle': 2783,\n",
       " 'mouse': 1939,\n",
       " 'in air': 1728,\n",
       " 'bottles': 1185,\n",
       " 'emergency': 128,\n",
       " 'nike': 603,\n",
       " 'speed limit': 1554,\n",
       " 'gray and red': 798,\n",
       " 'white and green': 1223,\n",
       " 'babies': 799,\n",
       " 'big': 2875,\n",
       " 'vegetable': 2784,\n",
       " 'plates': 1002,\n",
       " 'several': 1390,\n",
       " 'skateboards': 1652,\n",
       " 'wheel': 232,\n",
       " 'bird feeder': 800,\n",
       " 'public market center': 582,\n",
       " 'rail': 1003,\n",
       " 'rain': 1004,\n",
       " 'hand': 233,\n",
       " '9:55': 2167,\n",
       " 'garlic': 1940,\n",
       " 'soccer ball': 1391,\n",
       " 'kia': 1941,\n",
       " 'on': 2507,\n",
       " 'kid': 1942,\n",
       " 'butter': 1943,\n",
       " 'dishes': 157,\n",
       " 'condiments': 1005,\n",
       " 'ocean': 604,\n",
       " 'hispanic': 1749,\n",
       " 'washington monument': 2971,\n",
       " 'mother': 2168,\n",
       " 'hearts': 2972,\n",
       " 'pooping': 996,\n",
       " 'left': 2785,\n",
       " 'american flag': 1555,\n",
       " 'photographer': 2579,\n",
       " 'photo': 1750,\n",
       " 'laptop': 2973,\n",
       " 'goggles': 2578,\n",
       " '50 feet': 1186,\n",
       " 'yes': 425,\n",
       " 'kayaking': 2651,\n",
       " 'hills': 1006,\n",
       " 'sunflower': 1187,\n",
       " 'elm': 598,\n",
       " 'in front': 1945,\n",
       " 'cherry': 605,\n",
       " 'boot': 3125,\n",
       " 'hilly': 1007,\n",
       " 'roast beef': 801,\n",
       " 'main street': 802,\n",
       " 'board': 1751,\n",
       " 'easy': 2382,\n",
       " 'east': 2383,\n",
       " 'hat': 28,\n",
       " 'to get to other side': 29,\n",
       " 'mayo': 2580,\n",
       " 'ski pole': 1008,\n",
       " 'wii controllers': 607,\n",
       " 'boxes': 1752,\n",
       " 'boxer': 1753,\n",
       " 'descending': 608,\n",
       " 'background': 2786,\n",
       " '12:35': 30,\n",
       " '6:05': 2384,\n",
       " 'shadow': 31,\n",
       " 'catching frisbee': 2974,\n",
       " '6:00': 2385,\n",
       " '12:30': 32,\n",
       " 'coffee maker': 609,\n",
       " '59': 2169,\n",
       " 'cooler': 235,\n",
       " 'lily': 1695,\n",
       " 'grizzly': 1009,\n",
       " '56': 2172,\n",
       " 'kitesurfing': 427,\n",
       " '50': 2174,\n",
       " '53': 2175,\n",
       " '52': 2176,\n",
       " 'train car': 803,\n",
       " 'pavement': 804,\n",
       " 'mickey mouse': 1818,\n",
       " 'steps': 805,\n",
       " 'night': 236,\n",
       " 'security': 1010,\n",
       " 'cirrus': 237,\n",
       " 'antique': 1011,\n",
       " 'butterfly': 2416,\n",
       " 'right': 2387,\n",
       " 'petting': 2177,\n",
       " 'people': 806,\n",
       " \"he's not\": 1949,\n",
       " 'crown': 33,\n",
       " 'dead': 428,\n",
       " 'crows': 34,\n",
       " 'dining room': 1188,\n",
       " '2:20': 1394,\n",
       " 'tie dye': 1012,\n",
       " 'orchid': 2582,\n",
       " '10 years': 429,\n",
       " 'bottom': 35,\n",
       " 'purple': 1013,\n",
       " 'fox': 807,\n",
       " 'ham and cheese': 430,\n",
       " 'fog': 808,\n",
       " 'cnn': 2975,\n",
       " '3:30': 1396,\n",
       " 'skateboarder': 431,\n",
       " 'christmas': 1397,\n",
       " 'trunk': 2645,\n",
       " 'cord': 1398,\n",
       " 'khaki': 610,\n",
       " 'k': 1524,\n",
       " 'corn': 1399,\n",
       " '34': 2096,\n",
       " 'lamps': 2179,\n",
       " 'post': 1754,\n",
       " 'dalmatian': 2180,\n",
       " 'benches': 37,\n",
       " 'cowboy': 2181,\n",
       " 'meow': 2787,\n",
       " 'o': 2389,\n",
       " 'dinner': 611,\n",
       " 'afternoon': 433,\n",
       " 'parking garage': 880,\n",
       " 'octopus': 1755,\n",
       " 'hospital': 2141,\n",
       " 'indians': 988,\n",
       " 'toothpicks': 612,\n",
       " 'mantle': 1014,\n",
       " 'tinkerbell': 2788,\n",
       " 'selfie': 434,\n",
       " 'fern': 613,\n",
       " 'down': 435,\n",
       " 'bats': 614,\n",
       " 'old': 2388,\n",
       " 'parade': 2680,\n",
       " 'palm tree': 1590,\n",
       " 'fabric': 38,\n",
       " 'tennis': 436,\n",
       " 'sunlight': 615,\n",
       " 'virgin': 2182,\n",
       " 'donut shop': 2789,\n",
       " 'towing': 616,\n",
       " 'wax': 1756,\n",
       " 'white and yellow': 1190,\n",
       " 'over easy': 1950,\n",
       " 'kiting': 617,\n",
       " 'war': 1757,\n",
       " 'happy': 809,\n",
       " 'fork': 1040,\n",
       " 'head': 1400,\n",
       " 'medium': 1401,\n",
       " 'yellow and white': 1191,\n",
       " 'snowy': 2584,\n",
       " 'batman': 437,\n",
       " 'tigers': 810,\n",
       " 'converse': 1758,\n",
       " 'landing': 438,\n",
       " 'ford': 1192,\n",
       " 'wireless': 2583,\n",
       " 'bags': 2827,\n",
       " 'heat': 1402,\n",
       " 'bottom right': 238,\n",
       " 'cat food': 1044,\n",
       " 'sailboats': 239,\n",
       " 'turtle': 2409,\n",
       " 'dump': 3058,\n",
       " 'congratulations': 39,\n",
       " 'slope': 2395,\n",
       " 'playing soccer': 2178,\n",
       " 'inside': 1557,\n",
       " 'trash': 3032,\n",
       " '7:10': 2586,\n",
       " '2:25': 1393,\n",
       " 'lays': 811,\n",
       " 'passenger': 40,\n",
       " 'sticks': 1193,\n",
       " 'classic': 1194,\n",
       " 'umpire': 2588,\n",
       " 'cleats': 1431,\n",
       " 'hungry': 2207,\n",
       " 'diamond': 2851,\n",
       " 'on sign': 2390,\n",
       " 'pink and white': 1559,\n",
       " 'playing video game': 708,\n",
       " 'muffins': 439,\n",
       " 'ship': 1195,\n",
       " 'triangles': 42,\n",
       " 'no': 1403,\n",
       " 'ny': 1404,\n",
       " 'setting': 618,\n",
       " '7:45': 2939,\n",
       " 'holding': 2589,\n",
       " 'digital': 1196,\n",
       " 'tie': 2976,\n",
       " 'roll': 43,\n",
       " 'whipped cream': 2393,\n",
       " 'evergreen': 1405,\n",
       " 'picture': 620,\n",
       " 'thumbs up': 2590,\n",
       " '4 way': 812,\n",
       " 'handicap': 440,\n",
       " 'center': 1346,\n",
       " 'purple and white': 2183,\n",
       " 'fell': 1067,\n",
       " 'red sox': 1197,\n",
       " 'jones': 2791,\n",
       " 'tugboat': 2591,\n",
       " 'younger': 2977,\n",
       " 'wii remote': 643,\n",
       " 'phone': 707,\n",
       " 'yacht': 2184,\n",
       " 'jacket': 441,\n",
       " 'teeth': 1952,\n",
       " 'serious': 2978,\n",
       " 'backward': 1406,\n",
       " 'adult': 1913,\n",
       " 'peacock': 813,\n",
       " 'cessna': 1953,\n",
       " 'riding bikes': 442,\n",
       " 'chain': 44,\n",
       " 'playing video games': 2911,\n",
       " 'under armour': 2963,\n",
       " 'skis': 1198,\n",
       " 'focus': 2186,\n",
       " 'silverware': 240,\n",
       " 'skate': 1560,\n",
       " 'daytime': 1189,\n",
       " 'skiing': 1561,\n",
       " 'baseball field': 2605,\n",
       " 'chair': 45,\n",
       " 'toothpick': 1016,\n",
       " 'milk': 2792,\n",
       " 'long time': 622,\n",
       " 'venice': 814,\n",
       " 'grape': 1017,\n",
       " 'show': 2000,\n",
       " 'father': 443,\n",
       " 'prom': 3073,\n",
       " 'crates': 46,\n",
       " '0': 444,\n",
       " 'bicycles': 1563,\n",
       " 'brushing his teeth': 2646,\n",
       " 'ride': 2699,\n",
       " 'southwest': 1760,\n",
       " 'brown': 2594,\n",
       " 'smartphone': 2647,\n",
       " 'string': 1199,\n",
       " 'on dresser': 766,\n",
       " 'banana bread': 1761,\n",
       " 'kitten': 1762,\n",
       " 'kitchenaid': 1763,\n",
       " 'cool': 2188,\n",
       " 'dim': 2793,\n",
       " 'on wall': 1408,\n",
       " 'clouds': 681,\n",
       " 'limes': 2794,\n",
       " 'freightliner': 2249,\n",
       " 'posts': 623,\n",
       " 'gun': 241,\n",
       " 'cloudy': 624,\n",
       " 'magnet': 1200,\n",
       " 'p': 1018,\n",
       " 'horseback riding': 242,\n",
       " 'teal': 817,\n",
       " 'team': 818,\n",
       " 'sidewalk': 2596,\n",
       " 'dip': 2796,\n",
       " 'round': 445,\n",
       " 'seaweed': 3100,\n",
       " 'slow down': 243,\n",
       " 'pork': 625,\n",
       " 'heinz': 1409,\n",
       " 'htc': 2597,\n",
       " '20 ft': 3074,\n",
       " 'collage': 1565,\n",
       " 'bedroom': 2522,\n",
       " 'rectangles': 3041,\n",
       " 'sign': 1566,\n",
       " '11:45': 47,\n",
       " 'shirts': 48,\n",
       " '12:28': 1955,\n",
       " 'soldiers': 2719,\n",
       " 'harry potter': 130,\n",
       " '12:25': 1956,\n",
       " 'chicken': 3101,\n",
       " '12:20': 1957,\n",
       " 'drinks': 2981,\n",
       " 'cargo': 1764,\n",
       " 'dog food': 1092,\n",
       " 'stands': 2982,\n",
       " 'kite string': 1958,\n",
       " 'wildebeest': 1765,\n",
       " 'mall': 2454,\n",
       " 'uniform': 1766,\n",
       " 'current': 819,\n",
       " 'falling': 2398,\n",
       " 'in hand': 2819,\n",
       " 'gazebo': 1959,\n",
       " 'transportation': 1201,\n",
       " 'on man': 2983,\n",
       " 'no smoking': 820,\n",
       " 'makeup': 1960,\n",
       " 'french': 2797,\n",
       " 'water': 2984,\n",
       " '2:30': 244,\n",
       " \"don't walk\": 2399,\n",
       " '2:35': 245,\n",
       " 'frosting': 446,\n",
       " 'teacher': 246,\n",
       " 'easton': 1202,\n",
       " '3:25': 247,\n",
       " 'boy': 448,\n",
       " 'male': 2456,\n",
       " '3:20': 248,\n",
       " 'healthy': 2190,\n",
       " 'bus station': 2400,\n",
       " 'name tag': 2986,\n",
       " 'bow': 449,\n",
       " 'cinnamon': 1410,\n",
       " 'bob': 450,\n",
       " 'pillow': 249,\n",
       " 'nowhere': 2494,\n",
       " 'easyjet': 1961,\n",
       " 'petting horse': 1568,\n",
       " 'love': 821,\n",
       " 'hiking': 1020,\n",
       " 'tuxedo': 626,\n",
       " 'shark': 1411,\n",
       " 'uphill': 251,\n",
       " 'snowboard': 1021,\n",
       " 'no light': 2191,\n",
       " 'sun hat': 451,\n",
       " '1st': 1412,\n",
       " 'playing wii': 2599,\n",
       " 'pony': 2251,\n",
       " 'market': 2600,\n",
       " '30 mph': 2682,\n",
       " 'sunbathing': 822,\n",
       " 'working': 340,\n",
       " 'birthday cake': 2614,\n",
       " '10:15': 2192,\n",
       " 'wicker': 1570,\n",
       " 'angry': 1571,\n",
       " '10:10': 2193,\n",
       " 'sports': 709,\n",
       " '4th of july': 1392,\n",
       " '1 in middle': 627,\n",
       " 'wood': 3010,\n",
       " 'iphone': 2194,\n",
       " 'sunflowers': 1500,\n",
       " 'softball': 2255,\n",
       " 'angels': 2601,\n",
       " 'conductor': 2988,\n",
       " 'club': 2602,\n",
       " 'phillies': 2799,\n",
       " 'fanta': 2820,\n",
       " 'oregon': 2403,\n",
       " 'chocolate': 1414,\n",
       " 'downtown': 2800,\n",
       " 'riding': 166,\n",
       " 'blinds': 2421,\n",
       " 'fly': 2801,\n",
       " 'ibm': 1478,\n",
       " 'tokyo': 2802,\n",
       " 'heineken': 823,\n",
       " 'cap': 1769,\n",
       " 'cat': 1770,\n",
       " 'wallet': 1203,\n",
       " 'can': 1771,\n",
       " 'ferry': 2989,\n",
       " 'pickle': 628,\n",
       " 'urinals': 3044,\n",
       " 'heart': 1772,\n",
       " 'nursing': 629,\n",
       " 'mirrors': 49,\n",
       " 'taking photo': 1415,\n",
       " 'confused': 1964,\n",
       " 'soup': 2803,\n",
       " 'parachute': 50,\n",
       " 'drawer': 2804,\n",
       " 'pizza box': 452,\n",
       " 'pond': 2252,\n",
       " 'black and brown': 630,\n",
       " 'clothing': 1773,\n",
       " 'wetsuits': 1489,\n",
       " 'pink': 1204,\n",
       " 'rays': 1205,\n",
       " 'winter': 824,\n",
       " 'to catch frisbee': 1206,\n",
       " 'sailboat': 631,\n",
       " 'watching': 2321,\n",
       " 'brand': 2930,\n",
       " 'magazine': 432,\n",
       " 'pine': 1207,\n",
       " '1': 2195,\n",
       " '7:00': 1416,\n",
       " 'cardinal': 2196,\n",
       " '7:05': 1417,\n",
       " 'elephant': 825,\n",
       " 'tile': 1208,\n",
       " 'photography': 2913,\n",
       " 'under sink': 1573,\n",
       " 'laundry': 1874,\n",
       " 'mat': 1966,\n",
       " 'information': 884,\n",
       " 'flat screen': 252,\n",
       " 'on his head': 2992,\n",
       " 'man in middle': 453,\n",
       " 'ducati': 1776,\n",
       " 'produce': 253,\n",
       " 'toilet paper': 1778,\n",
       " 'vases': 254,\n",
       " 'floral': 2993,\n",
       " 'green and black': 2852,\n",
       " 'tablecloth': 454,\n",
       " 'man': 1968,\n",
       " 'classroom': 2994,\n",
       " 'surfing': 51,\n",
       " 'natural': 1574,\n",
       " 'neck': 1969,\n",
       " 'candles': 1023,\n",
       " 'wheelchair': 826,\n",
       " 'placemat': 2404,\n",
       " 'corona': 255,\n",
       " 'daisies': 2883,\n",
       " 'mango': 52,\n",
       " 'in box': 85,\n",
       " 'african': 2807,\n",
       " 'basket': 455,\n",
       " 'tall': 1970,\n",
       " '2 years': 632,\n",
       " 'bunk': 2947,\n",
       " 'blue team': 1779,\n",
       " 'cute': 1210,\n",
       " 'serving': 256,\n",
       " 'shoes': 456,\n",
       " 'haircut': 1024,\n",
       " 'years': 53,\n",
       " 'stability': 1211,\n",
       " 'pizza cutter': 1575,\n",
       " 'pitch': 1971,\n",
       " 'marshmallows': 1212,\n",
       " 'cold': 1025,\n",
       " 'still': 257,\n",
       " 'birds': 1026,\n",
       " 'police': 457,\n",
       " 'monitor': 458,\n",
       " 'curly': 2606,\n",
       " 'smoothie': 1213,\n",
       " 'bagels': 829,\n",
       " 'polka dot': 830,\n",
       " 'platform': 633,\n",
       " 'window': 1027,\n",
       " '2 men': 831,\n",
       " 'gatorade': 832,\n",
       " 'farmer': 634,\n",
       " 'main': 2809,\n",
       " 'tiara': 258,\n",
       " 'texas': 1214,\n",
       " ...}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans2label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
