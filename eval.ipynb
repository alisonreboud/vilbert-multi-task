{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/aloui/miniconda3/envs/vilbert-mt/lib/python3.6/site-packages/tensorpack/callbacks/hooks.py:17: The name tf.train.SessionRunHook is deprecated. Please use tf.estimator.SessionRunHook instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/aloui/miniconda3/envs/vilbert-mt/lib/python3.6/site-packages/tensorpack/tfutils/optimizer.py:18: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/aloui/miniconda3/envs/vilbert-mt/lib/python3.6/site-packages/tensorpack/tfutils/sesscreate.py:20: The name tf.train.SessionCreator is deprecated. Please use tf.compat.v1.train.SessionCreator instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import json\n",
    "import logging\n",
    "import os\n",
    "import random\n",
    "from io import open\n",
    "import numpy as np\n",
    "\n",
    "from tensorboardX import SummaryWriter\n",
    "from tqdm import tqdm\n",
    "from bisect import bisect\n",
    "import yaml\n",
    "from easydict import EasyDict as edict\n",
    "import sys\n",
    "import pdb\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "\n",
    "from vilbert.task_utils import (\n",
    "    LoadDatasetEval,\n",
    "    LoadLosses,\n",
    "    ForwardModelsTrain,\n",
    "    ForwardModelsVal,\n",
    "    EvaluatingModel,\n",
    ")\n",
    "\n",
    "import vilbert.utils as utils\n",
    "import torch.distributed as dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(\n",
    "    format=\"%(asctime)s - %(levelname)s - %(name)s -   %(message)s\",\n",
    "    datefmt=\"%m/%d/%Y %H:%M:%S\",\n",
    "    level=logging.INFO,\n",
    ")\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/30/2020 12:53:11 - INFO - __main__ -   device: cuda n_gpu: 1, distributed training: False, 16-bits training: False\n",
      "07/30/2020 12:53:11 - INFO - pytorch_transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/aloui/.cache/torch/pytorch_transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
      "07/30/2020 12:53:11 - INFO - vilbert.task_utils -   Loading VQA Dataset with batch size 30\n",
      "07/30/2020 12:53:11 - INFO - vilbert.datasets.vqa_dataset -   Loading from datasets/VQA/cache/VQA_test_23_cleaned.pkl\n",
      "07/30/2020 12:54:27 - INFO - vilbert.utils -   logging file at: pytorch_model_19.bin-jupyter-test\n",
      "07/30/2020 12:54:27 - INFO - vilbert.utils -   loading weights file save/VQA_bert_base_6layer_6conect-finetune_from_multi_task_model/pytorch_model_19.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Running evaluation *****\n",
      "  Num Iters:  {'TASK1': 14927}\n",
      "  Batch size:  {'TASK1': 30}\n",
      "14926/14927\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/30/2020 13:24:34 - INFO - vilbert.utils -   Eval task TASK1 on iteration 0 \n",
      "07/30/2020 13:24:34 - INFO - vilbert.utils -   Validation [VQA]: loss 6.200 score 0.000 \n"
     ]
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "parser.add_argument(\n",
    "    \"--bert_model\",\n",
    "    default=\"bert-base-uncased\",\n",
    "    type=str,\n",
    "    help=\"Bert pre-trained model selected in the list: bert-base-uncased, \"\n",
    "    \"bert-large-uncased, bert-base-cased, bert-base-multilingual, bert-base-chinese.\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--from_pretrained\",\n",
    "    default=\"bert-base-uncased\",\n",
    "    type=str,\n",
    "    help=\"Bert pre-trained model selected in the list: bert-base-uncased, \"\n",
    "    \"bert-large-uncased, bert-base-cased, bert-base-multilingual, bert-base-chinese.\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--output_dir\",\n",
    "    default=\"results\",\n",
    "    type=str,\n",
    "    help=\"The output directory where the model checkpoints will be written.\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--config_file\",\n",
    "    default=\"config/bert_config.json\",\n",
    "    type=str,\n",
    "    help=\"The config file which specified the model details.\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--no_cuda\", action=\"store_true\", help=\"Whether not to use CUDA when available\"\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--do_lower_case\",\n",
    "    default=True,\n",
    "    type=bool,\n",
    "    help=\"Whether to lower case the input text. True for uncased models, False for cased models.\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--local_rank\",\n",
    "    type=int,\n",
    "    default=-1,\n",
    "    help=\"local_rank for distributed training on gpus\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--seed\", type=int, default=42, help=\"random seed for initialization\"\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--fp16\",\n",
    "    action=\"store_true\",\n",
    "    help=\"Whether to use 16-bit float precision instead of 32-bit\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--loss_scale\",\n",
    "    type=float,\n",
    "    default=0,\n",
    "    help=\"Loss scaling to improve fp16 numeric stability. Only used when fp16 set to True.\\n\"\n",
    "    \"0 (default value): dynamic loss scaling.\\n\"\n",
    "    \"Positive power of 2: static loss scaling value.\\n\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--num_workers\",\n",
    "    type=int,\n",
    "    default=16,\n",
    "    help=\"Number of workers in the dataloader.\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--save_name\", default=\"\", type=str, help=\"save name for training.\"\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--use_chunk\",\n",
    "    default=0,\n",
    "    type=float,\n",
    "    help=\"whether use chunck for parallel training.\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--batch_size\", default=30, type=int, help=\"what is the batch size?\"\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--tasks\", default=\"\", type=str, help=\"1-2-3... training task separate by -\"\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--in_memory\",\n",
    "    default=False,\n",
    "    type=bool,\n",
    "    help=\"whether use chunck for parallel training.\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--baseline\", action=\"store_true\", help=\"whether use single stream baseline.\"\n",
    ")\n",
    "parser.add_argument(\"--split\", default=\"\", type=str, help=\"which split to use.\")\n",
    "parser.add_argument(\n",
    "    \"--dynamic_attention\",\n",
    "    action=\"store_true\",\n",
    "    help=\"whether use dynamic attention.\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--clean_train_sets\",\n",
    "    default=True,\n",
    "    type=bool,\n",
    "    help=\"whether clean train sets for multitask data.\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--visual_target\",\n",
    "    default=0,\n",
    "    type=int,\n",
    "    help=\"which target to use for visual branch. \\\n",
    "    0: soft label, \\\n",
    "    1: regress the feature, \\\n",
    "    2: NCE loss.\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--task_specific_tokens\",\n",
    "    action=\"store_true\",\n",
    "    help=\"whether to use task specific tokens for the multi-task learning.\",\n",
    ")\n",
    "\n",
    "#args = parser.parse_args()\n",
    "args = parser.parse_args(['--bert_model', 'bert-base-uncased',\n",
    "                          '--from_pretrained', 'save/VQA_bert_base_6layer_6conect-finetune_from_multi_task_model/pytorch_model_19.bin',\n",
    "                          '--config_file', 'config/bert_base_6layer_6conect.json',\n",
    "                          '--tasks', '1',\n",
    "                          '--split', 'test',\n",
    "                          '--save_name', 'jupyter-test',\n",
    "                          '--task_specific_tokens'])\n",
    "\n",
    "\n",
    "with open(\"vilbert_tasks.yml\", \"r\") as f:\n",
    "    task_cfg = edict(yaml.safe_load(f))\n",
    "\n",
    "random.seed(args.seed)\n",
    "np.random.seed(args.seed)\n",
    "torch.manual_seed(args.seed)\n",
    "\n",
    "if args.baseline:\n",
    "    from pytorch_transformers.modeling_bert import BertConfig\n",
    "    from vilbert.basebert import BaseBertForVLTasks\n",
    "else:\n",
    "    from vilbert.vilbert import BertConfig\n",
    "    from vilbert.vilbert import VILBertForVLTasks\n",
    "\n",
    "task_names = []\n",
    "for i, task_id in enumerate(args.tasks.split(\"-\")):\n",
    "    task = \"TASK\" + task_id\n",
    "    name = task_cfg[task][\"name\"]\n",
    "    task_names.append(name)\n",
    "\n",
    "# timeStamp = '-'.join(task_names) + '_' + args.config_file.split('/')[1].split('.')[0]\n",
    "timeStamp = args.from_pretrained.split(\"/\")[-1] + \"-\" + args.save_name\n",
    "savePath = os.path.join(args.output_dir, timeStamp)\n",
    "config = BertConfig.from_json_file(args.config_file)\n",
    "\n",
    "if args.task_specific_tokens:\n",
    "    config.task_specific_tokens = True\n",
    "\n",
    "if args.local_rank == -1 or args.no_cuda:\n",
    "    device = torch.device(\n",
    "        \"cuda\" if torch.cuda.is_available() and not args.no_cuda else \"cpu\"\n",
    "    )\n",
    "    n_gpu = torch.cuda.device_count()\n",
    "else:\n",
    "    torch.cuda.set_device(args.local_rank)\n",
    "    device = torch.device(\"cuda\", args.local_rank)\n",
    "    n_gpu = 1\n",
    "    # Initializes the distributed backend which will take care of sychronizing nodes/GPUs\n",
    "    torch.distributed.init_process_group(backend=\"nccl\")\n",
    "\n",
    "logger.info(\n",
    "    \"device: {} n_gpu: {}, distributed training: {}, 16-bits training: {}\".format(\n",
    "        device, n_gpu, bool(args.local_rank != -1), args.fp16\n",
    "    )\n",
    ")\n",
    "\n",
    "default_gpu = False\n",
    "if dist.is_available() and args.local_rank != -1:\n",
    "    rank = dist.get_rank()\n",
    "    if rank == 0:\n",
    "        default_gpu = True\n",
    "else:\n",
    "    default_gpu = True\n",
    "\n",
    "if default_gpu and not os.path.exists(savePath):\n",
    "    os.makedirs(savePath)\n",
    "\n",
    "task_batch_size, task_num_iters, task_ids, task_datasets_val, task_dataloader_val = LoadDatasetEval(\n",
    "    args, task_cfg, args.tasks.split(\"-\")\n",
    ")\n",
    "\n",
    "tbLogger = utils.tbLogger(\n",
    "    timeStamp,\n",
    "    savePath,\n",
    "    task_names,\n",
    "    task_ids,\n",
    "    task_num_iters,\n",
    "    1,\n",
    "    save_logger=False,\n",
    "    txt_name=\"eval.txt\",\n",
    ")\n",
    "num_labels = max([dataset.num_labels for dataset in task_datasets_val.values()])\n",
    "\n",
    "if args.dynamic_attention:\n",
    "    config.dynamic_attention = True\n",
    "if \"roberta\" in args.bert_model:\n",
    "    config.model = \"roberta\"\n",
    "\n",
    "if args.visual_target == 0:\n",
    "    config.v_target_size = 1601\n",
    "    config.visual_target = args.visual_target\n",
    "else:\n",
    "    config.v_target_size = 2048\n",
    "    config.visual_target = args.visual_target\n",
    "\n",
    "if args.task_specific_tokens:\n",
    "    config.task_specific_tokens = True\n",
    "\n",
    "if args.baseline:\n",
    "    model = BaseBertForVLTasks.from_pretrained(\n",
    "        args.from_pretrained,\n",
    "        config=config,\n",
    "        num_labels=num_labels,\n",
    "        default_gpu=default_gpu,\n",
    "    )\n",
    "else:\n",
    "    model = VILBertForVLTasks.from_pretrained(\n",
    "        args.from_pretrained,\n",
    "        config=config,\n",
    "        num_labels=num_labels,\n",
    "        default_gpu=default_gpu,\n",
    "    )\n",
    "\n",
    "task_losses = LoadLosses(args, task_cfg, args.tasks.split(\"-\"))\n",
    "model.to(device)\n",
    "if args.local_rank != -1:\n",
    "    try:\n",
    "        from apex.parallel import DistributedDataParallel as DDP\n",
    "    except ImportError:\n",
    "        raise ImportError(\n",
    "            \"Please install apex from https://www.github.com/nvidia/apex to use distributed and fp16 training.\"\n",
    "        )\n",
    "    model = DDP(model, delay_allreduce=True)\n",
    "\n",
    "elif n_gpu > 1:\n",
    "    model = nn.DataParallel(model)\n",
    "\n",
    "print(\"***** Running evaluation *****\")\n",
    "print(\"  Num Iters: \", task_num_iters)\n",
    "print(\"  Batch size: \", task_batch_size)\n",
    "\n",
    "model.eval()\n",
    "# when run evaluate, we run each task sequentially.\n",
    "for task_id in task_ids:\n",
    "    results = []\n",
    "    others = []\n",
    "    \n",
    "    for i, batch in enumerate(task_dataloader_val[task_id]):\n",
    "        loss, score, batch_size, results, others = EvaluatingModel(\n",
    "            args,\n",
    "            task_cfg,\n",
    "            device,\n",
    "            task_id,\n",
    "            batch,\n",
    "            model,\n",
    "            task_dataloader_val,\n",
    "            task_losses,\n",
    "            results,\n",
    "            others,\n",
    "        )\n",
    "\n",
    "        tbLogger.step_val(0, float(loss), float(score), task_id, batch_size, \"val\")\n",
    "        sys.stdout.write(\"%d/%d\\r\" % (i, len(task_dataloader_val[task_id])))\n",
    "        sys.stdout.flush()\n",
    "    # save the result or evaluate the result.\n",
    "    ave_score = tbLogger.showLossVal(task_id)\n",
    "\n",
    "    if args.split:\n",
    "        json_path = os.path.join(savePath, args.split)\n",
    "    else:\n",
    "        json_path = os.path.join(savePath, task_cfg[task_id][\"val_split\"])\n",
    "\n",
    "    json.dump(results, open(json_path + \"_result.json\", \"w\"))\n",
    "    json.dump(others, open(json_path + \"_others.json\", \"w\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable              Type                          Data/Info\n",
      "-------------------------------------------------------------\n",
      "BertConfig            type                          <class 'vilbert.vilbert.BertConfig'>\n",
      "EvaluatingModel       function                      <function EvaluatingModel at 0x7fc9b59b5ea0>\n",
      "F                     module                        <module 'torch.nn.functio<...>/torch/nn/functional.py'>\n",
      "ForwardModelsTrain    function                      <function ForwardModelsTrain at 0x7fc9b59b5bf8>\n",
      "ForwardModelsVal      function                      <function ForwardModelsVal at 0x7fc9b59b5b70>\n",
      "LoadDatasetEval       function                      <function LoadDatasetEval at 0x7fc9b59b5d90>\n",
      "LoadLosses            function                      <function LoadLosses at 0x7fc9b59b5c80>\n",
      "SummaryWriter         type                          <class 'tensorboardX.writer.SummaryWriter'>\n",
      "VILBertForVLTasks     type                          <class 'vilbert.vilbert.VILBertForVLTasks'>\n",
      "argparse              module                        <module 'argparse' from '<...>b/python3.6/argparse.py'>\n",
      "args                  Namespace                     Namespace(baseline=False,<...>chunk=0, visual_target=0)\n",
      "ave_score             float                         0.0\n",
      "batch                 list                          n=9\n",
      "batch_size            int                           13\n",
      "bisect                builtin_function_or_method    <built-in function bisect>\n",
      "config                BertConfig                    {\\n  \"attention_probs_dro<...>h_coattention\": true\\n}\\n\n",
      "default_gpu           bool                          True\n",
      "device                device                        cuda\n",
      "dist                  module                        <module 'torch.distribute<...>distributed/__init__.py'>\n",
      "edict                 type                          <class 'easydict.EasyDict'>\n",
      "f                     TextIOWrapper                 <_io.TextIOWrapper name='<...>ode='r' encoding='UTF-8'>\n",
      "i                     int                           14926\n",
      "json                  module                        <module 'json' from '/hom<...>hon3.6/json/__init__.py'>\n",
      "json_path             str                           results/pytorch_model_19.bin-jupyter-test/test\n",
      "logger                Logger                        <Logger __main__ (INFO)>\n",
      "logging               module                        <module 'logging' from '/<...>3.6/logging/__init__.py'>\n",
      "loss                  float                         6.742756366729736\n",
      "model                 VILBertForVLTasks             VILBertForVLTasks(\\n  (be<...>features=1, bias=True)\\n)\n",
      "n_gpu                 int                           1\n",
      "name                  str                           VQA\n",
      "nn                    module                        <module 'torch.nn' from '<...>es/torch/nn/__init__.py'>\n",
      "np                    module                        <module 'numpy' from '/ho<...>kages/numpy/__init__.py'>\n",
      "num_labels            int                           3129\n",
      "open                  builtin_function_or_method    <built-in function open>\n",
      "os                    module                        <module 'os' from '/home/<...>-mt/lib/python3.6/os.py'>\n",
      "others                list                          n=0\n",
      "parser                ArgumentParser                ArgumentParser(prog='ipyk<...>r='error', add_help=True)\n",
      "pdb                   module                        <module 'pdb' from '/home<...>mt/lib/python3.6/pdb.py'>\n",
      "random                module                        <module 'random' from '/h<...>lib/python3.6/random.py'>\n",
      "results               list                          n=447793\n",
      "savePath              str                           results/pytorch_model_19.bin-jupyter-test\n",
      "score                 float                         0.0\n",
      "sys                   module                        <module 'sys' (built-in)>\n",
      "task                  str                           TASK1\n",
      "task_batch_size       dict                          n=1\n",
      "task_cfg              EasyDict                      {'TASK1': {'name': 'VQA',<...> 2e-06, 'num_epoch': 20}}\n",
      "task_dataloader_val   dict                          n=1\n",
      "task_datasets_val     dict                          n=1\n",
      "task_id               str                           TASK1\n",
      "task_ids              list                          n=1\n",
      "task_losses           dict                          n=1\n",
      "task_names            list                          n=1\n",
      "task_num_iters        dict                          n=1\n",
      "tbLogger              tbLogger                      <vilbert.utils.tbLogger object at 0x7fca3cf98160>\n",
      "timeStamp             str                           pytorch_model_19.bin-jupyter-test\n",
      "torch                 module                        <module 'torch' from '/ho<...>kages/torch/__init__.py'>\n",
      "tqdm                  type                          <class 'tqdm._tqdm.tqdm'>\n",
      "utils                 module                        <module 'vilbert.utils' f<...>i-task/vilbert/utils.py'>\n",
      "yaml                  module                        <module 'yaml' from '/hom<...>ckages/yaml/__init__.py'>\n"
     ]
    }
   ],
   "source": [
    "%whos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Namespace(baseline=False, batch_size=30, bert_model='bert-base-uncased', clean_train_sets=True, config_file='config/bert_base_6layer_6conect.json', do_lower_case=True, dynamic_attention=False, fp16=False, from_pretrained='save/VQA_bert_base_6layer_6conect-finetune_from_multi_task_model/pytorch_model_19.bin', in_memory=False, local_rank=-1, loss_scale=0, no_cuda=False, num_workers=16, output_dir='results', save_name='jupyter-test', seed=42, split='test', task_specific_tokens=True, tasks='1', use_chunk=0, visual_target=0)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = tuple(t.cuda(device=device, non_blocking=True) for t in batch)\n",
    "\n",
    "features, spatials, image_mask, question, target, input_mask, segment_ids, co_attention_mask, question_id = (\n",
    "    batch\n",
    ")\n",
    "\n",
    "task_tokens = question.new().resize_(question.size(0), 1).fill_(int(task_id[4:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "vil_prediction, vil_prediction_gqa, vil_logit, vil_binary_prediction, vil_tri_prediction, vision_prediction, vision_logit, linguisic_prediction, linguisic_logit, _ = model(\n",
    "    question, \n",
    "    features, \n",
    "    spatials, \n",
    "    segment_ids, \n",
    "    input_mask, \n",
    "    image_mask, \n",
    "    co_attention_mask, \n",
    "    task_tokens,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = torch.max(vil_prediction, 1)[1].data  # argmax\n",
    "one_hots = torch.zeros(*target.size()).cuda()\n",
    "one_hots.scatter_(1, logits.view(-1, 1), 1)\n",
    "scores = one_hots * target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.7033, device='cuda:0')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores.sum() / features.size(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/aloui/vilbert-multi-task/vilbert/vilbert.py:1333: TracerWarning: resize_ can't be represented in the JIT at the moment, so we won't connect any uses of this value with its current trace. If you happen to use it again, it will show up as a constant in the graph.\n",
      "  mask_tokens = input_txt.new().resize_(input_txt.size(0), 1).fill_(1)\n",
      "/aloui/vilbert-multi-task/vilbert/vilbert.py:1686: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if pooled_output.size(0) % 2 == 0:\n",
      "/home/aloui/miniconda3/envs/vilbert-mt/lib/python3.6/site-packages/torch/tensor.py:461: RuntimeWarning: Iterating over a tensor might cause the trace to be incorrect. Passing a tensor of different shape won't change the number of iterations executed (and might lead to errors or silently give incorrect results).\n",
      "  'incorrect results).', category=RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tracer cannot infer type of (tensor([[-27.4702, -20.0061, -19.1144,  ..., -20.4823, -16.3293, -18.1125],\n",
      "        [-25.9752, -12.4897, -14.5002,  ..., -19.2217, -13.6832, -16.6774],\n",
      "        [-25.3385, -20.9599, -20.1954,  ..., -16.5659, -13.5078, -19.9544],\n",
      "        ...,\n",
      "        [-27.0937, -18.9782, -20.0203,  ..., -19.8446, -16.5560, -18.3714],\n",
      "        [-29.0177, -21.6413, -19.3137,  ..., -20.1550, -14.5698, -19.3638],\n",
      "        [-17.8832, -17.1968, -18.6551,  ..., -23.1266, -12.8441, -15.4455]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>), tensor([[-20.4525, -16.6485, -17.6500,  ..., -20.9428, -23.7464, -22.9949],\n",
      "        [-10.2533,  -9.6277, -12.2720,  ..., -10.0366, -11.6091, -11.4118],\n",
      "        [-14.6426,  -9.9717, -13.2709,  ..., -14.0173, -15.2406, -15.0422],\n",
      "        ...,\n",
      "        [-20.2942, -16.5288, -18.7356,  ..., -20.5999, -23.1127, -22.5909],\n",
      "        [-20.3451, -16.0831, -16.7768,  ..., -22.0253, -22.7605, -22.9622],\n",
      "        [-22.4740, -18.9633, -20.5899,  ..., -21.3940, -20.9538, -21.7462]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>), tensor([[ 0.0599],\n",
      "        [ 0.1171],\n",
      "        [ 0.4941],\n",
      "        [ 0.9925],\n",
      "        [-3.3296],\n",
      "        [-1.9499],\n",
      "        [-2.8255],\n",
      "        [ 2.9162],\n",
      "        [ 2.2314],\n",
      "        [-1.3572],\n",
      "        [ 0.0750],\n",
      "        [ 0.3308],\n",
      "        [-6.4344]], device='cuda:0', grad_fn=<AddmmBackward>), tensor([[ 1.0168, -1.4560],\n",
      "        [ 0.4394, -0.7130],\n",
      "        [ 0.5635, -1.0259],\n",
      "        [ 0.9504, -0.9160],\n",
      "        [-1.5116,  0.9104],\n",
      "        [-0.7247,  0.0473],\n",
      "        [-1.6223,  1.0563],\n",
      "        [ 2.2997, -2.7921],\n",
      "        [ 1.8853, -2.7878],\n",
      "        [-1.1677,  0.1753],\n",
      "        [ 1.2776, -1.5721],\n",
      "        [ 0.9433, -1.1861],\n",
      "        [-2.0293,  2.0754]], device='cuda:0', grad_fn=<AddmmBackward>), tensor([[-3.5996,  0.2554, -0.9897],\n",
      "        [-0.9617, -0.6349, -2.2250],\n",
      "        [-1.7885, -0.4647, -2.0216],\n",
      "        [-2.9917, -2.8721, -1.7129],\n",
      "        [ 0.0503, -1.3153, -4.0771],\n",
      "        [-0.7456, -1.6966, -3.1057],\n",
      "        [ 0.0762, -1.1042, -3.7933],\n",
      "        [-2.6247,  0.1129, -1.8018],\n",
      "        [-4.2214, -4.0598,  2.1115],\n",
      "        [-0.4129, -0.9595, -4.1957],\n",
      "        [-3.7155, -0.6163,  0.0436],\n",
      "        [-2.6387,  0.6272, -2.1931],\n",
      "        [ 4.2082, -4.8643, -5.8948]], device='cuda:0', grad_fn=<AddmmBackward>), tensor([[[ 6.9932, -6.0197, -1.8061,  ..., -5.5277, -4.0174, -4.6866],\n",
      "         [ 6.0698, -4.2143, -4.4177,  ..., -4.5690, -1.5735, -3.7839],\n",
      "         [ 6.9017, -4.5599, -3.6356,  ..., -5.3572, -4.7600, -3.4384],\n",
      "         ...,\n",
      "         [ 6.3078, -5.4526, -2.7511,  ..., -4.4551, -3.3576, -2.5950],\n",
      "         [ 6.2105, -6.8478, -3.5844,  ..., -5.8020, -4.4306, -5.3767],\n",
      "         [ 7.4624, -3.5126, -2.7239,  ..., -6.1464, -3.2660, -3.0274]],\n",
      "\n",
      "        [[ 6.5387, -7.3786, -4.7384,  ..., -3.5706, -2.2800, -5.4530],\n",
      "         [ 6.2333, -6.0986, -4.3881,  ..., -2.9597, -2.9377, -4.9595],\n",
      "         [ 6.6095, -7.1808, -3.8217,  ..., -1.3874, -2.0545, -5.0085],\n",
      "         ...,\n",
      "         [ 6.5636, -6.7779, -3.8220,  ..., -3.0767, -2.9216, -3.5481],\n",
      "         [ 6.4958, -6.7223, -4.4355,  ..., -2.4478, -2.7105, -4.5684],\n",
      "         [ 6.3298, -5.1766, -4.1231,  ..., -2.4257, -0.7212, -4.0867]],\n",
      "\n",
      "        [[ 6.9256, -6.4389, -4.7385,  ..., -5.8783, -4.3740, -5.8362],\n",
      "         [ 5.9885, -6.3019, -6.3263,  ..., -4.2401, -2.5165, -5.5382],\n",
      "         [ 6.4484, -4.5275, -4.4486,  ..., -4.6965, -1.6494, -4.5384],\n",
      "         ...,\n",
      "         [ 6.7272, -5.1716, -5.2925,  ..., -6.3015, -4.4967, -5.2962],\n",
      "         [ 8.0347, -5.4510, -4.3193,  ..., -7.0748, -4.8594, -5.0436],\n",
      "         [ 7.3415, -5.5104, -3.2990,  ..., -4.7945, -4.3692, -5.3421]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 7.1706, -7.1711, -4.5917,  ..., -5.6644, -4.1178, -5.6369],\n",
      "         [ 6.6126, -6.1385, -3.9587,  ..., -5.3651, -3.3678, -3.1463],\n",
      "         [ 5.8712, -4.7684, -4.9580,  ..., -4.4504, -1.4958, -3.9552],\n",
      "         ...,\n",
      "         [ 6.6971, -6.1093, -5.6312,  ..., -6.3874, -5.5427, -4.6938],\n",
      "         [ 7.6637, -6.5825, -5.1593,  ..., -7.1620, -4.8586, -4.4052],\n",
      "         [ 7.7266, -6.3126, -3.3587,  ..., -4.3614, -3.7595, -4.5945]],\n",
      "\n",
      "        [[ 6.7432, -8.0850, -4.9500,  ..., -5.9540, -3.1517, -7.3474],\n",
      "         [ 6.5131, -7.0408, -4.8714,  ..., -6.0469, -3.4530, -4.4121],\n",
      "         [ 5.5832, -4.9256, -5.2396,  ..., -4.8160, -1.3953, -5.0350],\n",
      "         ...,\n",
      "         [ 6.5053, -6.7370, -5.6225,  ..., -6.2398, -3.8963, -6.7754],\n",
      "         [ 7.1917, -7.0501, -5.3987,  ..., -7.4047, -4.4696, -6.2787],\n",
      "         [ 6.8749, -6.2893, -3.4541,  ..., -4.7570, -3.7967, -5.8311]],\n",
      "\n",
      "        [[ 5.7978, -4.6452, -4.6846,  ..., -5.9551, -2.9711, -5.7627],\n",
      "         [ 5.7749, -5.8742, -5.4230,  ..., -4.5581, -3.0574, -4.6296],\n",
      "         [ 5.7048, -4.7278, -6.1124,  ..., -4.2225, -1.5135, -5.6646],\n",
      "         ...,\n",
      "         [ 5.9001, -4.9484, -6.3717,  ..., -4.6494, -3.7034, -5.5895],\n",
      "         [ 6.8969, -5.8425, -6.9073,  ..., -5.8385, -3.8361, -5.4630],\n",
      "         [ 7.0598, -5.2407, -4.7488,  ..., -4.0350, -2.8269, -4.4923]]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>), tensor([[[ 1.1992e-02],\n",
      "         [ 2.0590e-01],\n",
      "         [-5.1387e+00],\n",
      "         ...,\n",
      "         [ 4.4118e-02],\n",
      "         [-4.2576e+00],\n",
      "         [-1.6857e+00]],\n",
      "\n",
      "        [[ 5.6642e-01],\n",
      "         [ 4.1032e-03],\n",
      "         [-2.0958e+00],\n",
      "         ...,\n",
      "         [-3.1959e+00],\n",
      "         [-2.3279e+00],\n",
      "         [-4.8118e-02]],\n",
      "\n",
      "        [[-9.3151e-01],\n",
      "         [-2.1123e+00],\n",
      "         [-8.0695e-02],\n",
      "         ...,\n",
      "         [-2.9982e+00],\n",
      "         [-3.0473e+00],\n",
      "         [-3.7810e+00]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-1.0506e+00],\n",
      "         [-4.2981e+00],\n",
      "         [ 8.7635e-02],\n",
      "         ...,\n",
      "         [-2.7343e+00],\n",
      "         [-3.8368e+00],\n",
      "         [-5.6515e+00]],\n",
      "\n",
      "        [[-1.9733e+00],\n",
      "         [-4.8770e+00],\n",
      "         [-6.0173e-01],\n",
      "         ...,\n",
      "         [-3.8316e+00],\n",
      "         [-2.3288e+00],\n",
      "         [-4.5286e+00]],\n",
      "\n",
      "        [[ 9.2018e-01],\n",
      "         [-3.9517e+00],\n",
      "         [-1.6769e+00],\n",
      "         ...,\n",
      "         [-1.1097e-01],\n",
      "         [-1.3863e+00],\n",
      "         [-1.7185e+00]]], device='cuda:0', grad_fn=<AddBackward0>), tensor([[[-4.6560e+00, -4.2019e+00, -4.4733e+00,  ..., -4.6358e+00,\n",
      "          -4.8291e+00, -4.6108e+00],\n",
      "         [-5.2868e+00, -4.8409e+00, -5.0601e+00,  ..., -5.2438e+00,\n",
      "          -5.4649e+00, -5.2217e+00],\n",
      "         [-4.6537e+00, -4.3716e+00, -4.3586e+00,  ..., -4.5950e+00,\n",
      "          -4.8400e+00, -4.6982e+00],\n",
      "         ...,\n",
      "         [-5.3149e+00, -4.9878e+00, -5.0413e+00,  ..., -5.5441e+00,\n",
      "          -5.4893e+00, -5.4384e+00],\n",
      "         [-5.5157e+00, -5.1637e+00, -5.2299e+00,  ..., -5.7416e+00,\n",
      "          -5.6769e+00, -5.6300e+00],\n",
      "         [-5.6776e+00, -5.3676e+00, -5.4529e+00,  ..., -5.9477e+00,\n",
      "          -5.8615e+00, -5.8388e+00]],\n",
      "\n",
      "        [[-3.8065e+00, -3.8571e+00, -3.9273e+00,  ..., -3.8903e+00,\n",
      "          -4.2707e+00, -3.8439e+00],\n",
      "         [-3.3888e+00, -3.4535e+00, -3.6374e+00,  ..., -3.5521e+00,\n",
      "          -3.8691e+00, -3.4290e+00],\n",
      "         [-3.4896e+00, -3.5330e+00, -3.7049e+00,  ..., -3.6867e+00,\n",
      "          -3.9980e+00, -3.5001e+00],\n",
      "         ...,\n",
      "         [-3.1431e+00, -3.2538e+00, -3.3225e+00,  ..., -3.2686e+00,\n",
      "          -3.5697e+00, -3.1630e+00],\n",
      "         [-3.7425e+00, -3.8209e+00, -3.9049e+00,  ..., -3.9374e+00,\n",
      "          -4.2138e+00, -3.7781e+00],\n",
      "         [-4.0073e+00, -4.0821e+00, -4.1850e+00,  ..., -4.1805e+00,\n",
      "          -4.4470e+00, -4.0452e+00]],\n",
      "\n",
      "        [[-9.8334e-01, -1.0031e+00, -8.1090e-01,  ..., -1.0882e+00,\n",
      "          -1.1897e+00, -1.0481e+00],\n",
      "         [-7.1851e-01, -7.0052e-01, -4.7680e-01,  ..., -8.6070e-01,\n",
      "          -8.7576e-01, -8.0642e-01],\n",
      "         [-2.6477e-01, -2.2178e-01, -4.3290e-03,  ..., -3.6580e-01,\n",
      "          -4.1003e-01, -2.2826e-01],\n",
      "         ...,\n",
      "         [ 2.0033e-01, -1.0799e-01,  3.4898e-01,  ..., -9.1979e-02,\n",
      "           4.0038e-02,  2.9736e-01],\n",
      "         [-1.4952e-01, -2.2219e-01,  2.3611e-01,  ..., -3.3765e-01,\n",
      "          -2.5224e-01, -4.6762e-02],\n",
      "         [-1.8486e-01, -3.0361e-01,  1.7630e-01,  ..., -4.0266e-01,\n",
      "          -3.0896e-01, -4.1778e-02]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 7.8641e-01,  1.1804e+00,  1.2599e+00,  ...,  1.0766e+00,\n",
      "           7.4190e-01,  8.8393e-01],\n",
      "         [-4.6743e-02,  3.6194e-01,  4.0661e-01,  ...,  1.8799e-01,\n",
      "          -1.1726e-01,  1.6521e-02],\n",
      "         [-2.4920e+00, -1.9476e+00, -2.0253e+00,  ..., -2.3763e+00,\n",
      "          -2.6342e+00, -2.4956e+00],\n",
      "         ...,\n",
      "         [-1.3498e+00, -1.0489e+00, -8.6525e-01,  ..., -1.3620e+00,\n",
      "          -1.3943e+00, -1.3670e+00],\n",
      "         [-5.5395e-01, -2.6993e-01, -4.0418e-02,  ..., -4.9562e-01,\n",
      "          -5.5740e-01, -5.3988e-01],\n",
      "         [-9.8216e-01, -6.6789e-01, -5.2005e-01,  ..., -9.1829e-01,\n",
      "          -1.0483e+00, -1.0281e+00]],\n",
      "\n",
      "        [[-3.0251e+00, -2.9239e+00, -2.6919e+00,  ..., -3.1231e+00,\n",
      "          -3.2632e+00, -2.9836e+00],\n",
      "         [-2.9900e+00, -2.8415e+00, -2.7029e+00,  ..., -3.1374e+00,\n",
      "          -3.1904e+00, -3.1188e+00],\n",
      "         [-2.8931e+00, -2.7870e+00, -2.6072e+00,  ..., -2.8628e+00,\n",
      "          -3.1952e+00, -2.7656e+00],\n",
      "         ...,\n",
      "         [-4.1295e+00, -3.8698e+00, -3.7082e+00,  ..., -4.2545e+00,\n",
      "          -4.2300e+00, -3.9767e+00],\n",
      "         [-3.8276e+00, -3.5912e+00, -3.4217e+00,  ..., -3.9192e+00,\n",
      "          -3.8967e+00, -3.6349e+00],\n",
      "         [-3.3853e+00, -3.1018e+00, -2.9536e+00,  ..., -3.5535e+00,\n",
      "          -3.4425e+00, -3.2173e+00]],\n",
      "\n",
      "        [[-1.1676e+00, -1.1754e+00, -1.1347e+00,  ..., -1.4378e+00,\n",
      "          -1.7277e+00, -1.3635e+00],\n",
      "         [-1.6947e+00, -1.7027e+00, -1.6292e+00,  ..., -1.9734e+00,\n",
      "          -2.2353e+00, -1.9171e+00],\n",
      "         [-1.7562e+00, -1.6799e+00, -1.6340e+00,  ..., -1.9413e+00,\n",
      "          -2.3133e+00, -1.8838e+00],\n",
      "         ...,\n",
      "         [-2.7674e+00, -2.7660e+00, -2.5485e+00,  ..., -3.1546e+00,\n",
      "          -3.3755e+00, -2.9668e+00],\n",
      "         [-2.6968e+00, -2.7757e+00, -2.5707e+00,  ..., -3.0735e+00,\n",
      "          -3.3301e+00, -2.8357e+00],\n",
      "         [-2.5827e+00, -2.6950e+00, -2.4851e+00,  ..., -2.9494e+00,\n",
      "          -3.1993e+00, -2.6083e+00]]], device='cuda:0', grad_fn=<AddBackward0>), tensor([[[-2.5622e-01],\n",
      "         [-2.1285e-01],\n",
      "         [-2.4290e-01],\n",
      "         [-1.9430e-01],\n",
      "         [-1.8553e-01],\n",
      "         [-2.2455e-01],\n",
      "         [-2.7456e-01],\n",
      "         [-2.0629e-01],\n",
      "         [-3.0213e-01],\n",
      "         [-1.7387e-01],\n",
      "         [ 2.1698e-01],\n",
      "         [-1.6648e-01],\n",
      "         [-1.0129e-01],\n",
      "         [-1.3845e-01],\n",
      "         [-1.1849e-01],\n",
      "         [-1.6114e-01],\n",
      "         [-2.6141e-01],\n",
      "         [-7.1643e-02],\n",
      "         [-9.7595e-02],\n",
      "         [-2.0399e-01],\n",
      "         [-6.8415e-02],\n",
      "         [-1.4807e-01],\n",
      "         [-1.7520e-01],\n",
      "         [-1.8287e-01]],\n",
      "\n",
      "        [[ 1.1215e-01],\n",
      "         [-2.3841e-03],\n",
      "         [-8.9766e-03],\n",
      "         [-1.3473e-03],\n",
      "         [ 1.7375e-02],\n",
      "         [ 8.1369e-02],\n",
      "         [ 1.0529e-01],\n",
      "         [ 4.4913e-02],\n",
      "         [ 1.0440e-01],\n",
      "         [ 3.0081e-03],\n",
      "         [ 1.0406e-02],\n",
      "         [-5.7892e-02],\n",
      "         [-2.3011e-03],\n",
      "         [ 3.0224e-01],\n",
      "         [ 6.4569e-02],\n",
      "         [ 8.7649e-02],\n",
      "         [ 9.1342e-02],\n",
      "         [ 7.9906e-02],\n",
      "         [ 7.9782e-02],\n",
      "         [ 1.0282e-01],\n",
      "         [ 9.3750e-02],\n",
      "         [ 1.2814e-01],\n",
      "         [ 6.4945e-02],\n",
      "         [ 9.4823e-02]],\n",
      "\n",
      "        [[ 3.9657e-02],\n",
      "         [ 5.0881e-02],\n",
      "         [ 3.4007e-02],\n",
      "         [ 6.0661e-02],\n",
      "         [ 5.0675e-02],\n",
      "         [ 1.1499e-01],\n",
      "         [-1.6901e-02],\n",
      "         [ 6.0167e-02],\n",
      "         [ 2.9456e-01],\n",
      "         [ 1.1306e-01],\n",
      "         [ 1.4217e-01],\n",
      "         [ 1.4445e-01],\n",
      "         [ 1.8983e-01],\n",
      "         [ 1.5533e-01],\n",
      "         [ 1.7759e-01],\n",
      "         [ 1.5250e-01],\n",
      "         [ 1.6346e-01],\n",
      "         [ 1.3017e-01],\n",
      "         [ 1.3119e-01],\n",
      "         [ 1.7189e-01],\n",
      "         [ 7.9115e-02],\n",
      "         [ 1.2099e-01],\n",
      "         [ 1.1328e-01],\n",
      "         [ 1.6688e-01]],\n",
      "\n",
      "        [[ 9.0657e-03],\n",
      "         [ 2.0398e-01],\n",
      "         [ 2.2107e-01],\n",
      "         [ 1.4951e-01],\n",
      "         [ 2.2144e-01],\n",
      "         [ 1.5120e-01],\n",
      "         [-1.7439e-01],\n",
      "         [ 2.0006e-01],\n",
      "         [ 1.3381e-01],\n",
      "         [ 3.6504e-03],\n",
      "         [ 3.6634e-03],\n",
      "         [ 3.4047e-02],\n",
      "         [ 6.6527e-02],\n",
      "         [ 3.4744e-02],\n",
      "         [ 1.8621e-02],\n",
      "         [ 1.5997e-02],\n",
      "         [ 2.7246e-02],\n",
      "         [ 1.9940e-02],\n",
      "         [ 1.3692e-02],\n",
      "         [ 4.5050e-02],\n",
      "         [ 4.4034e-02],\n",
      "         [ 3.8980e-02],\n",
      "         [ 8.6066e-03],\n",
      "         [ 7.7732e-02]],\n",
      "\n",
      "        [[-1.8757e-01],\n",
      "         [-1.4691e-01],\n",
      "         [-1.3623e-01],\n",
      "         [-1.4766e-01],\n",
      "         [-1.5679e-01],\n",
      "         [-2.2329e-01],\n",
      "         [-1.4984e-01],\n",
      "         [-1.6632e-01],\n",
      "         [-2.1240e-01],\n",
      "         [-1.6585e-01],\n",
      "         [-1.4876e-01],\n",
      "         [ 2.6420e-01],\n",
      "         [-1.3918e-01],\n",
      "         [-1.3544e-01],\n",
      "         [-1.3591e-01],\n",
      "         [-1.4607e-01],\n",
      "         [-1.5284e-01],\n",
      "         [-1.4449e-01],\n",
      "         [-1.4989e-01],\n",
      "         [-1.5136e-01],\n",
      "         [-1.3676e-01],\n",
      "         [-1.4948e-01],\n",
      "         [-1.5386e-01],\n",
      "         [-1.4731e-01]],\n",
      "\n",
      "        [[-2.4567e-01],\n",
      "         [-2.2569e-01],\n",
      "         [-2.1044e-01],\n",
      "         [-2.2062e-01],\n",
      "         [-2.2976e-01],\n",
      "         [-2.5891e-01],\n",
      "         [-2.2765e-01],\n",
      "         [-2.3852e-01],\n",
      "         [-2.6821e-01],\n",
      "         [-1.8903e-01],\n",
      "         [-2.3690e-01],\n",
      "         [ 2.6122e-01],\n",
      "         [-1.7183e-01],\n",
      "         [-1.9226e-01],\n",
      "         [-1.8792e-01],\n",
      "         [-1.9689e-01],\n",
      "         [-1.9158e-01],\n",
      "         [-1.6258e-01],\n",
      "         [-1.8556e-01],\n",
      "         [-2.0286e-01],\n",
      "         [-1.8456e-01],\n",
      "         [-1.9263e-01],\n",
      "         [-2.0377e-01],\n",
      "         [-2.1699e-01]],\n",
      "\n",
      "        [[-1.8227e-01],\n",
      "         [-1.3133e-01],\n",
      "         [-1.1322e-01],\n",
      "         [-1.3714e-01],\n",
      "         [-1.3212e-01],\n",
      "         [-1.3934e-01],\n",
      "         [-2.1589e-01],\n",
      "         [-1.3095e-01],\n",
      "         [ 2.9109e-01],\n",
      "         [-1.5584e-01],\n",
      "         [-1.4376e-01],\n",
      "         [-1.5625e-01],\n",
      "         [-1.4244e-01],\n",
      "         [-1.6027e-01],\n",
      "         [-1.5380e-01],\n",
      "         [-1.5396e-01],\n",
      "         [-1.5150e-01],\n",
      "         [-1.3151e-01],\n",
      "         [-1.5240e-01],\n",
      "         [-1.7534e-01],\n",
      "         [-1.3723e-01],\n",
      "         [-1.5171e-01],\n",
      "         [-1.6134e-01],\n",
      "         [-1.3349e-01]],\n",
      "\n",
      "        [[-6.0132e-02],\n",
      "         [-1.6506e-01],\n",
      "         [-1.8554e-01],\n",
      "         [-1.8192e-01],\n",
      "         [-1.9198e-01],\n",
      "         [-1.5861e-01],\n",
      "         [-1.3572e-01],\n",
      "         [-1.7676e-01],\n",
      "         [-1.6543e-01],\n",
      "         [ 3.1545e-01],\n",
      "         [ 3.0751e-02],\n",
      "         [-1.0193e-02],\n",
      "         [ 6.2718e-02],\n",
      "         [ 2.5264e-02],\n",
      "         [ 7.9220e-02],\n",
      "         [ 3.3293e-02],\n",
      "         [-9.9578e-03],\n",
      "         [ 3.0611e-02],\n",
      "         [ 2.8554e-02],\n",
      "         [-1.9079e-02],\n",
      "         [ 1.5262e-03],\n",
      "         [ 4.0772e-02],\n",
      "         [ 4.4672e-02],\n",
      "         [ 4.0495e-02]],\n",
      "\n",
      "        [[ 3.7294e-02],\n",
      "         [ 4.6517e-02],\n",
      "         [ 2.0263e-02],\n",
      "         [ 4.9128e-02],\n",
      "         [ 3.5498e-02],\n",
      "         [ 8.7618e-02],\n",
      "         [-1.0696e-01],\n",
      "         [ 6.6191e-02],\n",
      "         [ 2.6458e-01],\n",
      "         [ 8.0600e-02],\n",
      "         [ 1.0028e-01],\n",
      "         [ 1.3232e-01],\n",
      "         [ 1.6651e-01],\n",
      "         [ 2.4011e-01],\n",
      "         [ 2.7414e-01],\n",
      "         [ 1.2597e-01],\n",
      "         [ 2.2211e-01],\n",
      "         [ 1.0419e-01],\n",
      "         [ 1.1341e-01],\n",
      "         [ 1.6944e-01],\n",
      "         [ 8.4629e-02],\n",
      "         [ 1.6444e-01],\n",
      "         [ 9.5272e-02],\n",
      "         [ 9.4139e-02]],\n",
      "\n",
      "        [[-2.8676e-04],\n",
      "         [ 1.3911e-03],\n",
      "         [ 1.8260e-02],\n",
      "         [ 7.6101e-03],\n",
      "         [ 2.8796e-02],\n",
      "         [-1.5109e-02],\n",
      "         [ 2.6178e-02],\n",
      "         [ 1.4761e-03],\n",
      "         [ 3.9161e-02],\n",
      "         [-1.0636e-01],\n",
      "         [-1.0581e-01],\n",
      "         [ 7.5015e-03],\n",
      "         [ 2.4722e-01],\n",
      "         [-9.3416e-02],\n",
      "         [-3.8146e-02],\n",
      "         [-8.1138e-02],\n",
      "         [-4.1016e-02],\n",
      "         [-1.3682e-02],\n",
      "         [ 2.1532e-02],\n",
      "         [-2.2482e-02],\n",
      "         [ 9.0566e-03],\n",
      "         [-1.1354e-01],\n",
      "         [-8.7592e-02],\n",
      "         [ 8.0724e-03]],\n",
      "\n",
      "        [[ 1.5619e-01],\n",
      "         [ 1.4240e-01],\n",
      "         [ 5.5793e-02],\n",
      "         [ 1.2516e-01],\n",
      "         [ 1.2780e-01],\n",
      "         [ 1.7074e-01],\n",
      "         [ 1.2355e-01],\n",
      "         [ 1.0156e-01],\n",
      "         [ 1.5529e-01],\n",
      "         [ 3.6283e-01],\n",
      "         [ 1.6179e-01],\n",
      "         [ 2.2154e-01],\n",
      "         [ 2.7337e-01],\n",
      "         [ 2.4066e-01],\n",
      "         [ 2.7004e-01],\n",
      "         [ 1.6767e-01],\n",
      "         [ 1.9803e-01],\n",
      "         [ 3.0233e-01],\n",
      "         [ 1.9409e-01],\n",
      "         [ 1.5990e-01],\n",
      "         [ 1.5723e-01],\n",
      "         [ 2.7199e-01],\n",
      "         [ 1.8649e-01],\n",
      "         [ 2.0280e-01]],\n",
      "\n",
      "        [[-7.8074e-02],\n",
      "         [-5.7218e-02],\n",
      "         [-2.5670e-02],\n",
      "         [-6.8699e-02],\n",
      "         [ 5.2639e-02],\n",
      "         [-9.7107e-02],\n",
      "         [-7.9909e-02],\n",
      "         [-1.7429e-01],\n",
      "         [-9.6944e-02],\n",
      "         [-6.3766e-02],\n",
      "         [ 2.5762e-01],\n",
      "         [-9.1113e-02],\n",
      "         [-5.2263e-02],\n",
      "         [-6.5880e-02],\n",
      "         [-8.1698e-02],\n",
      "         [-9.0836e-02],\n",
      "         [-1.1195e-01],\n",
      "         [-6.9694e-02],\n",
      "         [-1.0620e-01],\n",
      "         [-1.4202e-01],\n",
      "         [-1.2524e-01],\n",
      "         [-1.7274e-01],\n",
      "         [-1.6002e-01],\n",
      "         [-1.6329e-01]],\n",
      "\n",
      "        [[ 1.4111e-01],\n",
      "         [ 1.2021e-01],\n",
      "         [ 6.6518e-02],\n",
      "         [ 1.2021e-01],\n",
      "         [ 4.5047e-02],\n",
      "         [-3.0587e-02],\n",
      "         [-1.0746e-03],\n",
      "         [ 9.3350e-02],\n",
      "         [ 1.2414e-01],\n",
      "         [ 1.3117e-01],\n",
      "         [ 2.7222e-01],\n",
      "         [ 7.2117e-02],\n",
      "         [ 8.2904e-02],\n",
      "         [ 8.0531e-02],\n",
      "         [ 7.7689e-02],\n",
      "         [ 3.8549e-02],\n",
      "         [ 2.7719e-02],\n",
      "         [ 7.8876e-02],\n",
      "         [ 6.1680e-02],\n",
      "         [ 5.4731e-02],\n",
      "         [ 5.3968e-02],\n",
      "         [ 1.5452e-01],\n",
      "         [ 9.7629e-02],\n",
      "         [ 5.7103e-02]]], device='cuda:0', grad_fn=<AddBackward0>), ([], [], []))\n",
      ":List trace inputs must have elements (toTypeInferredIValue at /opt/conda/conda-bld/pytorch_1579027003190/work/torch/csrc/jit/pybind_utils.h:293)\n",
      "frame #0: c10::Error::Error(c10::SourceLocation, std::string const&) + 0x47 (0x7fc9ff191627 in /home/aloui/miniconda3/envs/vilbert-mt/lib/python3.6/site-packages/torch/lib/libc10.so)\n",
      "frame #1: <unknown function> + 0x6e4c9f (0x7fca304efc9f in /home/aloui/miniconda3/envs/vilbert-mt/lib/python3.6/site-packages/torch/lib/libtorch_python.so)\n",
      "frame #2: <unknown function> + 0x769f4b (0x7fca30574f4b in /home/aloui/miniconda3/envs/vilbert-mt/lib/python3.6/site-packages/torch/lib/libtorch_python.so)\n",
      "frame #3: torch::jit::tracer::trace(std::vector<c10::IValue, std::allocator<c10::IValue> >, std::function<std::vector<c10::IValue, std::allocator<c10::IValue> > (std::vector<c10::IValue, std::allocator<c10::IValue> >)> const&, std::function<std::string (at::Tensor const&)>, bool, torch::jit::script::Module*) + 0x4e6 (0x7fca04d96e26 in /home/aloui/miniconda3/envs/vilbert-mt/lib/python3.6/site-packages/torch/lib/libtorch.so)\n",
      "frame #4: <unknown function> + 0x7660e1 (0x7fca305710e1 in /home/aloui/miniconda3/envs/vilbert-mt/lib/python3.6/site-packages/torch/lib/libtorch_python.so)\n",
      "frame #5: <unknown function> + 0x77ffb1 (0x7fca3058afb1 in /home/aloui/miniconda3/envs/vilbert-mt/lib/python3.6/site-packages/torch/lib/libtorch_python.so)\n",
      "frame #6: <unknown function> + 0x28c076 (0x7fca30097076 in /home/aloui/miniconda3/envs/vilbert-mt/lib/python3.6/site-packages/torch/lib/libtorch_python.so)\n",
      "frame #7: _PyCFunction_FastCallDict + 0x154 (0x560568e28304 in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\n",
      "frame #8: <unknown function> + 0x199c5e (0x560568eafc5e in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\n",
      "frame #9: _PyEval_EvalFrameDefault + 0x30a (0x560568ed281a in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\n",
      "frame #10: <unknown function> + 0x19335e (0x560568ea935e in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\n",
      "frame #11: <unknown function> + 0x193f31 (0x560568ea9f31 in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\n",
      "frame #12: <unknown function> + 0x199be5 (0x560568eafbe5 in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\n",
      "frame #13: _PyEval_EvalFrameDefault + 0x30a (0x560568ed281a in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\n",
      "frame #14: <unknown function> + 0x192f26 (0x560568ea8f26 in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\n",
      "frame #15: <unknown function> + 0x193f31 (0x560568ea9f31 in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\n",
      "frame #16: <unknown function> + 0x199be5 (0x560568eafbe5 in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\n",
      "frame #17: _PyEval_EvalFrameDefault + 0x30a (0x560568ed281a in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\n",
      "frame #18: <unknown function> + 0x192f26 (0x560568ea8f26 in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\n",
      "frame #19: <unknown function> + 0x193f31 (0x560568ea9f31 in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\n",
      "frame #20: <unknown function> + 0x199be5 (0x560568eafbe5 in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\n",
      "frame #21: _PyEval_EvalFrameDefault + 0x30a (0x560568ed281a in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\n",
      "frame #22: <unknown function> + 0x192f26 (0x560568ea8f26 in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\n",
      "frame #23: <unknown function> + 0x193f31 (0x560568ea9f31 in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\n",
      "frame #24: <unknown function> + 0x199be5 (0x560568eafbe5 in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\n",
      "frame #25: _PyEval_EvalFrameDefault + 0x10c9 (0x560568ed35d9 in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\n",
      "frame #26: PyEval_EvalCodeEx + 0x329 (0x560568eaaa49 in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\n",
      "frame #27: PyEval_EvalCode + 0x1c (0x560568eab7ec in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\n",
      "frame #28: <unknown function> + 0x1ba227 (0x560568ed0227 in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\n",
      "frame #29: _PyCFunction_FastCallDict + 0x91 (0x560568e28241 in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\n",
      "frame #30: <unknown function> + 0x199b0c (0x560568eafb0c in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\n",
      "frame #31: _PyEval_EvalFrameDefault + 0x30a (0x560568ed281a in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\n",
      "frame #32: _PyGen_Send + 0x256 (0x560568eb2bc6 in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\n",
      "frame #33: _PyEval_EvalFrameDefault + 0x1445 (0x560568ed3955 in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\n",
      "frame #34: _PyGen_Send + 0x256 (0x560568eb2bc6 in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\n",
      "frame #35: _PyEval_EvalFrameDefault + 0x1445 (0x560568ed3955 in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\n",
      "frame #36: _PyGen_Send + 0x256 (0x560568eb2bc6 in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\n",
      "frame #37: _PyCFunction_FastCallDict + 0x115 (0x560568e282c5 in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\n",
      "frame #38: <unknown function> + 0x199b0c (0x560568eafb0c in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\n",
      "frame #39: _PyEval_EvalFrameDefault + 0x30a (0x560568ed281a in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\n",
      "frame #40: <unknown function> + 0x193cfb (0x560568ea9cfb in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\n",
      "frame #41: <unknown function> + 0x199be5 (0x560568eafbe5 in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\n",
      "frame #42: _PyEval_EvalFrameDefault + 0x30a (0x560568ed281a in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\n",
      "frame #43: <unknown function> + 0x193cfb (0x560568ea9cfb in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\n",
      "frame #44: <unknown function> + 0x199be5 (0x560568eafbe5 in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\n",
      "frame #45: _PyEval_EvalFrameDefault + 0x30a (0x560568ed281a in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\n",
      "frame #46: <unknown function> + 0x192f26 (0x560568ea8f26 in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\n",
      "frame #47: _PyFunction_FastCallDict + 0x3d8 (0x560568eaa628 in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\n",
      "frame #48: _PyObject_FastCallDict + 0x26f (0x560568e286cf in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\n",
      "frame #49: _PyObject_Call_Prepend + 0x63 (0x560568e2d143 in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\n",
      "frame #50: PyObject_Call + 0x3e (0x560568e2810e in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\n",
      "frame #51: _PyEval_EvalFrameDefault + 0x1aaf (0x560568ed3fbf in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\n",
      "frame #52: <unknown function> + 0x1931f6 (0x560568ea91f6 in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\n",
      "frame #53: <unknown function> + 0x193f31 (0x560568ea9f31 in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\n",
      "frame #54: <unknown function> + 0x199be5 (0x560568eafbe5 in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\n",
      "frame #55: _PyEval_EvalFrameDefault + 0x10c9 (0x560568ed35d9 in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\n",
      "frame #56: <unknown function> + 0x19c744 (0x560568eb2744 in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\n",
      "frame #57: _PyCFunction_FastCallDict + 0x91 (0x560568e28241 in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\n",
      "frame #58: <unknown function> + 0x199b0c (0x560568eafb0c in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\n",
      "frame #59: _PyEval_EvalFrameDefault + 0x30a (0x560568ed281a in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\n",
      "frame #60: <unknown function> + 0x1931f6 (0x560568ea91f6 in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\n",
      "frame #61: <unknown function> + 0x193f31 (0x560568ea9f31 in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\n",
      "frame #62: <unknown function> + 0x199be5 (0x560568eafbe5 in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\n",
      "frame #63: _PyEval_EvalFrameDefault + 0x30a (0x560568ed281a in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\n",
      "\n",
      "Error occurs, No graph saved\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Tracer cannot infer type of (tensor([[-27.4702, -20.0061, -19.1144,  ..., -20.4823, -16.3293, -18.1125],\n        [-25.9752, -12.4897, -14.5002,  ..., -19.2217, -13.6832, -16.6774],\n        [-25.3385, -20.9599, -20.1954,  ..., -16.5659, -13.5078, -19.9544],\n        ...,\n        [-27.0937, -18.9782, -20.0203,  ..., -19.8446, -16.5560, -18.3714],\n        [-29.0177, -21.6413, -19.3137,  ..., -20.1550, -14.5698, -19.3638],\n        [-17.8832, -17.1968, -18.6551,  ..., -23.1266, -12.8441, -15.4455]],\n       device='cuda:0', grad_fn=<AddmmBackward>), tensor([[-20.4525, -16.6485, -17.6500,  ..., -20.9428, -23.7464, -22.9949],\n        [-10.2533,  -9.6277, -12.2720,  ..., -10.0366, -11.6091, -11.4118],\n        [-14.6426,  -9.9717, -13.2709,  ..., -14.0173, -15.2406, -15.0422],\n        ...,\n        [-20.2942, -16.5288, -18.7356,  ..., -20.5999, -23.1127, -22.5909],\n        [-20.3451, -16.0831, -16.7768,  ..., -22.0253, -22.7605, -22.9622],\n        [-22.4740, -18.9633, -20.5899,  ..., -21.3940, -20.9538, -21.7462]],\n       device='cuda:0', grad_fn=<AddmmBackward>), tensor([[ 0.0599],\n        [ 0.1171],\n        [ 0.4941],\n        [ 0.9925],\n        [-3.3296],\n        [-1.9499],\n        [-2.8255],\n        [ 2.9162],\n        [ 2.2314],\n        [-1.3572],\n        [ 0.0750],\n        [ 0.3308],\n        [-6.4344]], device='cuda:0', grad_fn=<AddmmBackward>), tensor([[ 1.0168, -1.4560],\n        [ 0.4394, -0.7130],\n        [ 0.5635, -1.0259],\n        [ 0.9504, -0.9160],\n        [-1.5116,  0.9104],\n        [-0.7247,  0.0473],\n        [-1.6223,  1.0563],\n        [ 2.2997, -2.7921],\n        [ 1.8853, -2.7878],\n        [-1.1677,  0.1753],\n        [ 1.2776, -1.5721],\n        [ 0.9433, -1.1861],\n        [-2.0293,  2.0754]], device='cuda:0', grad_fn=<AddmmBackward>), tensor([[-3.5996,  0.2554, -0.9897],\n        [-0.9617, -0.6349, -2.2250],\n        [-1.7885, -0.4647, -2.0216],\n        [-2.9917, -2.8721, -1.7129],\n        [ 0.0503, -1.3153, -4.0771],\n        [-0.7456, -1.6966, -3.1057],\n        [ 0.0762, -1.1042, -3.7933],\n        [-2.6247,  0.1129, -1.8018],\n        [-4.2214, -4.0598,  2.1115],\n        [-0.4129, -0.9595, -4.1957],\n        [-3.7155, -0.6163,  0.0436],\n        [-2.6387,  0.6272, -2.1931],\n        [ 4.2082, -4.8643, -5.8948]], device='cuda:0', grad_fn=<AddmmBackward>), tensor([[[ 6.9932, -6.0197, -1.8061,  ..., -5.5277, -4.0174, -4.6866],\n         [ 6.0698, -4.2143, -4.4177,  ..., -4.5690, -1.5735, -3.7839],\n         [ 6.9017, -4.5599, -3.6356,  ..., -5.3572, -4.7600, -3.4384],\n         ...,\n         [ 6.3078, -5.4526, -2.7511,  ..., -4.4551, -3.3576, -2.5950],\n         [ 6.2105, -6.8478, -3.5844,  ..., -5.8020, -4.4306, -5.3767],\n         [ 7.4624, -3.5126, -2.7239,  ..., -6.1464, -3.2660, -3.0274]],\n\n        [[ 6.5387, -7.3786, -4.7384,  ..., -3.5706, -2.2800, -5.4530],\n         [ 6.2333, -6.0986, -4.3881,  ..., -2.9597, -2.9377, -4.9595],\n         [ 6.6095, -7.1808, -3.8217,  ..., -1.3874, -2.0545, -5.0085],\n         ...,\n         [ 6.5636, -6.7779, -3.8220,  ..., -3.0767, -2.9216, -3.5481],\n         [ 6.4958, -6.7223, -4.4355,  ..., -2.4478, -2.7105, -4.5684],\n         [ 6.3298, -5.1766, -4.1231,  ..., -2.4257, -0.7212, -4.0867]],\n\n        [[ 6.9256, -6.4389, -4.7385,  ..., -5.8783, -4.3740, -5.8362],\n         [ 5.9885, -6.3019, -6.3263,  ..., -4.2401, -2.5165, -5.5382],\n         [ 6.4484, -4.5275, -4.4486,  ..., -4.6965, -1.6494, -4.5384],\n         ...,\n         [ 6.7272, -5.1716, -5.2925,  ..., -6.3015, -4.4967, -5.2962],\n         [ 8.0347, -5.4510, -4.3193,  ..., -7.0748, -4.8594, -5.0436],\n         [ 7.3415, -5.5104, -3.2990,  ..., -4.7945, -4.3692, -5.3421]],\n\n        ...,\n\n        [[ 7.1706, -7.1711, -4.5917,  ..., -5.6644, -4.1178, -5.6369],\n         [ 6.6126, -6.1385, -3.9587,  ..., -5.3651, -3.3678, -3.1463],\n         [ 5.8712, -4.7684, -4.9580,  ..., -4.4504, -1.4958, -3.9552],\n         ...,\n         [ 6.6971, -6.1093, -5.6312,  ..., -6.3874, -5.5427, -4.6938],\n         [ 7.6637, -6.5825, -5.1593,  ..., -7.1620, -4.8586, -4.4052],\n         [ 7.7266, -6.3126, -3.3587,  ..., -4.3614, -3.7595, -4.5945]],\n\n        [[ 6.7432, -8.0850, -4.9500,  ..., -5.9540, -3.1517, -7.3474],\n         [ 6.5131, -7.0408, -4.8714,  ..., -6.0469, -3.4530, -4.4121],\n         [ 5.5832, -4.9256, -5.2396,  ..., -4.8160, -1.3953, -5.0350],\n         ...,\n         [ 6.5053, -6.7370, -5.6225,  ..., -6.2398, -3.8963, -6.7754],\n         [ 7.1917, -7.0501, -5.3987,  ..., -7.4047, -4.4696, -6.2787],\n         [ 6.8749, -6.2893, -3.4541,  ..., -4.7570, -3.7967, -5.8311]],\n\n        [[ 5.7978, -4.6452, -4.6846,  ..., -5.9551, -2.9711, -5.7627],\n         [ 5.7749, -5.8742, -5.4230,  ..., -4.5581, -3.0574, -4.6296],\n         [ 5.7048, -4.7278, -6.1124,  ..., -4.2225, -1.5135, -5.6646],\n         ...,\n         [ 5.9001, -4.9484, -6.3717,  ..., -4.6494, -3.7034, -5.5895],\n         [ 6.8969, -5.8425, -6.9073,  ..., -5.8385, -3.8361, -5.4630],\n         [ 7.0598, -5.2407, -4.7488,  ..., -4.0350, -2.8269, -4.4923]]],\n       device='cuda:0', grad_fn=<AddBackward0>), tensor([[[ 1.1992e-02],\n         [ 2.0590e-01],\n         [-5.1387e+00],\n         ...,\n         [ 4.4118e-02],\n         [-4.2576e+00],\n         [-1.6857e+00]],\n\n        [[ 5.6642e-01],\n         [ 4.1032e-03],\n         [-2.0958e+00],\n         ...,\n         [-3.1959e+00],\n         [-2.3279e+00],\n         [-4.8118e-02]],\n\n        [[-9.3151e-01],\n         [-2.1123e+00],\n         [-8.0695e-02],\n         ...,\n         [-2.9982e+00],\n         [-3.0473e+00],\n         [-3.7810e+00]],\n\n        ...,\n\n        [[-1.0506e+00],\n         [-4.2981e+00],\n         [ 8.7635e-02],\n         ...,\n         [-2.7343e+00],\n         [-3.8368e+00],\n         [-5.6515e+00]],\n\n        [[-1.9733e+00],\n         [-4.8770e+00],\n         [-6.0173e-01],\n         ...,\n         [-3.8316e+00],\n         [-2.3288e+00],\n         [-4.5286e+00]],\n\n        [[ 9.2018e-01],\n         [-3.9517e+00],\n         [-1.6769e+00],\n         ...,\n         [-1.1097e-01],\n         [-1.3863e+00],\n         [-1.7185e+00]]], device='cuda:0', grad_fn=<AddBackward0>), tensor([[[-4.6560e+00, -4.2019e+00, -4.4733e+00,  ..., -4.6358e+00,\n          -4.8291e+00, -4.6108e+00],\n         [-5.2868e+00, -4.8409e+00, -5.0601e+00,  ..., -5.2438e+00,\n          -5.4649e+00, -5.2217e+00],\n         [-4.6537e+00, -4.3716e+00, -4.3586e+00,  ..., -4.5950e+00,\n          -4.8400e+00, -4.6982e+00],\n         ...,\n         [-5.3149e+00, -4.9878e+00, -5.0413e+00,  ..., -5.5441e+00,\n          -5.4893e+00, -5.4384e+00],\n         [-5.5157e+00, -5.1637e+00, -5.2299e+00,  ..., -5.7416e+00,\n          -5.6769e+00, -5.6300e+00],\n         [-5.6776e+00, -5.3676e+00, -5.4529e+00,  ..., -5.9477e+00,\n          -5.8615e+00, -5.8388e+00]],\n\n        [[-3.8065e+00, -3.8571e+00, -3.9273e+00,  ..., -3.8903e+00,\n          -4.2707e+00, -3.8439e+00],\n         [-3.3888e+00, -3.4535e+00, -3.6374e+00,  ..., -3.5521e+00,\n          -3.8691e+00, -3.4290e+00],\n         [-3.4896e+00, -3.5330e+00, -3.7049e+00,  ..., -3.6867e+00,\n          -3.9980e+00, -3.5001e+00],\n         ...,\n         [-3.1431e+00, -3.2538e+00, -3.3225e+00,  ..., -3.2686e+00,\n          -3.5697e+00, -3.1630e+00],\n         [-3.7425e+00, -3.8209e+00, -3.9049e+00,  ..., -3.9374e+00,\n          -4.2138e+00, -3.7781e+00],\n         [-4.0073e+00, -4.0821e+00, -4.1850e+00,  ..., -4.1805e+00,\n          -4.4470e+00, -4.0452e+00]],\n\n        [[-9.8334e-01, -1.0031e+00, -8.1090e-01,  ..., -1.0882e+00,\n          -1.1897e+00, -1.0481e+00],\n         [-7.1851e-01, -7.0052e-01, -4.7680e-01,  ..., -8.6070e-01,\n          -8.7576e-01, -8.0642e-01],\n         [-2.6477e-01, -2.2178e-01, -4.3290e-03,  ..., -3.6580e-01,\n          -4.1003e-01, -2.2826e-01],\n         ...,\n         [ 2.0033e-01, -1.0799e-01,  3.4898e-01,  ..., -9.1979e-02,\n           4.0038e-02,  2.9736e-01],\n         [-1.4952e-01, -2.2219e-01,  2.3611e-01,  ..., -3.3765e-01,\n          -2.5224e-01, -4.6762e-02],\n         [-1.8486e-01, -3.0361e-01,  1.7630e-01,  ..., -4.0266e-01,\n          -3.0896e-01, -4.1778e-02]],\n\n        ...,\n\n        [[ 7.8641e-01,  1.1804e+00,  1.2599e+00,  ...,  1.0766e+00,\n           7.4190e-01,  8.8393e-01],\n         [-4.6743e-02,  3.6194e-01,  4.0661e-01,  ...,  1.8799e-01,\n          -1.1726e-01,  1.6521e-02],\n         [-2.4920e+00, -1.9476e+00, -2.0253e+00,  ..., -2.3763e+00,\n          -2.6342e+00, -2.4956e+00],\n         ...,\n         [-1.3498e+00, -1.0489e+00, -8.6525e-01,  ..., -1.3620e+00,\n          -1.3943e+00, -1.3670e+00],\n         [-5.5395e-01, -2.6993e-01, -4.0418e-02,  ..., -4.9562e-01,\n          -5.5740e-01, -5.3988e-01],\n         [-9.8216e-01, -6.6789e-01, -5.2005e-01,  ..., -9.1829e-01,\n          -1.0483e+00, -1.0281e+00]],\n\n        [[-3.0251e+00, -2.9239e+00, -2.6919e+00,  ..., -3.1231e+00,\n          -3.2632e+00, -2.9836e+00],\n         [-2.9900e+00, -2.8415e+00, -2.7029e+00,  ..., -3.1374e+00,\n          -3.1904e+00, -3.1188e+00],\n         [-2.8931e+00, -2.7870e+00, -2.6072e+00,  ..., -2.8628e+00,\n          -3.1952e+00, -2.7656e+00],\n         ...,\n         [-4.1295e+00, -3.8698e+00, -3.7082e+00,  ..., -4.2545e+00,\n          -4.2300e+00, -3.9767e+00],\n         [-3.8276e+00, -3.5912e+00, -3.4217e+00,  ..., -3.9192e+00,\n          -3.8967e+00, -3.6349e+00],\n         [-3.3853e+00, -3.1018e+00, -2.9536e+00,  ..., -3.5535e+00,\n          -3.4425e+00, -3.2173e+00]],\n\n        [[-1.1676e+00, -1.1754e+00, -1.1347e+00,  ..., -1.4378e+00,\n          -1.7277e+00, -1.3635e+00],\n         [-1.6947e+00, -1.7027e+00, -1.6292e+00,  ..., -1.9734e+00,\n          -2.2353e+00, -1.9171e+00],\n         [-1.7562e+00, -1.6799e+00, -1.6340e+00,  ..., -1.9413e+00,\n          -2.3133e+00, -1.8838e+00],\n         ...,\n         [-2.7674e+00, -2.7660e+00, -2.5485e+00,  ..., -3.1546e+00,\n          -3.3755e+00, -2.9668e+00],\n         [-2.6968e+00, -2.7757e+00, -2.5707e+00,  ..., -3.0735e+00,\n          -3.3301e+00, -2.8357e+00],\n         [-2.5827e+00, -2.6950e+00, -2.4851e+00,  ..., -2.9494e+00,\n          -3.1993e+00, -2.6083e+00]]], device='cuda:0', grad_fn=<AddBackward0>), tensor([[[-2.5622e-01],\n         [-2.1285e-01],\n         [-2.4290e-01],\n         [-1.9430e-01],\n         [-1.8553e-01],\n         [-2.2455e-01],\n         [-2.7456e-01],\n         [-2.0629e-01],\n         [-3.0213e-01],\n         [-1.7387e-01],\n         [ 2.1698e-01],\n         [-1.6648e-01],\n         [-1.0129e-01],\n         [-1.3845e-01],\n         [-1.1849e-01],\n         [-1.6114e-01],\n         [-2.6141e-01],\n         [-7.1643e-02],\n         [-9.7595e-02],\n         [-2.0399e-01],\n         [-6.8415e-02],\n         [-1.4807e-01],\n         [-1.7520e-01],\n         [-1.8287e-01]],\n\n        [[ 1.1215e-01],\n         [-2.3841e-03],\n         [-8.9766e-03],\n         [-1.3473e-03],\n         [ 1.7375e-02],\n         [ 8.1369e-02],\n         [ 1.0529e-01],\n         [ 4.4913e-02],\n         [ 1.0440e-01],\n         [ 3.0081e-03],\n         [ 1.0406e-02],\n         [-5.7892e-02],\n         [-2.3011e-03],\n         [ 3.0224e-01],\n         [ 6.4569e-02],\n         [ 8.7649e-02],\n         [ 9.1342e-02],\n         [ 7.9906e-02],\n         [ 7.9782e-02],\n         [ 1.0282e-01],\n         [ 9.3750e-02],\n         [ 1.2814e-01],\n         [ 6.4945e-02],\n         [ 9.4823e-02]],\n\n        [[ 3.9657e-02],\n         [ 5.0881e-02],\n         [ 3.4007e-02],\n         [ 6.0661e-02],\n         [ 5.0675e-02],\n         [ 1.1499e-01],\n         [-1.6901e-02],\n         [ 6.0167e-02],\n         [ 2.9456e-01],\n         [ 1.1306e-01],\n         [ 1.4217e-01],\n         [ 1.4445e-01],\n         [ 1.8983e-01],\n         [ 1.5533e-01],\n         [ 1.7759e-01],\n         [ 1.5250e-01],\n         [ 1.6346e-01],\n         [ 1.3017e-01],\n         [ 1.3119e-01],\n         [ 1.7189e-01],\n         [ 7.9115e-02],\n         [ 1.2099e-01],\n         [ 1.1328e-01],\n         [ 1.6688e-01]],\n\n        [[ 9.0657e-03],\n         [ 2.0398e-01],\n         [ 2.2107e-01],\n         [ 1.4951e-01],\n         [ 2.2144e-01],\n         [ 1.5120e-01],\n         [-1.7439e-01],\n         [ 2.0006e-01],\n         [ 1.3381e-01],\n         [ 3.6504e-03],\n         [ 3.6634e-03],\n         [ 3.4047e-02],\n         [ 6.6527e-02],\n         [ 3.4744e-02],\n         [ 1.8621e-02],\n         [ 1.5997e-02],\n         [ 2.7246e-02],\n         [ 1.9940e-02],\n         [ 1.3692e-02],\n         [ 4.5050e-02],\n         [ 4.4034e-02],\n         [ 3.8980e-02],\n         [ 8.6066e-03],\n         [ 7.7732e-02]],\n\n        [[-1.8757e-01],\n         [-1.4691e-01],\n         [-1.3623e-01],\n         [-1.4766e-01],\n         [-1.5679e-01],\n         [-2.2329e-01],\n         [-1.4984e-01],\n         [-1.6632e-01],\n         [-2.1240e-01],\n         [-1.6585e-01],\n         [-1.4876e-01],\n         [ 2.6420e-01],\n         [-1.3918e-01],\n         [-1.3544e-01],\n         [-1.3591e-01],\n         [-1.4607e-01],\n         [-1.5284e-01],\n         [-1.4449e-01],\n         [-1.4989e-01],\n         [-1.5136e-01],\n         [-1.3676e-01],\n         [-1.4948e-01],\n         [-1.5386e-01],\n         [-1.4731e-01]],\n\n        [[-2.4567e-01],\n         [-2.2569e-01],\n         [-2.1044e-01],\n         [-2.2062e-01],\n         [-2.2976e-01],\n         [-2.5891e-01],\n         [-2.2765e-01],\n         [-2.3852e-01],\n         [-2.6821e-01],\n         [-1.8903e-01],\n         [-2.3690e-01],\n         [ 2.6122e-01],\n         [-1.7183e-01],\n         [-1.9226e-01],\n         [-1.8792e-01],\n         [-1.9689e-01],\n         [-1.9158e-01],\n         [-1.6258e-01],\n         [-1.8556e-01],\n         [-2.0286e-01],\n         [-1.8456e-01],\n         [-1.9263e-01],\n         [-2.0377e-01],\n         [-2.1699e-01]],\n\n        [[-1.8227e-01],\n         [-1.3133e-01],\n         [-1.1322e-01],\n         [-1.3714e-01],\n         [-1.3212e-01],\n         [-1.3934e-01],\n         [-2.1589e-01],\n         [-1.3095e-01],\n         [ 2.9109e-01],\n         [-1.5584e-01],\n         [-1.4376e-01],\n         [-1.5625e-01],\n         [-1.4244e-01],\n         [-1.6027e-01],\n         [-1.5380e-01],\n         [-1.5396e-01],\n         [-1.5150e-01],\n         [-1.3151e-01],\n         [-1.5240e-01],\n         [-1.7534e-01],\n         [-1.3723e-01],\n         [-1.5171e-01],\n         [-1.6134e-01],\n         [-1.3349e-01]],\n\n        [[-6.0132e-02],\n         [-1.6506e-01],\n         [-1.8554e-01],\n         [-1.8192e-01],\n         [-1.9198e-01],\n         [-1.5861e-01],\n         [-1.3572e-01],\n         [-1.7676e-01],\n         [-1.6543e-01],\n         [ 3.1545e-01],\n         [ 3.0751e-02],\n         [-1.0193e-02],\n         [ 6.2718e-02],\n         [ 2.5264e-02],\n         [ 7.9220e-02],\n         [ 3.3293e-02],\n         [-9.9578e-03],\n         [ 3.0611e-02],\n         [ 2.8554e-02],\n         [-1.9079e-02],\n         [ 1.5262e-03],\n         [ 4.0772e-02],\n         [ 4.4672e-02],\n         [ 4.0495e-02]],\n\n        [[ 3.7294e-02],\n         [ 4.6517e-02],\n         [ 2.0263e-02],\n         [ 4.9128e-02],\n         [ 3.5498e-02],\n         [ 8.7618e-02],\n         [-1.0696e-01],\n         [ 6.6191e-02],\n         [ 2.6458e-01],\n         [ 8.0600e-02],\n         [ 1.0028e-01],\n         [ 1.3232e-01],\n         [ 1.6651e-01],\n         [ 2.4011e-01],\n         [ 2.7414e-01],\n         [ 1.2597e-01],\n         [ 2.2211e-01],\n         [ 1.0419e-01],\n         [ 1.1341e-01],\n         [ 1.6944e-01],\n         [ 8.4629e-02],\n         [ 1.6444e-01],\n         [ 9.5272e-02],\n         [ 9.4139e-02]],\n\n        [[-2.8676e-04],\n         [ 1.3911e-03],\n         [ 1.8260e-02],\n         [ 7.6101e-03],\n         [ 2.8796e-02],\n         [-1.5109e-02],\n         [ 2.6178e-02],\n         [ 1.4761e-03],\n         [ 3.9161e-02],\n         [-1.0636e-01],\n         [-1.0581e-01],\n         [ 7.5015e-03],\n         [ 2.4722e-01],\n         [-9.3416e-02],\n         [-3.8146e-02],\n         [-8.1138e-02],\n         [-4.1016e-02],\n         [-1.3682e-02],\n         [ 2.1532e-02],\n         [-2.2482e-02],\n         [ 9.0566e-03],\n         [-1.1354e-01],\n         [-8.7592e-02],\n         [ 8.0724e-03]],\n\n        [[ 1.5619e-01],\n         [ 1.4240e-01],\n         [ 5.5793e-02],\n         [ 1.2516e-01],\n         [ 1.2780e-01],\n         [ 1.7074e-01],\n         [ 1.2355e-01],\n         [ 1.0156e-01],\n         [ 1.5529e-01],\n         [ 3.6283e-01],\n         [ 1.6179e-01],\n         [ 2.2154e-01],\n         [ 2.7337e-01],\n         [ 2.4066e-01],\n         [ 2.7004e-01],\n         [ 1.6767e-01],\n         [ 1.9803e-01],\n         [ 3.0233e-01],\n         [ 1.9409e-01],\n         [ 1.5990e-01],\n         [ 1.5723e-01],\n         [ 2.7199e-01],\n         [ 1.8649e-01],\n         [ 2.0280e-01]],\n\n        [[-7.8074e-02],\n         [-5.7218e-02],\n         [-2.5670e-02],\n         [-6.8699e-02],\n         [ 5.2639e-02],\n         [-9.7107e-02],\n         [-7.9909e-02],\n         [-1.7429e-01],\n         [-9.6944e-02],\n         [-6.3766e-02],\n         [ 2.5762e-01],\n         [-9.1113e-02],\n         [-5.2263e-02],\n         [-6.5880e-02],\n         [-8.1698e-02],\n         [-9.0836e-02],\n         [-1.1195e-01],\n         [-6.9694e-02],\n         [-1.0620e-01],\n         [-1.4202e-01],\n         [-1.2524e-01],\n         [-1.7274e-01],\n         [-1.6002e-01],\n         [-1.6329e-01]],\n\n        [[ 1.4111e-01],\n         [ 1.2021e-01],\n         [ 6.6518e-02],\n         [ 1.2021e-01],\n         [ 4.5047e-02],\n         [-3.0587e-02],\n         [-1.0746e-03],\n         [ 9.3350e-02],\n         [ 1.2414e-01],\n         [ 1.3117e-01],\n         [ 2.7222e-01],\n         [ 7.2117e-02],\n         [ 8.2904e-02],\n         [ 8.0531e-02],\n         [ 7.7689e-02],\n         [ 3.8549e-02],\n         [ 2.7719e-02],\n         [ 7.8876e-02],\n         [ 6.1680e-02],\n         [ 5.4731e-02],\n         [ 5.3968e-02],\n         [ 1.5452e-01],\n         [ 9.7629e-02],\n         [ 5.7103e-02]]], device='cuda:0', grad_fn=<AddBackward0>), ([], [], []))\n:List trace inputs must have elements (toTypeInferredIValue at /opt/conda/conda-bld/pytorch_1579027003190/work/torch/csrc/jit/pybind_utils.h:293)\nframe #0: c10::Error::Error(c10::SourceLocation, std::string const&) + 0x47 (0x7fc9ff191627 in /home/aloui/miniconda3/envs/vilbert-mt/lib/python3.6/site-packages/torch/lib/libc10.so)\nframe #1: <unknown function> + 0x6e4c9f (0x7fca304efc9f in /home/aloui/miniconda3/envs/vilbert-mt/lib/python3.6/site-packages/torch/lib/libtorch_python.so)\nframe #2: <unknown function> + 0x769f4b (0x7fca30574f4b in /home/aloui/miniconda3/envs/vilbert-mt/lib/python3.6/site-packages/torch/lib/libtorch_python.so)\nframe #3: torch::jit::tracer::trace(std::vector<c10::IValue, std::allocator<c10::IValue> >, std::function<std::vector<c10::IValue, std::allocator<c10::IValue> > (std::vector<c10::IValue, std::allocator<c10::IValue> >)> const&, std::function<std::string (at::Tensor const&)>, bool, torch::jit::script::Module*) + 0x4e6 (0x7fca04d96e26 in /home/aloui/miniconda3/envs/vilbert-mt/lib/python3.6/site-packages/torch/lib/libtorch.so)\nframe #4: <unknown function> + 0x7660e1 (0x7fca305710e1 in /home/aloui/miniconda3/envs/vilbert-mt/lib/python3.6/site-packages/torch/lib/libtorch_python.so)\nframe #5: <unknown function> + 0x77ffb1 (0x7fca3058afb1 in /home/aloui/miniconda3/envs/vilbert-mt/lib/python3.6/site-packages/torch/lib/libtorch_python.so)\nframe #6: <unknown function> + 0x28c076 (0x7fca30097076 in /home/aloui/miniconda3/envs/vilbert-mt/lib/python3.6/site-packages/torch/lib/libtorch_python.so)\nframe #7: _PyCFunction_FastCallDict + 0x154 (0x560568e28304 in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\nframe #8: <unknown function> + 0x199c5e (0x560568eafc5e in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\nframe #9: _PyEval_EvalFrameDefault + 0x30a (0x560568ed281a in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\nframe #10: <unknown function> + 0x19335e (0x560568ea935e in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\nframe #11: <unknown function> + 0x193f31 (0x560568ea9f31 in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\nframe #12: <unknown function> + 0x199be5 (0x560568eafbe5 in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\nframe #13: _PyEval_EvalFrameDefault + 0x30a (0x560568ed281a in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\nframe #14: <unknown function> + 0x192f26 (0x560568ea8f26 in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\nframe #15: <unknown function> + 0x193f31 (0x560568ea9f31 in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\nframe #16: <unknown function> + 0x199be5 (0x560568eafbe5 in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\nframe #17: _PyEval_EvalFrameDefault + 0x30a (0x560568ed281a in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\nframe #18: <unknown function> + 0x192f26 (0x560568ea8f26 in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\nframe #19: <unknown function> + 0x193f31 (0x560568ea9f31 in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\nframe #20: <unknown function> + 0x199be5 (0x560568eafbe5 in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\nframe #21: _PyEval_EvalFrameDefault + 0x30a (0x560568ed281a in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\nframe #22: <unknown function> + 0x192f26 (0x560568ea8f26 in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\nframe #23: <unknown function> + 0x193f31 (0x560568ea9f31 in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\nframe #24: <unknown function> + 0x199be5 (0x560568eafbe5 in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\nframe #25: _PyEval_EvalFrameDefault + 0x10c9 (0x560568ed35d9 in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\nframe #26: PyEval_EvalCodeEx + 0x329 (0x560568eaaa49 in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\nframe #27: PyEval_EvalCode + 0x1c (0x560568eab7ec in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\nframe #28: <unknown function> + 0x1ba227 (0x560568ed0227 in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\nframe #29: _PyCFunction_FastCallDict + 0x91 (0x560568e28241 in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\nframe #30: <unknown function> + 0x199b0c (0x560568eafb0c in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\nframe #31: _PyEval_EvalFrameDefault + 0x30a (0x560568ed281a in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\nframe #32: _PyGen_Send + 0x256 (0x560568eb2bc6 in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\nframe #33: _PyEval_EvalFrameDefault + 0x1445 (0x560568ed3955 in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\nframe #34: _PyGen_Send + 0x256 (0x560568eb2bc6 in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\nframe #35: _PyEval_EvalFrameDefault + 0x1445 (0x560568ed3955 in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\nframe #36: _PyGen_Send + 0x256 (0x560568eb2bc6 in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\nframe #37: _PyCFunction_FastCallDict + 0x115 (0x560568e282c5 in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\nframe #38: <unknown function> + 0x199b0c (0x560568eafb0c in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\nframe #39: _PyEval_EvalFrameDefault + 0x30a (0x560568ed281a in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\nframe #40: <unknown function> + 0x193cfb (0x560568ea9cfb in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\nframe #41: <unknown function> + 0x199be5 (0x560568eafbe5 in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\nframe #42: _PyEval_EvalFrameDefault + 0x30a (0x560568ed281a in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\nframe #43: <unknown function> + 0x193cfb (0x560568ea9cfb in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\nframe #44: <unknown function> + 0x199be5 (0x560568eafbe5 in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\nframe #45: _PyEval_EvalFrameDefault + 0x30a (0x560568ed281a in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\nframe #46: <unknown function> + 0x192f26 (0x560568ea8f26 in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\nframe #47: _PyFunction_FastCallDict + 0x3d8 (0x560568eaa628 in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\nframe #48: _PyObject_FastCallDict + 0x26f (0x560568e286cf in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\nframe #49: _PyObject_Call_Prepend + 0x63 (0x560568e2d143 in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\nframe #50: PyObject_Call + 0x3e (0x560568e2810e in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\nframe #51: _PyEval_EvalFrameDefault + 0x1aaf (0x560568ed3fbf in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\nframe #52: <unknown function> + 0x1931f6 (0x560568ea91f6 in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\nframe #53: <unknown function> + 0x193f31 (0x560568ea9f31 in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\nframe #54: <unknown function> + 0x199be5 (0x560568eafbe5 in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\nframe #55: _PyEval_EvalFrameDefault + 0x10c9 (0x560568ed35d9 in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\nframe #56: <unknown function> + 0x19c744 (0x560568eb2744 in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\nframe #57: _PyCFunction_FastCallDict + 0x91 (0x560568e28241 in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\nframe #58: <unknown function> + 0x199b0c (0x560568eafb0c in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\nframe #59: _PyEval_EvalFrameDefault + 0x30a (0x560568ed281a in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\nframe #60: <unknown function> + 0x1931f6 (0x560568ea91f6 in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\nframe #61: <unknown function> + 0x193f31 (0x560568ea9f31 in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\nframe #62: <unknown function> + 0x199be5 (0x560568eafbe5 in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\nframe #63: _PyEval_EvalFrameDefault + 0x30a (0x560568ed281a in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-dbc0b7c8906d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mwriter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSummaryWriter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogdir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'results/runs'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0minput_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mquestion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspatials\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msegment_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mco_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask_tokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_to_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/vilbert-mt/lib/python3.6/site-packages/tensorboardX/writer.py\u001b[0m in \u001b[0;36madd_graph\u001b[0;34m(self, model, input_to_model, verbose)\u001b[0m\n\u001b[1;32m    792\u001b[0m         \"\"\"\n\u001b[1;32m    793\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensorboard\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pytorch_graph\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 794\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_file_writer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_to_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    795\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    796\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0madd_graph_deprecated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_to_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprofile_with_cuda\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/vilbert-mt/lib/python3.6/site-packages/torch/utils/tensorboard/_pytorch_graph.py\u001b[0m in \u001b[0;36mgraph\u001b[0;34m(model, args, verbose)\u001b[0m\n\u001b[1;32m    289\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Error occurs, No graph saved'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 291\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    292\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/vilbert-mt/lib/python3.6/site-packages/torch/utils/tensorboard/_pytorch_graph.py\u001b[0m in \u001b[0;36mgraph\u001b[0;34m(model, args, verbose)\u001b[0m\n\u001b[1;32m    283\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0monnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# TODO: move outside of torch.onnx?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 285\u001b[0;31m             \u001b[0mtrace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    286\u001b[0m             \u001b[0mgraph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_pass_inline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/vilbert-mt/lib/python3.6/site-packages/torch/jit/__init__.py\u001b[0m in \u001b[0;36mtrace\u001b[0;34m(func, example_inputs, optimize, check_trace, check_inputs, check_tolerance, _force_outplace, _module_class, _compilation_unit)\u001b[0m\n\u001b[1;32m    880\u001b[0m         return trace_module(func, {'forward': example_inputs}, None,\n\u001b[1;32m    881\u001b[0m                             \u001b[0mcheck_trace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrap_check_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheck_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 882\u001b[0;31m                             check_tolerance, _force_outplace, _module_class)\n\u001b[0m\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m     if (hasattr(func, '__self__') and isinstance(func.__self__, torch.nn.Module) and\n",
      "\u001b[0;32m~/miniconda3/envs/vilbert-mt/lib/python3.6/site-packages/torch/jit/__init__.py\u001b[0m in \u001b[0;36mtrace_module\u001b[0;34m(mod, inputs, optimize, check_trace, check_inputs, check_tolerance, _force_outplace, _module_class, _compilation_unit)\u001b[0m\n\u001b[1;32m   1032\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmod\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mmethod_name\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"forward\"\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1033\u001b[0m             \u001b[0mexample_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexample_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1034\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_c\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_method_from_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexample_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar_lookup_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_force_outplace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1035\u001b[0m             \u001b[0mcheck_trace_method\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_c\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Tracer cannot infer type of (tensor([[-27.4702, -20.0061, -19.1144,  ..., -20.4823, -16.3293, -18.1125],\n        [-25.9752, -12.4897, -14.5002,  ..., -19.2217, -13.6832, -16.6774],\n        [-25.3385, -20.9599, -20.1954,  ..., -16.5659, -13.5078, -19.9544],\n        ...,\n        [-27.0937, -18.9782, -20.0203,  ..., -19.8446, -16.5560, -18.3714],\n        [-29.0177, -21.6413, -19.3137,  ..., -20.1550, -14.5698, -19.3638],\n        [-17.8832, -17.1968, -18.6551,  ..., -23.1266, -12.8441, -15.4455]],\n       device='cuda:0', grad_fn=<AddmmBackward>), tensor([[-20.4525, -16.6485, -17.6500,  ..., -20.9428, -23.7464, -22.9949],\n        [-10.2533,  -9.6277, -12.2720,  ..., -10.0366, -11.6091, -11.4118],\n        [-14.6426,  -9.9717, -13.2709,  ..., -14.0173, -15.2406, -15.0422],\n        ...,\n        [-20.2942, -16.5288, -18.7356,  ..., -20.5999, -23.1127, -22.5909],\n        [-20.3451, -16.0831, -16.7768,  ..., -22.0253, -22.7605, -22.9622],\n        [-22.4740, -18.9633, -20.5899,  ..., -21.3940, -20.9538, -21.7462]],\n       device='cuda:0', grad_fn=<AddmmBackward>), tensor([[ 0.0599],\n        [ 0.1171],\n        [ 0.4941],\n        [ 0.9925],\n        [-3.3296],\n        [-1.9499],\n        [-2.8255],\n        [ 2.9162],\n        [ 2.2314],\n        [-1.3572],\n        [ 0.0750],\n        [ 0.3308],\n        [-6.4344]], device='cuda:0', grad_fn=<AddmmBackward>), tensor([[ 1.0168, -1.4560],\n        [ 0.4394, -0.7130],\n        [ 0.5635, -1.0259],\n        [ 0.9504, -0.9160],\n        [-1.5116,  0.9104],\n        [-0.7247,  0.0473],\n        [-1.6223,  1.0563],\n        [ 2.2997, -2.7921],\n        [ 1.8853, -2.7878],\n        [-1.1677,  0.1753],\n        [ 1.2776, -1.5721],\n        [ 0.9433, -1.1861],\n        [-2.0293,  2.0754]], device='cuda:0', grad_fn=<AddmmBackward>), tensor([[-3.5996,  0.2554, -0.9897],\n        [-0.9617, -0.6349, -2.2250],\n        [-1.7885, -0.4647, -2.0216],\n        [-2.9917, -2.8721, -1.7129],\n        [ 0.0503, -1.3153, -4.0771],\n        [-0.7456, -1.6966, -3.1057],\n        [ 0.0762, -1.1042, -3.7933],\n        [-2.6247,  0.1129, -1.8018],\n        [-4.2214, -4.0598,  2.1115],\n        [-0.4129, -0.9595, -4.1957],\n        [-3.7155, -0.6163,  0.0436],\n        [-2.6387,  0.6272, -2.1931],\n        [ 4.2082, -4.8643, -5.8948]], device='cuda:0', grad_fn=<AddmmBackward>), tensor([[[ 6.9932, -6.0197, -1.8061,  ..., -5.5277, -4.0174, -4.6866],\n         [ 6.0698, -4.2143, -4.4177,  ..., -4.5690, -1.5735, -3.7839],\n         [ 6.9017, -4.5599, -3.6356,  ..., -5.3572, -4.7600, -3.4384],\n         ...,\n         [ 6.3078, -5.4526, -2.7511,  ..., -4.4551, -3.3576, -2.5950],\n         [ 6.2105, -6.8478, -3.5844,  ..., -5.8020, -4.4306, -5.3767],\n         [ 7.4624, -3.5126, -2.7239,  ..., -6.1464, -3.2660, -3.0274]],\n\n        [[ 6.5387, -7.3786, -4.7384,  ..., -3.5706, -2.2800, -5.4530],\n         [ 6.2333, -6.0986, -4.3881,  ..., -2.9597, -2.9377, -4.9595],\n         [ 6.6095, -7.1808, -3.8217,  ..., -1.3874, -2.0545, -5.0085],\n         ...,\n         [ 6.5636, -6.7779, -3.8220,  ..., -3.0767, -2.9216, -3.5481],\n         [ 6.4958, -6.7223, -4.4355,  ..., -2.4478, -2.7105, -4.5684],\n         [ 6.3298, -5.1766, -4.1231,  ..., -2.4257, -0.7212, -4.0867]],\n\n        [[ 6.9256, -6.4389, -4.7385,  ..., -5.8783, -4.3740, -5.8362],\n         [ 5.9885, -6.3019, -6.3263,  ..., -4.2401, -2.5165, -5.5382],\n         [ 6.4484, -4.5275, -4.4486,  ..., -4.6965, -1.6494, -4.5384],\n         ...,\n         [ 6.7272, -5.1716, -5.2925,  ..., -6.3015, -4.4967, -5.2962],\n         [ 8.0347, -5.4510, -4.3193,  ..., -7.0748, -4.8594, -5.0436],\n         [ 7.3415, -5.5104, -3.2990,  ..., -4.7945, -4.3692, -5.3421]],\n\n        ...,\n\n        [[ 7.1706, -7.1711, -4.5917,  ..., -5.6644, -4.1178, -5.6369],\n         [ 6.6126, -6.1385, -3.9587,  ..., -5.3651, -3.3678, -3.1463],\n         [ 5.8712, -4.7684, -4.9580,  ..., -4.4504, -1.4958, -3.9552],\n         ...,\n         [ 6.6971, -6.1093, -5.6312,  ..., -6.3874, -5.5427, -4.6938],\n         [ 7.6637, -6.5825, -5.1593,  ..., -7.1620, -4.8586, -4.4052],\n         [ 7.7266, -6.3126, -3.3587,  ..., -4.3614, -3.7595, -4.5945]],\n\n        [[ 6.7432, -8.0850, -4.9500,  ..., -5.9540, -3.1517, -7.3474],\n         [ 6.5131, -7.0408, -4.8714,  ..., -6.0469, -3.4530, -4.4121],\n         [ 5.5832, -4.9256, -5.2396,  ..., -4.8160, -1.3953, -5.0350],\n         ...,\n         [ 6.5053, -6.7370, -5.6225,  ..., -6.2398, -3.8963, -6.7754],\n         [ 7.1917, -7.0501, -5.3987,  ..., -7.4047, -4.4696, -6.2787],\n         [ 6.8749, -6.2893, -3.4541,  ..., -4.7570, -3.7967, -5.8311]],\n\n        [[ 5.7978, -4.6452, -4.6846,  ..., -5.9551, -2.9711, -5.7627],\n         [ 5.7749, -5.8742, -5.4230,  ..., -4.5581, -3.0574, -4.6296],\n         [ 5.7048, -4.7278, -6.1124,  ..., -4.2225, -1.5135, -5.6646],\n         ...,\n         [ 5.9001, -4.9484, -6.3717,  ..., -4.6494, -3.7034, -5.5895],\n         [ 6.8969, -5.8425, -6.9073,  ..., -5.8385, -3.8361, -5.4630],\n         [ 7.0598, -5.2407, -4.7488,  ..., -4.0350, -2.8269, -4.4923]]],\n       device='cuda:0', grad_fn=<AddBackward0>), tensor([[[ 1.1992e-02],\n         [ 2.0590e-01],\n         [-5.1387e+00],\n         ...,\n         [ 4.4118e-02],\n         [-4.2576e+00],\n         [-1.6857e+00]],\n\n        [[ 5.6642e-01],\n         [ 4.1032e-03],\n         [-2.0958e+00],\n         ...,\n         [-3.1959e+00],\n         [-2.3279e+00],\n         [-4.8118e-02]],\n\n        [[-9.3151e-01],\n         [-2.1123e+00],\n         [-8.0695e-02],\n         ...,\n         [-2.9982e+00],\n         [-3.0473e+00],\n         [-3.7810e+00]],\n\n        ...,\n\n        [[-1.0506e+00],\n         [-4.2981e+00],\n         [ 8.7635e-02],\n         ...,\n         [-2.7343e+00],\n         [-3.8368e+00],\n         [-5.6515e+00]],\n\n        [[-1.9733e+00],\n         [-4.8770e+00],\n         [-6.0173e-01],\n         ...,\n         [-3.8316e+00],\n         [-2.3288e+00],\n         [-4.5286e+00]],\n\n        [[ 9.2018e-01],\n         [-3.9517e+00],\n         [-1.6769e+00],\n         ...,\n         [-1.1097e-01],\n         [-1.3863e+00],\n         [-1.7185e+00]]], device='cuda:0', grad_fn=<AddBackward0>), tensor([[[-4.6560e+00, -4.2019e+00, -4.4733e+00,  ..., -4.6358e+00,\n          -4.8291e+00, -4.6108e+00],\n         [-5.2868e+00, -4.8409e+00, -5.0601e+00,  ..., -5.2438e+00,\n          -5.4649e+00, -5.2217e+00],\n         [-4.6537e+00, -4.3716e+00, -4.3586e+00,  ..., -4.5950e+00,\n          -4.8400e+00, -4.6982e+00],\n         ...,\n         [-5.3149e+00, -4.9878e+00, -5.0413e+00,  ..., -5.5441e+00,\n          -5.4893e+00, -5.4384e+00],\n         [-5.5157e+00, -5.1637e+00, -5.2299e+00,  ..., -5.7416e+00,\n          -5.6769e+00, -5.6300e+00],\n         [-5.6776e+00, -5.3676e+00, -5.4529e+00,  ..., -5.9477e+00,\n          -5.8615e+00, -5.8388e+00]],\n\n        [[-3.8065e+00, -3.8571e+00, -3.9273e+00,  ..., -3.8903e+00,\n          -4.2707e+00, -3.8439e+00],\n         [-3.3888e+00, -3.4535e+00, -3.6374e+00,  ..., -3.5521e+00,\n          -3.8691e+00, -3.4290e+00],\n         [-3.4896e+00, -3.5330e+00, -3.7049e+00,  ..., -3.6867e+00,\n          -3.9980e+00, -3.5001e+00],\n         ...,\n         [-3.1431e+00, -3.2538e+00, -3.3225e+00,  ..., -3.2686e+00,\n          -3.5697e+00, -3.1630e+00],\n         [-3.7425e+00, -3.8209e+00, -3.9049e+00,  ..., -3.9374e+00,\n          -4.2138e+00, -3.7781e+00],\n         [-4.0073e+00, -4.0821e+00, -4.1850e+00,  ..., -4.1805e+00,\n          -4.4470e+00, -4.0452e+00]],\n\n        [[-9.8334e-01, -1.0031e+00, -8.1090e-01,  ..., -1.0882e+00,\n          -1.1897e+00, -1.0481e+00],\n         [-7.1851e-01, -7.0052e-01, -4.7680e-01,  ..., -8.6070e-01,\n          -8.7576e-01, -8.0642e-01],\n         [-2.6477e-01, -2.2178e-01, -4.3290e-03,  ..., -3.6580e-01,\n          -4.1003e-01, -2.2826e-01],\n         ...,\n         [ 2.0033e-01, -1.0799e-01,  3.4898e-01,  ..., -9.1979e-02,\n           4.0038e-02,  2.9736e-01],\n         [-1.4952e-01, -2.2219e-01,  2.3611e-01,  ..., -3.3765e-01,\n          -2.5224e-01, -4.6762e-02],\n         [-1.8486e-01, -3.0361e-01,  1.7630e-01,  ..., -4.0266e-01,\n          -3.0896e-01, -4.1778e-02]],\n\n        ...,\n\n        [[ 7.8641e-01,  1.1804e+00,  1.2599e+00,  ...,  1.0766e+00,\n           7.4190e-01,  8.8393e-01],\n         [-4.6743e-02,  3.6194e-01,  4.0661e-01,  ...,  1.8799e-01,\n          -1.1726e-01,  1.6521e-02],\n         [-2.4920e+00, -1.9476e+00, -2.0253e+00,  ..., -2.3763e+00,\n          -2.6342e+00, -2.4956e+00],\n         ...,\n         [-1.3498e+00, -1.0489e+00, -8.6525e-01,  ..., -1.3620e+00,\n          -1.3943e+00, -1.3670e+00],\n         [-5.5395e-01, -2.6993e-01, -4.0418e-02,  ..., -4.9562e-01,\n          -5.5740e-01, -5.3988e-01],\n         [-9.8216e-01, -6.6789e-01, -5.2005e-01,  ..., -9.1829e-01,\n          -1.0483e+00, -1.0281e+00]],\n\n        [[-3.0251e+00, -2.9239e+00, -2.6919e+00,  ..., -3.1231e+00,\n          -3.2632e+00, -2.9836e+00],\n         [-2.9900e+00, -2.8415e+00, -2.7029e+00,  ..., -3.1374e+00,\n          -3.1904e+00, -3.1188e+00],\n         [-2.8931e+00, -2.7870e+00, -2.6072e+00,  ..., -2.8628e+00,\n          -3.1952e+00, -2.7656e+00],\n         ...,\n         [-4.1295e+00, -3.8698e+00, -3.7082e+00,  ..., -4.2545e+00,\n          -4.2300e+00, -3.9767e+00],\n         [-3.8276e+00, -3.5912e+00, -3.4217e+00,  ..., -3.9192e+00,\n          -3.8967e+00, -3.6349e+00],\n         [-3.3853e+00, -3.1018e+00, -2.9536e+00,  ..., -3.5535e+00,\n          -3.4425e+00, -3.2173e+00]],\n\n        [[-1.1676e+00, -1.1754e+00, -1.1347e+00,  ..., -1.4378e+00,\n          -1.7277e+00, -1.3635e+00],\n         [-1.6947e+00, -1.7027e+00, -1.6292e+00,  ..., -1.9734e+00,\n          -2.2353e+00, -1.9171e+00],\n         [-1.7562e+00, -1.6799e+00, -1.6340e+00,  ..., -1.9413e+00,\n          -2.3133e+00, -1.8838e+00],\n         ...,\n         [-2.7674e+00, -2.7660e+00, -2.5485e+00,  ..., -3.1546e+00,\n          -3.3755e+00, -2.9668e+00],\n         [-2.6968e+00, -2.7757e+00, -2.5707e+00,  ..., -3.0735e+00,\n          -3.3301e+00, -2.8357e+00],\n         [-2.5827e+00, -2.6950e+00, -2.4851e+00,  ..., -2.9494e+00,\n          -3.1993e+00, -2.6083e+00]]], device='cuda:0', grad_fn=<AddBackward0>), tensor([[[-2.5622e-01],\n         [-2.1285e-01],\n         [-2.4290e-01],\n         [-1.9430e-01],\n         [-1.8553e-01],\n         [-2.2455e-01],\n         [-2.7456e-01],\n         [-2.0629e-01],\n         [-3.0213e-01],\n         [-1.7387e-01],\n         [ 2.1698e-01],\n         [-1.6648e-01],\n         [-1.0129e-01],\n         [-1.3845e-01],\n         [-1.1849e-01],\n         [-1.6114e-01],\n         [-2.6141e-01],\n         [-7.1643e-02],\n         [-9.7595e-02],\n         [-2.0399e-01],\n         [-6.8415e-02],\n         [-1.4807e-01],\n         [-1.7520e-01],\n         [-1.8287e-01]],\n\n        [[ 1.1215e-01],\n         [-2.3841e-03],\n         [-8.9766e-03],\n         [-1.3473e-03],\n         [ 1.7375e-02],\n         [ 8.1369e-02],\n         [ 1.0529e-01],\n         [ 4.4913e-02],\n         [ 1.0440e-01],\n         [ 3.0081e-03],\n         [ 1.0406e-02],\n         [-5.7892e-02],\n         [-2.3011e-03],\n         [ 3.0224e-01],\n         [ 6.4569e-02],\n         [ 8.7649e-02],\n         [ 9.1342e-02],\n         [ 7.9906e-02],\n         [ 7.9782e-02],\n         [ 1.0282e-01],\n         [ 9.3750e-02],\n         [ 1.2814e-01],\n         [ 6.4945e-02],\n         [ 9.4823e-02]],\n\n        [[ 3.9657e-02],\n         [ 5.0881e-02],\n         [ 3.4007e-02],\n         [ 6.0661e-02],\n         [ 5.0675e-02],\n         [ 1.1499e-01],\n         [-1.6901e-02],\n         [ 6.0167e-02],\n         [ 2.9456e-01],\n         [ 1.1306e-01],\n         [ 1.4217e-01],\n         [ 1.4445e-01],\n         [ 1.8983e-01],\n         [ 1.5533e-01],\n         [ 1.7759e-01],\n         [ 1.5250e-01],\n         [ 1.6346e-01],\n         [ 1.3017e-01],\n         [ 1.3119e-01],\n         [ 1.7189e-01],\n         [ 7.9115e-02],\n         [ 1.2099e-01],\n         [ 1.1328e-01],\n         [ 1.6688e-01]],\n\n        [[ 9.0657e-03],\n         [ 2.0398e-01],\n         [ 2.2107e-01],\n         [ 1.4951e-01],\n         [ 2.2144e-01],\n         [ 1.5120e-01],\n         [-1.7439e-01],\n         [ 2.0006e-01],\n         [ 1.3381e-01],\n         [ 3.6504e-03],\n         [ 3.6634e-03],\n         [ 3.4047e-02],\n         [ 6.6527e-02],\n         [ 3.4744e-02],\n         [ 1.8621e-02],\n         [ 1.5997e-02],\n         [ 2.7246e-02],\n         [ 1.9940e-02],\n         [ 1.3692e-02],\n         [ 4.5050e-02],\n         [ 4.4034e-02],\n         [ 3.8980e-02],\n         [ 8.6066e-03],\n         [ 7.7732e-02]],\n\n        [[-1.8757e-01],\n         [-1.4691e-01],\n         [-1.3623e-01],\n         [-1.4766e-01],\n         [-1.5679e-01],\n         [-2.2329e-01],\n         [-1.4984e-01],\n         [-1.6632e-01],\n         [-2.1240e-01],\n         [-1.6585e-01],\n         [-1.4876e-01],\n         [ 2.6420e-01],\n         [-1.3918e-01],\n         [-1.3544e-01],\n         [-1.3591e-01],\n         [-1.4607e-01],\n         [-1.5284e-01],\n         [-1.4449e-01],\n         [-1.4989e-01],\n         [-1.5136e-01],\n         [-1.3676e-01],\n         [-1.4948e-01],\n         [-1.5386e-01],\n         [-1.4731e-01]],\n\n        [[-2.4567e-01],\n         [-2.2569e-01],\n         [-2.1044e-01],\n         [-2.2062e-01],\n         [-2.2976e-01],\n         [-2.5891e-01],\n         [-2.2765e-01],\n         [-2.3852e-01],\n         [-2.6821e-01],\n         [-1.8903e-01],\n         [-2.3690e-01],\n         [ 2.6122e-01],\n         [-1.7183e-01],\n         [-1.9226e-01],\n         [-1.8792e-01],\n         [-1.9689e-01],\n         [-1.9158e-01],\n         [-1.6258e-01],\n         [-1.8556e-01],\n         [-2.0286e-01],\n         [-1.8456e-01],\n         [-1.9263e-01],\n         [-2.0377e-01],\n         [-2.1699e-01]],\n\n        [[-1.8227e-01],\n         [-1.3133e-01],\n         [-1.1322e-01],\n         [-1.3714e-01],\n         [-1.3212e-01],\n         [-1.3934e-01],\n         [-2.1589e-01],\n         [-1.3095e-01],\n         [ 2.9109e-01],\n         [-1.5584e-01],\n         [-1.4376e-01],\n         [-1.5625e-01],\n         [-1.4244e-01],\n         [-1.6027e-01],\n         [-1.5380e-01],\n         [-1.5396e-01],\n         [-1.5150e-01],\n         [-1.3151e-01],\n         [-1.5240e-01],\n         [-1.7534e-01],\n         [-1.3723e-01],\n         [-1.5171e-01],\n         [-1.6134e-01],\n         [-1.3349e-01]],\n\n        [[-6.0132e-02],\n         [-1.6506e-01],\n         [-1.8554e-01],\n         [-1.8192e-01],\n         [-1.9198e-01],\n         [-1.5861e-01],\n         [-1.3572e-01],\n         [-1.7676e-01],\n         [-1.6543e-01],\n         [ 3.1545e-01],\n         [ 3.0751e-02],\n         [-1.0193e-02],\n         [ 6.2718e-02],\n         [ 2.5264e-02],\n         [ 7.9220e-02],\n         [ 3.3293e-02],\n         [-9.9578e-03],\n         [ 3.0611e-02],\n         [ 2.8554e-02],\n         [-1.9079e-02],\n         [ 1.5262e-03],\n         [ 4.0772e-02],\n         [ 4.4672e-02],\n         [ 4.0495e-02]],\n\n        [[ 3.7294e-02],\n         [ 4.6517e-02],\n         [ 2.0263e-02],\n         [ 4.9128e-02],\n         [ 3.5498e-02],\n         [ 8.7618e-02],\n         [-1.0696e-01],\n         [ 6.6191e-02],\n         [ 2.6458e-01],\n         [ 8.0600e-02],\n         [ 1.0028e-01],\n         [ 1.3232e-01],\n         [ 1.6651e-01],\n         [ 2.4011e-01],\n         [ 2.7414e-01],\n         [ 1.2597e-01],\n         [ 2.2211e-01],\n         [ 1.0419e-01],\n         [ 1.1341e-01],\n         [ 1.6944e-01],\n         [ 8.4629e-02],\n         [ 1.6444e-01],\n         [ 9.5272e-02],\n         [ 9.4139e-02]],\n\n        [[-2.8676e-04],\n         [ 1.3911e-03],\n         [ 1.8260e-02],\n         [ 7.6101e-03],\n         [ 2.8796e-02],\n         [-1.5109e-02],\n         [ 2.6178e-02],\n         [ 1.4761e-03],\n         [ 3.9161e-02],\n         [-1.0636e-01],\n         [-1.0581e-01],\n         [ 7.5015e-03],\n         [ 2.4722e-01],\n         [-9.3416e-02],\n         [-3.8146e-02],\n         [-8.1138e-02],\n         [-4.1016e-02],\n         [-1.3682e-02],\n         [ 2.1532e-02],\n         [-2.2482e-02],\n         [ 9.0566e-03],\n         [-1.1354e-01],\n         [-8.7592e-02],\n         [ 8.0724e-03]],\n\n        [[ 1.5619e-01],\n         [ 1.4240e-01],\n         [ 5.5793e-02],\n         [ 1.2516e-01],\n         [ 1.2780e-01],\n         [ 1.7074e-01],\n         [ 1.2355e-01],\n         [ 1.0156e-01],\n         [ 1.5529e-01],\n         [ 3.6283e-01],\n         [ 1.6179e-01],\n         [ 2.2154e-01],\n         [ 2.7337e-01],\n         [ 2.4066e-01],\n         [ 2.7004e-01],\n         [ 1.6767e-01],\n         [ 1.9803e-01],\n         [ 3.0233e-01],\n         [ 1.9409e-01],\n         [ 1.5990e-01],\n         [ 1.5723e-01],\n         [ 2.7199e-01],\n         [ 1.8649e-01],\n         [ 2.0280e-01]],\n\n        [[-7.8074e-02],\n         [-5.7218e-02],\n         [-2.5670e-02],\n         [-6.8699e-02],\n         [ 5.2639e-02],\n         [-9.7107e-02],\n         [-7.9909e-02],\n         [-1.7429e-01],\n         [-9.6944e-02],\n         [-6.3766e-02],\n         [ 2.5762e-01],\n         [-9.1113e-02],\n         [-5.2263e-02],\n         [-6.5880e-02],\n         [-8.1698e-02],\n         [-9.0836e-02],\n         [-1.1195e-01],\n         [-6.9694e-02],\n         [-1.0620e-01],\n         [-1.4202e-01],\n         [-1.2524e-01],\n         [-1.7274e-01],\n         [-1.6002e-01],\n         [-1.6329e-01]],\n\n        [[ 1.4111e-01],\n         [ 1.2021e-01],\n         [ 6.6518e-02],\n         [ 1.2021e-01],\n         [ 4.5047e-02],\n         [-3.0587e-02],\n         [-1.0746e-03],\n         [ 9.3350e-02],\n         [ 1.2414e-01],\n         [ 1.3117e-01],\n         [ 2.7222e-01],\n         [ 7.2117e-02],\n         [ 8.2904e-02],\n         [ 8.0531e-02],\n         [ 7.7689e-02],\n         [ 3.8549e-02],\n         [ 2.7719e-02],\n         [ 7.8876e-02],\n         [ 6.1680e-02],\n         [ 5.4731e-02],\n         [ 5.3968e-02],\n         [ 1.5452e-01],\n         [ 9.7629e-02],\n         [ 5.7103e-02]]], device='cuda:0', grad_fn=<AddBackward0>), ([], [], []))\n:List trace inputs must have elements (toTypeInferredIValue at /opt/conda/conda-bld/pytorch_1579027003190/work/torch/csrc/jit/pybind_utils.h:293)\nframe #0: c10::Error::Error(c10::SourceLocation, std::string const&) + 0x47 (0x7fc9ff191627 in /home/aloui/miniconda3/envs/vilbert-mt/lib/python3.6/site-packages/torch/lib/libc10.so)\nframe #1: <unknown function> + 0x6e4c9f (0x7fca304efc9f in /home/aloui/miniconda3/envs/vilbert-mt/lib/python3.6/site-packages/torch/lib/libtorch_python.so)\nframe #2: <unknown function> + 0x769f4b (0x7fca30574f4b in /home/aloui/miniconda3/envs/vilbert-mt/lib/python3.6/site-packages/torch/lib/libtorch_python.so)\nframe #3: torch::jit::tracer::trace(std::vector<c10::IValue, std::allocator<c10::IValue> >, std::function<std::vector<c10::IValue, std::allocator<c10::IValue> > (std::vector<c10::IValue, std::allocator<c10::IValue> >)> const&, std::function<std::string (at::Tensor const&)>, bool, torch::jit::script::Module*) + 0x4e6 (0x7fca04d96e26 in /home/aloui/miniconda3/envs/vilbert-mt/lib/python3.6/site-packages/torch/lib/libtorch.so)\nframe #4: <unknown function> + 0x7660e1 (0x7fca305710e1 in /home/aloui/miniconda3/envs/vilbert-mt/lib/python3.6/site-packages/torch/lib/libtorch_python.so)\nframe #5: <unknown function> + 0x77ffb1 (0x7fca3058afb1 in /home/aloui/miniconda3/envs/vilbert-mt/lib/python3.6/site-packages/torch/lib/libtorch_python.so)\nframe #6: <unknown function> + 0x28c076 (0x7fca30097076 in /home/aloui/miniconda3/envs/vilbert-mt/lib/python3.6/site-packages/torch/lib/libtorch_python.so)\nframe #7: _PyCFunction_FastCallDict + 0x154 (0x560568e28304 in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\nframe #8: <unknown function> + 0x199c5e (0x560568eafc5e in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\nframe #9: _PyEval_EvalFrameDefault + 0x30a (0x560568ed281a in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\nframe #10: <unknown function> + 0x19335e (0x560568ea935e in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\nframe #11: <unknown function> + 0x193f31 (0x560568ea9f31 in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\nframe #12: <unknown function> + 0x199be5 (0x560568eafbe5 in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\nframe #13: _PyEval_EvalFrameDefault + 0x30a (0x560568ed281a in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\nframe #14: <unknown function> + 0x192f26 (0x560568ea8f26 in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\nframe #15: <unknown function> + 0x193f31 (0x560568ea9f31 in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\nframe #16: <unknown function> + 0x199be5 (0x560568eafbe5 in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\nframe #17: _PyEval_EvalFrameDefault + 0x30a (0x560568ed281a in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\nframe #18: <unknown function> + 0x192f26 (0x560568ea8f26 in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\nframe #19: <unknown function> + 0x193f31 (0x560568ea9f31 in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\nframe #20: <unknown function> + 0x199be5 (0x560568eafbe5 in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\nframe #21: _PyEval_EvalFrameDefault + 0x30a (0x560568ed281a in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\nframe #22: <unknown function> + 0x192f26 (0x560568ea8f26 in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\nframe #23: <unknown function> + 0x193f31 (0x560568ea9f31 in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\nframe #24: <unknown function> + 0x199be5 (0x560568eafbe5 in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\nframe #25: _PyEval_EvalFrameDefault + 0x10c9 (0x560568ed35d9 in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\nframe #26: PyEval_EvalCodeEx + 0x329 (0x560568eaaa49 in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\nframe #27: PyEval_EvalCode + 0x1c (0x560568eab7ec in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\nframe #28: <unknown function> + 0x1ba227 (0x560568ed0227 in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\nframe #29: _PyCFunction_FastCallDict + 0x91 (0x560568e28241 in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\nframe #30: <unknown function> + 0x199b0c (0x560568eafb0c in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\nframe #31: _PyEval_EvalFrameDefault + 0x30a (0x560568ed281a in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\nframe #32: _PyGen_Send + 0x256 (0x560568eb2bc6 in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\nframe #33: _PyEval_EvalFrameDefault + 0x1445 (0x560568ed3955 in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\nframe #34: _PyGen_Send + 0x256 (0x560568eb2bc6 in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\nframe #35: _PyEval_EvalFrameDefault + 0x1445 (0x560568ed3955 in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\nframe #36: _PyGen_Send + 0x256 (0x560568eb2bc6 in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\nframe #37: _PyCFunction_FastCallDict + 0x115 (0x560568e282c5 in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\nframe #38: <unknown function> + 0x199b0c (0x560568eafb0c in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\nframe #39: _PyEval_EvalFrameDefault + 0x30a (0x560568ed281a in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\nframe #40: <unknown function> + 0x193cfb (0x560568ea9cfb in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\nframe #41: <unknown function> + 0x199be5 (0x560568eafbe5 in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\nframe #42: _PyEval_EvalFrameDefault + 0x30a (0x560568ed281a in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\nframe #43: <unknown function> + 0x193cfb (0x560568ea9cfb in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\nframe #44: <unknown function> + 0x199be5 (0x560568eafbe5 in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\nframe #45: _PyEval_EvalFrameDefault + 0x30a (0x560568ed281a in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\nframe #46: <unknown function> + 0x192f26 (0x560568ea8f26 in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\nframe #47: _PyFunction_FastCallDict + 0x3d8 (0x560568eaa628 in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\nframe #48: _PyObject_FastCallDict + 0x26f (0x560568e286cf in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\nframe #49: _PyObject_Call_Prepend + 0x63 (0x560568e2d143 in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\nframe #50: PyObject_Call + 0x3e (0x560568e2810e in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\nframe #51: _PyEval_EvalFrameDefault + 0x1aaf (0x560568ed3fbf in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\nframe #52: <unknown function> + 0x1931f6 (0x560568ea91f6 in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\nframe #53: <unknown function> + 0x193f31 (0x560568ea9f31 in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\nframe #54: <unknown function> + 0x199be5 (0x560568eafbe5 in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\nframe #55: _PyEval_EvalFrameDefault + 0x10c9 (0x560568ed35d9 in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\nframe #56: <unknown function> + 0x19c744 (0x560568eb2744 in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\nframe #57: _PyCFunction_FastCallDict + 0x91 (0x560568e28241 in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\nframe #58: <unknown function> + 0x199b0c (0x560568eafb0c in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\nframe #59: _PyEval_EvalFrameDefault + 0x30a (0x560568ed281a in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\nframe #60: <unknown function> + 0x1931f6 (0x560568ea91f6 in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\nframe #61: <unknown function> + 0x193f31 (0x560568ea9f31 in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\nframe #62: <unknown function> + 0x199be5 (0x560568eafbe5 in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\nframe #63: _PyEval_EvalFrameDefault + 0x30a (0x560568ed281a in /home/aloui/miniconda3/envs/vilbert-mt/bin/python)\n"
     ]
    }
   ],
   "source": [
    "writer = SummaryWriter(logdir='results/runs')\n",
    "input_ = (question, features, spatials, segment_ids, input_mask, image_mask, co_attention_mask, task_tokens)\n",
    "writer.add_graph(model, input_to_model=input_)\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VILBertForVLTasks(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (task_embeddings): Embedding(20, 768)\n",
       "    )\n",
       "    (v_embeddings): BertImageEmbeddings(\n",
       "      (image_embeddings): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "      (image_location_embeddings): Linear(in_features=5, out_features=1024, bias=True)\n",
       "      (LayerNorm): FusedLayerNorm(torch.Size([1024]), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (v_layer): ModuleList(\n",
       "        (0): BertImageLayer(\n",
       "          (attention): BertImageAttention(\n",
       "            (self): BertImageSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertImageSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): FusedLayerNorm(torch.Size([1024]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertImageIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (output): BertImageOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([1024]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertImageLayer(\n",
       "          (attention): BertImageAttention(\n",
       "            (self): BertImageSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertImageSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): FusedLayerNorm(torch.Size([1024]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertImageIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (output): BertImageOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([1024]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertImageLayer(\n",
       "          (attention): BertImageAttention(\n",
       "            (self): BertImageSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertImageSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): FusedLayerNorm(torch.Size([1024]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertImageIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (output): BertImageOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([1024]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertImageLayer(\n",
       "          (attention): BertImageAttention(\n",
       "            (self): BertImageSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertImageSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): FusedLayerNorm(torch.Size([1024]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertImageIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (output): BertImageOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([1024]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertImageLayer(\n",
       "          (attention): BertImageAttention(\n",
       "            (self): BertImageSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertImageSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): FusedLayerNorm(torch.Size([1024]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertImageIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (output): BertImageOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([1024]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertImageLayer(\n",
       "          (attention): BertImageAttention(\n",
       "            (self): BertImageSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertImageSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): FusedLayerNorm(torch.Size([1024]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertImageIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (output): BertImageOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([1024]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (c_layer): ModuleList(\n",
       "        (0): BertConnectionLayer(\n",
       "          (biattention): BertBiAttention(\n",
       "            (query1): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (key1): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (value1): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (dropout1): Dropout(p=0.1, inplace=False)\n",
       "            (query2): Linear(in_features=768, out_features=1024, bias=True)\n",
       "            (key2): Linear(in_features=768, out_features=1024, bias=True)\n",
       "            (value2): Linear(in_features=768, out_features=1024, bias=True)\n",
       "            (dropout2): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (biOutput): BertBiOutput(\n",
       "            (dense1): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm1): FusedLayerNorm(torch.Size([1024]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout1): Dropout(p=0.1, inplace=False)\n",
       "            (q_dense1): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_dropout1): Dropout(p=0.1, inplace=False)\n",
       "            (dense2): Linear(in_features=1024, out_features=768, bias=True)\n",
       "            (LayerNorm2): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout2): Dropout(p=0.1, inplace=False)\n",
       "            (q_dense2): Linear(in_features=1024, out_features=768, bias=True)\n",
       "            (q_dropout2): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (v_intermediate): BertImageIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (v_output): BertImageOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([1024]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (t_intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (t_output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertConnectionLayer(\n",
       "          (biattention): BertBiAttention(\n",
       "            (query1): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (key1): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (value1): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (dropout1): Dropout(p=0.1, inplace=False)\n",
       "            (query2): Linear(in_features=768, out_features=1024, bias=True)\n",
       "            (key2): Linear(in_features=768, out_features=1024, bias=True)\n",
       "            (value2): Linear(in_features=768, out_features=1024, bias=True)\n",
       "            (dropout2): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (biOutput): BertBiOutput(\n",
       "            (dense1): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm1): FusedLayerNorm(torch.Size([1024]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout1): Dropout(p=0.1, inplace=False)\n",
       "            (q_dense1): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_dropout1): Dropout(p=0.1, inplace=False)\n",
       "            (dense2): Linear(in_features=1024, out_features=768, bias=True)\n",
       "            (LayerNorm2): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout2): Dropout(p=0.1, inplace=False)\n",
       "            (q_dense2): Linear(in_features=1024, out_features=768, bias=True)\n",
       "            (q_dropout2): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (v_intermediate): BertImageIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (v_output): BertImageOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([1024]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (t_intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (t_output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertConnectionLayer(\n",
       "          (biattention): BertBiAttention(\n",
       "            (query1): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (key1): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (value1): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (dropout1): Dropout(p=0.1, inplace=False)\n",
       "            (query2): Linear(in_features=768, out_features=1024, bias=True)\n",
       "            (key2): Linear(in_features=768, out_features=1024, bias=True)\n",
       "            (value2): Linear(in_features=768, out_features=1024, bias=True)\n",
       "            (dropout2): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (biOutput): BertBiOutput(\n",
       "            (dense1): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm1): FusedLayerNorm(torch.Size([1024]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout1): Dropout(p=0.1, inplace=False)\n",
       "            (q_dense1): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_dropout1): Dropout(p=0.1, inplace=False)\n",
       "            (dense2): Linear(in_features=1024, out_features=768, bias=True)\n",
       "            (LayerNorm2): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout2): Dropout(p=0.1, inplace=False)\n",
       "            (q_dense2): Linear(in_features=1024, out_features=768, bias=True)\n",
       "            (q_dropout2): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (v_intermediate): BertImageIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (v_output): BertImageOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([1024]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (t_intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (t_output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertConnectionLayer(\n",
       "          (biattention): BertBiAttention(\n",
       "            (query1): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (key1): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (value1): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (dropout1): Dropout(p=0.1, inplace=False)\n",
       "            (query2): Linear(in_features=768, out_features=1024, bias=True)\n",
       "            (key2): Linear(in_features=768, out_features=1024, bias=True)\n",
       "            (value2): Linear(in_features=768, out_features=1024, bias=True)\n",
       "            (dropout2): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (biOutput): BertBiOutput(\n",
       "            (dense1): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm1): FusedLayerNorm(torch.Size([1024]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout1): Dropout(p=0.1, inplace=False)\n",
       "            (q_dense1): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_dropout1): Dropout(p=0.1, inplace=False)\n",
       "            (dense2): Linear(in_features=1024, out_features=768, bias=True)\n",
       "            (LayerNorm2): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout2): Dropout(p=0.1, inplace=False)\n",
       "            (q_dense2): Linear(in_features=1024, out_features=768, bias=True)\n",
       "            (q_dropout2): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (v_intermediate): BertImageIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (v_output): BertImageOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([1024]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (t_intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (t_output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertConnectionLayer(\n",
       "          (biattention): BertBiAttention(\n",
       "            (query1): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (key1): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (value1): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (dropout1): Dropout(p=0.1, inplace=False)\n",
       "            (query2): Linear(in_features=768, out_features=1024, bias=True)\n",
       "            (key2): Linear(in_features=768, out_features=1024, bias=True)\n",
       "            (value2): Linear(in_features=768, out_features=1024, bias=True)\n",
       "            (dropout2): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (biOutput): BertBiOutput(\n",
       "            (dense1): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm1): FusedLayerNorm(torch.Size([1024]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout1): Dropout(p=0.1, inplace=False)\n",
       "            (q_dense1): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_dropout1): Dropout(p=0.1, inplace=False)\n",
       "            (dense2): Linear(in_features=1024, out_features=768, bias=True)\n",
       "            (LayerNorm2): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout2): Dropout(p=0.1, inplace=False)\n",
       "            (q_dense2): Linear(in_features=1024, out_features=768, bias=True)\n",
       "            (q_dropout2): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (v_intermediate): BertImageIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (v_output): BertImageOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([1024]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (t_intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (t_output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertConnectionLayer(\n",
       "          (biattention): BertBiAttention(\n",
       "            (query1): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (key1): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (value1): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (dropout1): Dropout(p=0.1, inplace=False)\n",
       "            (query2): Linear(in_features=768, out_features=1024, bias=True)\n",
       "            (key2): Linear(in_features=768, out_features=1024, bias=True)\n",
       "            (value2): Linear(in_features=768, out_features=1024, bias=True)\n",
       "            (dropout2): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (biOutput): BertBiOutput(\n",
       "            (dense1): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm1): FusedLayerNorm(torch.Size([1024]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout1): Dropout(p=0.1, inplace=False)\n",
       "            (q_dense1): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_dropout1): Dropout(p=0.1, inplace=False)\n",
       "            (dense2): Linear(in_features=1024, out_features=768, bias=True)\n",
       "            (LayerNorm2): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout2): Dropout(p=0.1, inplace=False)\n",
       "            (q_dense2): Linear(in_features=1024, out_features=768, bias=True)\n",
       "            (q_dropout2): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (v_intermediate): BertImageIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (v_output): BertImageOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([1024]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (t_intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (t_output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (t_pooler): BertTextPooler(\n",
       "      (dense): Linear(in_features=768, out_features=1024, bias=True)\n",
       "      (activation): ReLU()\n",
       "    )\n",
       "    (v_pooler): BertImagePooler(\n",
       "      (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      (activation): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (cls): BertPreTrainingHeads(\n",
       "    (predictions): BertLMPredictionHead(\n",
       "      (transform): BertPredictionHeadTransform(\n",
       "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "      )\n",
       "      (decoder): Linear(in_features=768, out_features=30522, bias=False)\n",
       "    )\n",
       "    (bi_seq_relationship): Linear(in_features=1024, out_features=2, bias=True)\n",
       "    (imagePredictions): BertImagePredictionHead(\n",
       "      (transform): BertImgPredictionHeadTransform(\n",
       "        (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (LayerNorm): FusedLayerNorm(torch.Size([1024]), eps=1e-12, elementwise_affine=True)\n",
       "      )\n",
       "      (decoder): Linear(in_features=1024, out_features=1601, bias=True)\n",
       "    )\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (vil_prediction): SimpleClassifier(\n",
       "    (logit_fc): Sequential(\n",
       "      (0): Linear(in_features=1024, out_features=2048, bias=True)\n",
       "      (1): GeLU()\n",
       "      (2): FusedLayerNorm(torch.Size([2048]), eps=1e-12, elementwise_affine=True)\n",
       "      (3): Linear(in_features=2048, out_features=3129, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (vil_prediction_gqa): SimpleClassifier(\n",
       "    (logit_fc): Sequential(\n",
       "      (0): Linear(in_features=1024, out_features=2048, bias=True)\n",
       "      (1): GeLU()\n",
       "      (2): FusedLayerNorm(torch.Size([2048]), eps=1e-12, elementwise_affine=True)\n",
       "      (3): Linear(in_features=2048, out_features=1533, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (vil_binary_prediction): SimpleClassifier(\n",
       "    (logit_fc): Sequential(\n",
       "      (0): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "      (1): GeLU()\n",
       "      (2): FusedLayerNorm(torch.Size([2048]), eps=1e-12, elementwise_affine=True)\n",
       "      (3): Linear(in_features=2048, out_features=2, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (vil_logit): Linear(in_features=1024, out_features=1, bias=True)\n",
       "  (vil_tri_prediction): Linear(in_features=1024, out_features=3, bias=True)\n",
       "  (vision_logit): Linear(in_features=1024, out_features=1, bias=True)\n",
       "  (linguisic_logit): Linear(in_features=768, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(10.9015, device='cuda:0', grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vil_prediction[0][2969]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2969, 2785, 2293,  878,   89, 2621, 2134, 2621, 1403,  425, 1027,  411,\n",
       "         425, 1403,  444, 1076, 2218, 2621,  402, 2621, 1136,  425,  711, 2785,\n",
       "        2681, 2681,  990,  425, 1684, 2594], device='cuda:0')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1., device='cuda:0')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hots[0][2969]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([30, 3129])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import _pickle as cPickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "targ = cPickle.load(open('datasets/VQA/cache/train_target.pkl', \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'image_id': 458752,\n",
       "  'labels': [1164],\n",
       "  'scores': [1],\n",
       "  'question_id': 458752000},\n",
       " {'image_id': 458752,\n",
       "  'labels': [1840, 290],\n",
       "  'scores': [0.3, 1],\n",
       "  'question_id': 458752001},\n",
       " {'image_id': 458752,\n",
       "  'labels': [1491],\n",
       "  'scores': [1],\n",
       "  'question_id': 458752002},\n",
       " {'image_id': 458752,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [1, 0.3],\n",
       "  'question_id': 458752003},\n",
       " {'image_id': 262146,\n",
       "  'labels': [3006],\n",
       "  'scores': [1],\n",
       "  'question_id': 262146000},\n",
       " {'image_id': 262146,\n",
       "  'labels': [1561],\n",
       "  'scores': [1],\n",
       "  'question_id': 262146001},\n",
       " {'image_id': 262146,\n",
       "  'labels': [2241, 1227, 1333],\n",
       "  'scores': [0.3, 0.3, 1],\n",
       "  'question_id': 262146002},\n",
       " {'image_id': 524291,\n",
       "  'labels': [1712],\n",
       "  'scores': [1],\n",
       "  'question_id': 524291000},\n",
       " {'image_id': 524291,\n",
       "  'labels': [425],\n",
       "  'scores': [1],\n",
       "  'question_id': 524291001},\n",
       " {'image_id': 524291,\n",
       "  'labels': [1712],\n",
       "  'scores': [1],\n",
       "  'question_id': 524291002},\n",
       " {'image_id': 393221,\n",
       "  'labels': [425],\n",
       "  'scores': [1],\n",
       "  'question_id': 393221000},\n",
       " {'image_id': 393221,\n",
       "  'labels': [425],\n",
       "  'scores': [1],\n",
       "  'question_id': 393221001},\n",
       " {'image_id': 393221,\n",
       "  'labels': [2154, 1448],\n",
       "  'scores': [0.3, 0.3],\n",
       "  'question_id': 393221002},\n",
       " {'image_id': 393223,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [1, 0.6],\n",
       "  'question_id': 393223000},\n",
       " {'image_id': 393223,\n",
       "  'labels': [3006, 2183],\n",
       "  'scores': [0.9, 0.3],\n",
       "  'question_id': 393223001},\n",
       " {'image_id': 393223,\n",
       "  'labels': [75, 2966, 2360],\n",
       "  'scores': [0.3, 0.3, 1],\n",
       "  'question_id': 393223002},\n",
       " {'image_id': 393223,\n",
       "  'labels': [425],\n",
       "  'scores': [1],\n",
       "  'question_id': 393223003},\n",
       " {'image_id': 393224,\n",
       "  'labels': [1403],\n",
       "  'scores': [1],\n",
       "  'question_id': 393224000},\n",
       " {'image_id': 393224,\n",
       "  'labels': [931, 1954, 735, 3079],\n",
       "  'scores': [0.3, 0.6, 0.3, 0.3],\n",
       "  'question_id': 393224001},\n",
       " {'image_id': 393224,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [0.9, 1],\n",
       "  'question_id': 393224002},\n",
       " {'image_id': 393224,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [0.3, 1],\n",
       "  'question_id': 393224003},\n",
       " {'image_id': 393224,\n",
       "  'labels': [1403],\n",
       "  'scores': [1],\n",
       "  'question_id': 393224004},\n",
       " {'image_id': 393224,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [0.3, 1],\n",
       "  'question_id': 393224005},\n",
       " {'image_id': 524297,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [1, 0.9],\n",
       "  'question_id': 524297000},\n",
       " {'image_id': 524297,\n",
       "  'labels': [1086, 1851, 2324],\n",
       "  'scores': [0.3, 0.3, 1],\n",
       "  'question_id': 524297001},\n",
       " {'image_id': 524297,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [0.3, 1],\n",
       "  'question_id': 524297002},\n",
       " {'image_id': 524297,\n",
       "  'labels': [1403],\n",
       "  'scores': [1],\n",
       "  'question_id': 524297003},\n",
       " {'image_id': 393227,\n",
       "  'labels': [425],\n",
       "  'scores': [1],\n",
       "  'question_id': 393227000},\n",
       " {'image_id': 393227,\n",
       "  'labels': [547],\n",
       "  'scores': [1],\n",
       "  'question_id': 393227001},\n",
       " {'image_id': 393227,\n",
       "  'labels': [2195, 2621, 841],\n",
       "  'scores': [1, 0.3, 0.3],\n",
       "  'question_id': 393227002},\n",
       " {'image_id': 393227,\n",
       "  'labels': [411, 545],\n",
       "  'scores': [1, 0.3],\n",
       "  'question_id': 393227003},\n",
       " {'image_id': 393227,\n",
       "  'labels': [1403],\n",
       "  'scores': [1],\n",
       "  'question_id': 393227004},\n",
       " {'image_id': 131084,\n",
       "  'labels': [2852, 990],\n",
       "  'scores': [0.9, 1],\n",
       "  'question_id': 131084000},\n",
       " {'image_id': 131084,\n",
       "  'labels': [425],\n",
       "  'scores': [1],\n",
       "  'question_id': 131084001},\n",
       " {'image_id': 131084,\n",
       "  'labels': [2062, 746, 2514],\n",
       "  'scores': [0.9, 0.6, 1],\n",
       "  'question_id': 131084002},\n",
       " {'image_id': 131074,\n",
       "  'labels': [1880, 905, 103, 2274, 1566],\n",
       "  'scores': [0.3, 0.3, 0.3, 0.3, 0.3],\n",
       "  'question_id': 131074000},\n",
       " {'image_id': 131074,\n",
       "  'labels': [841],\n",
       "  'scores': [1],\n",
       "  'question_id': 131074001},\n",
       " {'image_id': 131074,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [1, 0.9],\n",
       "  'question_id': 131074002},\n",
       " {'image_id': 131074,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [0.9, 1],\n",
       "  'question_id': 131074003},\n",
       " {'image_id': 131074,\n",
       "  'labels': [1601],\n",
       "  'scores': [1],\n",
       "  'question_id': 131074004},\n",
       " {'image_id': 131074,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [1, 0.6],\n",
       "  'question_id': 131074005},\n",
       " {'image_id': 393230,\n",
       "  'labels': [1561],\n",
       "  'scores': [1],\n",
       "  'question_id': 393230000},\n",
       " {'image_id': 393230,\n",
       "  'labels': [2195],\n",
       "  'scores': [1],\n",
       "  'question_id': 393230001},\n",
       " {'image_id': 393230,\n",
       "  'labels': [1403],\n",
       "  'scores': [1],\n",
       "  'question_id': 393230002},\n",
       " {'image_id': 393230,\n",
       "  'labels': [1561],\n",
       "  'scores': [1],\n",
       "  'question_id': 393230003},\n",
       " {'image_id': 393230,\n",
       "  'labels': [1880, 337],\n",
       "  'scores': [1, 0.3],\n",
       "  'question_id': 393230004},\n",
       " {'image_id': 393230,\n",
       "  'labels': [1434, 1198, 2423, 1162],\n",
       "  'scores': [0.3, 0.6, 0.3, 0.6],\n",
       "  'question_id': 393230005},\n",
       " {'image_id': 393230,\n",
       "  'labels': [1403],\n",
       "  'scores': [1],\n",
       "  'question_id': 393230006},\n",
       " {'image_id': 393230,\n",
       "  'labels': [411, 337],\n",
       "  'scores': [1, 0.3],\n",
       "  'question_id': 393230007},\n",
       " {'image_id': 393230,\n",
       "  'labels': [425],\n",
       "  'scores': [1],\n",
       "  'question_id': 393230008},\n",
       " {'image_id': 393230,\n",
       "  'labels': [1198, 2806, 2692, 1429, 1008],\n",
       "  'scores': [0.3, 0.6, 1, 0.3, 0.3],\n",
       "  'question_id': 393230009},\n",
       " {'image_id': 393230,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [1, 1],\n",
       "  'question_id': 393230010},\n",
       " {'image_id': 131087,\n",
       "  'labels': [51, 689],\n",
       "  'scores': [0.3, 1],\n",
       "  'question_id': 131087000},\n",
       " {'image_id': 131087,\n",
       "  'labels': [425],\n",
       "  'scores': [1],\n",
       "  'question_id': 131087001},\n",
       " {'image_id': 131087,\n",
       "  'labels': [425],\n",
       "  'scores': [1],\n",
       "  'question_id': 131087002},\n",
       " {'image_id': 131087,\n",
       "  'labels': [425],\n",
       "  'scores': [1],\n",
       "  'question_id': 131087003},\n",
       " {'image_id': 131087,\n",
       "  'labels': [1930, 689],\n",
       "  'scores': [0.9, 0.6],\n",
       "  'question_id': 131087004},\n",
       " {'image_id': 131075,\n",
       "  'labels': [2507, 175, 2437, 2786],\n",
       "  'scores': [0.6, 0.3, 0.3, 0.6],\n",
       "  'question_id': 131075000},\n",
       " {'image_id': 131075,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [0.3, 1],\n",
       "  'question_id': 131075001},\n",
       " {'image_id': 131075,\n",
       "  'labels': [275, 2551, 2875, 2522, 963],\n",
       "  'scores': [0.6, 1, 0.3, 0.3, 0.3],\n",
       "  'question_id': 131075002},\n",
       " {'image_id': 131075,\n",
       "  'labels': [2094, 1616, 2679],\n",
       "  'scores': [0.3, 0.6, 0.3],\n",
       "  'question_id': 131075003},\n",
       " {'image_id': 131075,\n",
       "  'labels': [1403],\n",
       "  'scores': [1],\n",
       "  'question_id': 131075004},\n",
       " {'image_id': 131075,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [1, 1],\n",
       "  'question_id': 131075005},\n",
       " {'image_id': 131075,\n",
       "  'labels': [517, 1076, 2875, 1616],\n",
       "  'scores': [1, 0.3, 0.3, 0.3],\n",
       "  'question_id': 131075006},\n",
       " {'image_id': 131075,\n",
       "  'labels': [2973, 2723, 1255],\n",
       "  'scores': [1, 0.6, 0.6],\n",
       "  'question_id': 131075007},\n",
       " {'image_id': 131075,\n",
       "  'labels': [2973],\n",
       "  'scores': [1],\n",
       "  'question_id': 131075008},\n",
       " {'image_id': 131075,\n",
       "  'labels': [2918, 1375, 1932],\n",
       "  'scores': [1, 1, 0.3],\n",
       "  'question_id': 131075009},\n",
       " {'image_id': 131075,\n",
       "  'labels': [1938],\n",
       "  'scores': [0.3],\n",
       "  'question_id': 131075010},\n",
       " {'image_id': 131075,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [1, 0.6],\n",
       "  'question_id': 131075011},\n",
       " {'image_id': 131075,\n",
       "  'labels': [425, 458],\n",
       "  'scores': [0.3, 0.6],\n",
       "  'question_id': 131075012},\n",
       " {'image_id': 131075,\n",
       "  'labels': [1060, 2723],\n",
       "  'scores': [0.3, 0.6],\n",
       "  'question_id': 131075013},\n",
       " {'image_id': 131075,\n",
       "  'labels': [1906, 2634, 750, 1444],\n",
       "  'scores': [0.3, 0.3, 0.3, 0.3],\n",
       "  'question_id': 131075014},\n",
       " {'image_id': 137045,\n",
       "  'labels': [1227],\n",
       "  'scores': [1],\n",
       "  'question_id': 137045000},\n",
       " {'image_id': 137045,\n",
       "  'labels': [425],\n",
       "  'scores': [1],\n",
       "  'question_id': 137045001},\n",
       " {'image_id': 137045,\n",
       "  'labels': [2914],\n",
       "  'scores': [1],\n",
       "  'question_id': 137045002},\n",
       " {'image_id': 131093,\n",
       "  'labels': [425],\n",
       "  'scores': [1],\n",
       "  'question_id': 131093000},\n",
       " {'image_id': 131093,\n",
       "  'labels': [444, 1403],\n",
       "  'scores': [0.3, 1],\n",
       "  'question_id': 131093001},\n",
       " {'image_id': 131093,\n",
       "  'labels': [444, 2621],\n",
       "  'scores': [0.3, 1],\n",
       "  'question_id': 131093002},\n",
       " {'image_id': 131093,\n",
       "  'labels': [425],\n",
       "  'scores': [1],\n",
       "  'question_id': 131093003},\n",
       " {'image_id': 524311,\n",
       "  'labels': [1848, 1863],\n",
       "  'scores': [0.3, 1],\n",
       "  'question_id': 524311000},\n",
       " {'image_id': 524311,\n",
       "  'labels': [425],\n",
       "  'scores': [1],\n",
       "  'question_id': 524311001},\n",
       " {'image_id': 524311,\n",
       "  'labels': [2447, 2339, 149],\n",
       "  'scores': [0.3, 0.3, 1],\n",
       "  'question_id': 524311002},\n",
       " {'image_id': 25,\n",
       "  'labels': [1539, 1095],\n",
       "  'scores': [1, 0.6],\n",
       "  'question_id': 25000},\n",
       " {'image_id': 25,\n",
       "  'labels': [2681, 2541, 1970],\n",
       "  'scores': [1, 0.3, 0.3],\n",
       "  'question_id': 25001},\n",
       " {'image_id': 25, 'labels': [425], 'scores': [1], 'question_id': 25002},\n",
       " {'image_id': 25, 'labels': [425], 'scores': [1], 'question_id': 25003},\n",
       " {'image_id': 25,\n",
       "  'labels': [492, 60, 2210, 425],\n",
       "  'scores': [0.3, 0.3, 0.3, 0.3],\n",
       "  'question_id': 25004},\n",
       " {'image_id': 25, 'labels': [1403], 'scores': [1], 'question_id': 25005},\n",
       " {'image_id': 25,\n",
       "  'labels': [1539, 1803, 1095],\n",
       "  'scores': [1, 0.9, 0.3],\n",
       "  'question_id': 25006},\n",
       " {'image_id': 25,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [1, 0.6],\n",
       "  'question_id': 25007},\n",
       " {'image_id': 25,\n",
       "  'labels': [425, 841, 1403],\n",
       "  'scores': [0.9, 0.3, 1],\n",
       "  'question_id': 25008},\n",
       " {'image_id': 25,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [1, 1],\n",
       "  'question_id': 25009},\n",
       " {'image_id': 25,\n",
       "  'labels': [1539, 1803, 1095],\n",
       "  'scores': [0.6, 1, 0.3],\n",
       "  'question_id': 25010},\n",
       " {'image_id': 25,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [1, 0.3],\n",
       "  'question_id': 25011},\n",
       " {'image_id': 25,\n",
       "  'labels': [2195, 425],\n",
       "  'scores': [0.3, 1],\n",
       "  'question_id': 25012},\n",
       " {'image_id': 25, 'labels': [1403], 'scores': [1], 'question_id': 25013},\n",
       " {'image_id': 25,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [1, 1],\n",
       "  'question_id': 25014},\n",
       " {'image_id': 25,\n",
       "  'labels': [2195, 841],\n",
       "  'scores': [0.6, 1],\n",
       "  'question_id': 25015},\n",
       " {'image_id': 25, 'labels': [1403], 'scores': [1], 'question_id': 25016},\n",
       " {'image_id': 25,\n",
       "  'labels': [841, 991],\n",
       "  'scores': [1, 0.3],\n",
       "  'question_id': 25017},\n",
       " {'image_id': 524314,\n",
       "  'labels': [490, 1645],\n",
       "  'scores': [0.3, 0.3],\n",
       "  'question_id': 524314000},\n",
       " {'image_id': 524314, 'labels': [], 'scores': [], 'question_id': 524314001},\n",
       " {'image_id': 524314, 'labels': [], 'scores': [], 'question_id': 524314002},\n",
       " {'image_id': 262171,\n",
       "  'labels': [703, 3031, 311, 1618],\n",
       "  'scores': [0.3, 1, 0.3, 0.9],\n",
       "  'question_id': 262171000},\n",
       " {'image_id': 262171,\n",
       "  'labels': [990],\n",
       "  'scores': [1],\n",
       "  'question_id': 262171001},\n",
       " {'image_id': 262171,\n",
       "  'labels': [2033, 2428],\n",
       "  'scores': [1, 0.9],\n",
       "  'question_id': 262171002},\n",
       " {'image_id': 262172,\n",
       "  'labels': [876, 425, 2785],\n",
       "  'scores': [0.3, 0.3, 0.6],\n",
       "  'question_id': 262172000},\n",
       " {'image_id': 262172,\n",
       "  'labels': [275],\n",
       "  'scores': [1],\n",
       "  'question_id': 262172001},\n",
       " {'image_id': 262172,\n",
       "  'labels': [425],\n",
       "  'scores': [1],\n",
       "  'question_id': 262172002},\n",
       " {'image_id': 131101,\n",
       "  'labels': [1204, 1333, 1559],\n",
       "  'scores': [1, 0.3, 0.9],\n",
       "  'question_id': 131101000},\n",
       " {'image_id': 131101,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [0.6, 1],\n",
       "  'question_id': 131101001},\n",
       " {'image_id': 131101,\n",
       "  'labels': [2387],\n",
       "  'scores': [1],\n",
       "  'question_id': 131101002},\n",
       " {'image_id': 30, 'labels': [425], 'scores': [1], 'question_id': 30000},\n",
       " {'image_id': 30,\n",
       "  'labels': [2643, 2325, 2343],\n",
       "  'scores': [0.3, 0.3, 0.9],\n",
       "  'question_id': 30001},\n",
       " {'image_id': 30,\n",
       "  'labels': [2387, 949, 1403, 2785],\n",
       "  'scores': [0.6, 0.3, 0.3, 1],\n",
       "  'question_id': 30002},\n",
       " {'image_id': 30,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [1, 1],\n",
       "  'question_id': 30003},\n",
       " {'image_id': 30, 'labels': [3006], 'scores': [1], 'question_id': 30004},\n",
       " {'image_id': 30,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [0.3, 1],\n",
       "  'question_id': 30005},\n",
       " {'image_id': 524320,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [0.9, 1],\n",
       "  'question_id': 524320000},\n",
       " {'image_id': 524320,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [0.9, 1],\n",
       "  'question_id': 524320001},\n",
       " {'image_id': 524320,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [0.3, 1],\n",
       "  'question_id': 524320002},\n",
       " {'image_id': 240304,\n",
       "  'labels': [425, 660],\n",
       "  'scores': [0.3, 1],\n",
       "  'question_id': 240304000},\n",
       " {'image_id': 240304,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [1, 0.3],\n",
       "  'question_id': 240304001},\n",
       " {'image_id': 240304,\n",
       "  'labels': [2525, 2643, 575],\n",
       "  'scores': [0.6, 0.6, 0.6],\n",
       "  'question_id': 240304002},\n",
       " {'image_id': 34, 'labels': [1403], 'scores': [1], 'question_id': 34000},\n",
       " {'image_id': 34, 'labels': [660], 'scores': [1], 'question_id': 34001},\n",
       " {'image_id': 34,\n",
       "  'labels': [1015, 429, 878, 841, 1913, 632],\n",
       "  'scores': [0.3, 0.9, 0.3, 0.6, 0.3, 0.3],\n",
       "  'question_id': 34002},\n",
       " {'image_id': 393251,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [1, 0.3],\n",
       "  'question_id': 393251000},\n",
       " {'image_id': 393251,\n",
       "  'labels': [425],\n",
       "  'scores': [1],\n",
       "  'question_id': 393251001},\n",
       " {'image_id': 393251,\n",
       "  'labels': [2274, 484],\n",
       "  'scores': [0.3, 1],\n",
       "  'question_id': 393251002},\n",
       " {'image_id': 393251,\n",
       "  'labels': [2614, 755, 425],\n",
       "  'scores': [0.3, 1, 0.3],\n",
       "  'question_id': 393251003},\n",
       " {'image_id': 262180,\n",
       "  'labels': [120, 1831, 960],\n",
       "  'scores': [0.3, 1, 0.3],\n",
       "  'question_id': 262180000},\n",
       " {'image_id': 262180,\n",
       "  'labels': [425],\n",
       "  'scores': [1],\n",
       "  'question_id': 262180001},\n",
       " {'image_id': 262180,\n",
       "  'labels': [1719],\n",
       "  'scores': [1],\n",
       "  'question_id': 262180002},\n",
       " {'image_id': 262180,\n",
       "  'labels': [3110, 1831, 1715],\n",
       "  'scores': [1, 0.6, 0.3],\n",
       "  'question_id': 262180003},\n",
       " {'image_id': 524325,\n",
       "  'labels': [1239],\n",
       "  'scores': [1],\n",
       "  'question_id': 524325000},\n",
       " {'image_id': 524325,\n",
       "  'labels': [480],\n",
       "  'scores': [1],\n",
       "  'question_id': 524325001},\n",
       " {'image_id': 524325,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [1, 0.3],\n",
       "  'question_id': 524325002},\n",
       " {'image_id': 43697, 'labels': [425], 'scores': [1], 'question_id': 43697000},\n",
       " {'image_id': 43697, 'labels': [3006], 'scores': [1], 'question_id': 43697001},\n",
       " {'image_id': 43697, 'labels': [1403], 'scores': [1], 'question_id': 43697002},\n",
       " {'image_id': 43697,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [0.6, 1],\n",
       "  'question_id': 43697003},\n",
       " {'image_id': 43697,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [1, 0.6],\n",
       "  'question_id': 43697004},\n",
       " {'image_id': 43697,\n",
       "  'labels': [2274, 106, 1245, 1005],\n",
       "  'scores': [0.3, 0.3, 1, 0.3],\n",
       "  'question_id': 43697005},\n",
       " {'image_id': 43697,\n",
       "  'labels': [1225, 1354],\n",
       "  'scores': [0.9, 1],\n",
       "  'question_id': 43697006},\n",
       " {'image_id': 262184,\n",
       "  'labels': [1403],\n",
       "  'scores': [1],\n",
       "  'question_id': 262184000},\n",
       " {'image_id': 262184,\n",
       "  'labels': [681, 1123],\n",
       "  'scores': [1, 0.3],\n",
       "  'question_id': 262184001},\n",
       " {'image_id': 262184,\n",
       "  'labels': [1687, 2210, 179],\n",
       "  'scores': [0.9, 0.3, 0.3],\n",
       "  'question_id': 262184002},\n",
       " {'image_id': 131113,\n",
       "  'labels': [2594, 730, 3090, 1333],\n",
       "  'scores': [1, 0.3, 0.3, 0.6],\n",
       "  'question_id': 131113000},\n",
       " {'image_id': 131113,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [1, 1],\n",
       "  'question_id': 131113001},\n",
       " {'image_id': 131113,\n",
       "  'labels': [919, 775],\n",
       "  'scores': [0.3, 1],\n",
       "  'question_id': 131113002},\n",
       " {'image_id': 131113,\n",
       "  'labels': [3025, 2864],\n",
       "  'scores': [0.6, 1],\n",
       "  'question_id': 131113003},\n",
       " {'image_id': 262187,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [0.6, 1],\n",
       "  'question_id': 262187000},\n",
       " {'image_id': 262187,\n",
       "  'labels': [2241, 1062, 1333],\n",
       "  'scores': [0.3, 0.6, 1],\n",
       "  'question_id': 262187001},\n",
       " {'image_id': 262187,\n",
       "  'labels': [1577, 1579, 3041, 445, 221],\n",
       "  'scores': [1, 0.3, 0.3, 0.3, 0.3],\n",
       "  'question_id': 262187002},\n",
       " {'image_id': 262187,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [0.6, 1],\n",
       "  'question_id': 262187003},\n",
       " {'image_id': 131118,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [1, 0.9],\n",
       "  'question_id': 131118000},\n",
       " {'image_id': 131118,\n",
       "  'labels': [841, 3031],\n",
       "  'scores': [1, 0.3],\n",
       "  'question_id': 131118001},\n",
       " {'image_id': 131118,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [1, 1],\n",
       "  'question_id': 131118002},\n",
       " {'image_id': 262191,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [1, 1],\n",
       "  'question_id': 262191000},\n",
       " {'image_id': 262191,\n",
       "  'labels': [425],\n",
       "  'scores': [0.6],\n",
       "  'question_id': 262191001},\n",
       " {'image_id': 262191,\n",
       "  'labels': [160, 853],\n",
       "  'scores': [1, 1],\n",
       "  'question_id': 262191002},\n",
       " {'image_id': 49, 'labels': [425], 'scores': [1], 'question_id': 49000},\n",
       " {'image_id': 49, 'labels': [1227], 'scores': [1], 'question_id': 49001},\n",
       " {'image_id': 49,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [0.9, 1],\n",
       "  'question_id': 49002},\n",
       " {'image_id': 524338,\n",
       "  'labels': [2195, 2621, 3031, 1239],\n",
       "  'scores': [0.3, 1, 0.3, 0.6],\n",
       "  'question_id': 524338000},\n",
       " {'image_id': 524338,\n",
       "  'labels': [598, 735, 1553, 2645, 2132, 1830],\n",
       "  'scores': [0.6, 0.3, 0.3, 0.3, 0.3, 0.3],\n",
       "  'question_id': 524338001},\n",
       " {'image_id': 524338,\n",
       "  'labels': [1403],\n",
       "  'scores': [1],\n",
       "  'question_id': 524338002},\n",
       " {'image_id': 213863,\n",
       "  'labels': [1775],\n",
       "  'scores': [1],\n",
       "  'question_id': 213863000},\n",
       " {'image_id': 213863,\n",
       "  'labels': [2985],\n",
       "  'scores': [1],\n",
       "  'question_id': 213863001},\n",
       " {'image_id': 213863,\n",
       "  'labels': [2588, 1840, 1083],\n",
       "  'scores': [0.3, 1, 0.3],\n",
       "  'question_id': 213863002},\n",
       " {'image_id': 393268,\n",
       "  'labels': [411],\n",
       "  'scores': [1],\n",
       "  'question_id': 393268000},\n",
       " {'image_id': 393268,\n",
       "  'labels': [2984, 1388],\n",
       "  'scores': [0.3, 1],\n",
       "  'question_id': 393268001},\n",
       " {'image_id': 393268,\n",
       "  'labels': [745, 1420, 750, 1906, 823],\n",
       "  'scores': [0.3, 0.3, 0.3, 0.3, 0.3],\n",
       "  'question_id': 393268002},\n",
       " {'image_id': 131126,\n",
       "  'labels': [35, 1553, 586, 750, 2712],\n",
       "  'scores': [0.6, 0.3, 0.3, 0.3, 0.3],\n",
       "  'question_id': 131126000},\n",
       " {'image_id': 131126,\n",
       "  'labels': [2387, 383, 758, 2785],\n",
       "  'scores': [0.3, 0.9, 0.3, 0.6],\n",
       "  'question_id': 131126001},\n",
       " {'image_id': 131126,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [1, 1],\n",
       "  'question_id': 131126002},\n",
       " {'image_id': 131127,\n",
       "  'labels': [603],\n",
       "  'scores': [1],\n",
       "  'question_id': 131127000},\n",
       " {'image_id': 131127,\n",
       "  'labels': [1403],\n",
       "  'scores': [1],\n",
       "  'question_id': 131127001},\n",
       " {'image_id': 131127,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [0.9, 1],\n",
       "  'question_id': 131127002},\n",
       " {'image_id': 131128,\n",
       "  'labels': [1191, 759],\n",
       "  'scores': [1, 0.3],\n",
       "  'question_id': 131128000},\n",
       " {'image_id': 131128,\n",
       "  'labels': [1191, 1190],\n",
       "  'scores': [1, 0.3],\n",
       "  'question_id': 131128001},\n",
       " {'image_id': 131128,\n",
       "  'labels': [2621, 841, 1618],\n",
       "  'scores': [1, 0.3, 0.3],\n",
       "  'question_id': 131128002},\n",
       " {'image_id': 131128,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [0.3, 1],\n",
       "  'question_id': 131128003},\n",
       " {'image_id': 262201,\n",
       "  'labels': [2862, 751, 1288, 1319],\n",
       "  'scores': [0.3, 0.3, 0.3, 0.3],\n",
       "  'question_id': 262201000},\n",
       " {'image_id': 262201,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [0.3, 1],\n",
       "  'question_id': 262201001},\n",
       " {'image_id': 262201,\n",
       "  'labels': [1978, 2387, 2383],\n",
       "  'scores': [0.3, 1, 0.3],\n",
       "  'question_id': 262201002},\n",
       " {'image_id': 262201,\n",
       "  'labels': [1403],\n",
       "  'scores': [1],\n",
       "  'question_id': 262201003},\n",
       " {'image_id': 370986,\n",
       "  'labels': [2435, 433, 469],\n",
       "  'scores': [0.6, 0.6, 0.9],\n",
       "  'question_id': 370986000},\n",
       " {'image_id': 370986,\n",
       "  'labels': [2195, 2621, 841],\n",
       "  'scores': [0.3, 0.3, 1],\n",
       "  'question_id': 370986001},\n",
       " {'image_id': 370986,\n",
       "  'labels': [2621],\n",
       "  'scores': [1],\n",
       "  'question_id': 370986002},\n",
       " {'image_id': 262204,\n",
       "  'labels': [841],\n",
       "  'scores': [1],\n",
       "  'question_id': 262204000},\n",
       " {'image_id': 262204,\n",
       "  'labels': [825],\n",
       "  'scores': [1],\n",
       "  'question_id': 262204001},\n",
       " {'image_id': 262204,\n",
       "  'labels': [1880],\n",
       "  'scores': [1],\n",
       "  'question_id': 262204002},\n",
       " {'image_id': 131133,\n",
       "  'labels': [2241, 1491, 1333],\n",
       "  'scores': [1, 0.3, 0.9],\n",
       "  'question_id': 131133000},\n",
       " {'image_id': 131133,\n",
       "  'labels': [1209, 377, 2386, 583, 187],\n",
       "  'scores': [0.3, 0.9, 0.3, 0.3, 0.3],\n",
       "  'question_id': 131133001},\n",
       " {'image_id': 131133,\n",
       "  'labels': [425],\n",
       "  'scores': [1],\n",
       "  'question_id': 131133002},\n",
       " {'image_id': 262207,\n",
       "  'labels': [2594, 1880, 1892, 3090],\n",
       "  'scores': [0.6, 0.3, 0.6, 0.9],\n",
       "  'question_id': 262207000},\n",
       " {'image_id': 262207,\n",
       "  'labels': [425],\n",
       "  'scores': [1],\n",
       "  'question_id': 262207001},\n",
       " {'image_id': 262207,\n",
       "  'labels': [2325, 1177, 1408],\n",
       "  'scores': [1, 0.3, 0.6],\n",
       "  'question_id': 262207002},\n",
       " {'image_id': 262207,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [1, 1],\n",
       "  'question_id': 262207003},\n",
       " {'image_id': 64,\n",
       "  'labels': [1968, 806, 2152, 3000],\n",
       "  'scores': [0.3, 0.3, 1, 0.3],\n",
       "  'question_id': 64000},\n",
       " {'image_id': 64,\n",
       "  'labels': [425, 169, 1403],\n",
       "  'scores': [1, 0.3, 1],\n",
       "  'question_id': 64001},\n",
       " {'image_id': 64, 'labels': [425], 'scores': [1], 'question_id': 64002},\n",
       " {'image_id': 64, 'labels': [94], 'scores': [1], 'question_id': 64003},\n",
       " {'image_id': 64,\n",
       "  'labels': [244, 2009],\n",
       "  'scores': [0.3, 0.3],\n",
       "  'question_id': 64004},\n",
       " {'image_id': 458763,\n",
       "  'labels': [3026, 2534],\n",
       "  'scores': [1, 0.3],\n",
       "  'question_id': 458763000},\n",
       " {'image_id': 458763,\n",
       "  'labels': [2621],\n",
       "  'scores': [1],\n",
       "  'question_id': 458763001},\n",
       " {'image_id': 458763,\n",
       "  'labels': [2195, 444],\n",
       "  'scores': [1, 1],\n",
       "  'question_id': 458763002},\n",
       " {'image_id': 458763,\n",
       "  'labels': [411, 990],\n",
       "  'scores': [1, 0.3],\n",
       "  'question_id': 458763003},\n",
       " {'image_id': 458763,\n",
       "  'labels': [3010],\n",
       "  'scores': [1],\n",
       "  'question_id': 458763004},\n",
       " {'image_id': 458763,\n",
       "  'labels': [4, 1397, 1207],\n",
       "  'scores': [0.3, 1, 0.3],\n",
       "  'question_id': 458763005},\n",
       " {'image_id': 458763,\n",
       "  'labels': [1403],\n",
       "  'scores': [1],\n",
       "  'question_id': 458763006},\n",
       " {'image_id': 567990,\n",
       "  'labels': [2529, 2763],\n",
       "  'scores': [0.6, 1],\n",
       "  'question_id': 567990000},\n",
       " {'image_id': 567990,\n",
       "  'labels': [425],\n",
       "  'scores': [1],\n",
       "  'question_id': 567990001},\n",
       " {'image_id': 567990,\n",
       "  'labels': [1742, 2511],\n",
       "  'scores': [1, 0.3],\n",
       "  'question_id': 567990002},\n",
       " {'image_id': 567990,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [1, 0.3],\n",
       "  'question_id': 567990003},\n",
       " {'image_id': 393286,\n",
       "  'labels': [425],\n",
       "  'scores': [1],\n",
       "  'question_id': 393286000},\n",
       " {'image_id': 393286,\n",
       "  'labels': [1403],\n",
       "  'scores': [1],\n",
       "  'question_id': 393286001},\n",
       " {'image_id': 393286,\n",
       "  'labels': [2773, 2369],\n",
       "  'scores': [1, 0.3],\n",
       "  'question_id': 393286002},\n",
       " {'image_id': 71, 'labels': [425], 'scores': [1], 'question_id': 71000},\n",
       " {'image_id': 71, 'labels': [425], 'scores': [1], 'question_id': 71001},\n",
       " {'image_id': 71, 'labels': [223], 'scores': [0.3], 'question_id': 71002},\n",
       " {'image_id': 72,\n",
       "  'labels': [2621, 841],\n",
       "  'scores': [0.3, 1],\n",
       "  'question_id': 72000},\n",
       " {'image_id': 72,\n",
       "  'labels': [575, 841, 660],\n",
       "  'scores': [1, 0.3, 0.3],\n",
       "  'question_id': 72001},\n",
       " {'image_id': 72, 'labels': [425], 'scores': [1], 'question_id': 72002},\n",
       " {'image_id': 393228,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [1, 0.3],\n",
       "  'question_id': 393228000},\n",
       " {'image_id': 393228,\n",
       "  'labels': [1403],\n",
       "  'scores': [1],\n",
       "  'question_id': 393228001},\n",
       " {'image_id': 393228,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [1, 0.6],\n",
       "  'question_id': 393228002},\n",
       " {'image_id': 393290,\n",
       "  'labels': [2306, 2274],\n",
       "  'scores': [1, 0.3],\n",
       "  'question_id': 393290000},\n",
       " {'image_id': 393290,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [1, 1],\n",
       "  'question_id': 393290001},\n",
       " {'image_id': 393290,\n",
       "  'labels': [2063, 311, 1618],\n",
       "  'scores': [0.3, 1, 1],\n",
       "  'question_id': 393290002},\n",
       " {'image_id': 393291,\n",
       "  'labels': [2969, 2203, 1678, 2785],\n",
       "  'scores': [0.9, 0.3, 0.3, 0.6],\n",
       "  'question_id': 393291000},\n",
       " {'image_id': 393291,\n",
       "  'labels': [1540],\n",
       "  'scores': [1],\n",
       "  'question_id': 393291001},\n",
       " {'image_id': 393291,\n",
       "  'labels': [3006, 2661, 759, 775],\n",
       "  'scores': [1, 0.3, 0.6, 0.3],\n",
       "  'question_id': 393291002},\n",
       " {'image_id': 393291,\n",
       "  'labels': [652, 1108],\n",
       "  'scores': [1, 1],\n",
       "  'question_id': 393291003},\n",
       " {'image_id': 393291,\n",
       "  'labels': [2868, 2920, 1775],\n",
       "  'scores': [1, 0.3, 0.3],\n",
       "  'question_id': 393291004},\n",
       " {'image_id': 393291,\n",
       "  'labels': [1491, 2594, 3090],\n",
       "  'scores': [0.6, 1, 0.6],\n",
       "  'question_id': 393291005},\n",
       " {'image_id': 393291,\n",
       "  'labels': [425, 1403, 49],\n",
       "  'scores': [0.3, 1, 0.3],\n",
       "  'question_id': 393291006},\n",
       " {'image_id': 393291,\n",
       "  'labels': [444, 2621, 841],\n",
       "  'scores': [0.3, 1, 0.6],\n",
       "  'question_id': 393291007},\n",
       " {'image_id': 393292,\n",
       "  'labels': [1403],\n",
       "  'scores': [1],\n",
       "  'question_id': 393292000},\n",
       " {'image_id': 393292,\n",
       "  'labels': [425],\n",
       "  'scores': [1],\n",
       "  'question_id': 393292001},\n",
       " {'image_id': 393292,\n",
       "  'labels': [2195, 841],\n",
       "  'scores': [1, 1],\n",
       "  'question_id': 393292002},\n",
       " {'image_id': 262221,\n",
       "  'labels': [2588, 2285],\n",
       "  'scores': [0.3, 1],\n",
       "  'question_id': 262221000},\n",
       " {'image_id': 262221,\n",
       "  'labels': [694],\n",
       "  'scores': [1],\n",
       "  'question_id': 262221001},\n",
       " {'image_id': 262221,\n",
       "  'labels': [2195, 841],\n",
       "  'scores': [1, 0.3],\n",
       "  'question_id': 262221002},\n",
       " {'image_id': 78,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [0.6, 1],\n",
       "  'question_id': 78000},\n",
       " {'image_id': 78,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [1, 0.3],\n",
       "  'question_id': 78001},\n",
       " {'image_id': 78,\n",
       "  'labels': [1296, 2063, 2673],\n",
       "  'scores': [0.3, 0.3, 1],\n",
       "  'question_id': 78002},\n",
       " {'image_id': 81,\n",
       "  'labels': [425, 2621, 1403],\n",
       "  'scores': [0.6, 0.3, 1],\n",
       "  'question_id': 81000},\n",
       " {'image_id': 81,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [0.6, 1],\n",
       "  'question_id': 81001},\n",
       " {'image_id': 81,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [1, 1],\n",
       "  'question_id': 81002},\n",
       " {'image_id': 81, 'labels': [342], 'scores': [1], 'question_id': 81003},\n",
       " {'image_id': 81, 'labels': [425], 'scores': [1], 'question_id': 81004},\n",
       " {'image_id': 86,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [1, 1],\n",
       "  'question_id': 86000},\n",
       " {'image_id': 86, 'labels': [2038], 'scores': [1], 'question_id': 86001},\n",
       " {'image_id': 86,\n",
       "  'labels': [1434, 1769, 28],\n",
       "  'scores': [1, 0.3, 1],\n",
       "  'question_id': 86002},\n",
       " {'image_id': 524375,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [1, 0.6],\n",
       "  'question_id': 524375000},\n",
       " {'image_id': 524375,\n",
       "  'labels': [2681, 1549, 2174],\n",
       "  'scores': [0.3, 1, 0.3],\n",
       "  'question_id': 524375001},\n",
       " {'image_id': 524375,\n",
       "  'labels': [1034, 1820, 1029, 1001, 735],\n",
       "  'scores': [1, 0.6, 0.3, 0.3, 0.3],\n",
       "  'question_id': 524375002},\n",
       " {'image_id': 524375,\n",
       "  'labels': [1989, 2769, 1995, 444, 2621, 3031, 1239],\n",
       "  'scores': [0.6, 0.3, 0.3, 0.3, 0.3, 0.3, 0.6],\n",
       "  'question_id': 524375003},\n",
       " {'image_id': 524375,\n",
       "  'labels': [1712, 2831, 3088],\n",
       "  'scores': [0.3, 0.3, 0.6],\n",
       "  'question_id': 524375004},\n",
       " {'image_id': 524375,\n",
       "  'labels': [683],\n",
       "  'scores': [0.6],\n",
       "  'question_id': 524375005},\n",
       " {'image_id': 524375,\n",
       "  'labels': [425],\n",
       "  'scores': [1],\n",
       "  'question_id': 524375006},\n",
       " {'image_id': 524375,\n",
       "  'labels': [1403],\n",
       "  'scores': [1],\n",
       "  'question_id': 524375007},\n",
       " {'image_id': 131160,\n",
       "  'labels': [3006, 914, 730],\n",
       "  'scores': [1, 0.9, 0.3],\n",
       "  'question_id': 131160000},\n",
       " {'image_id': 131160,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [1, 0.6],\n",
       "  'question_id': 131160001},\n",
       " {'image_id': 131160,\n",
       "  'labels': [3115, 1562, 2412, 2807, 1113],\n",
       "  'scores': [0.3, 0.3, 0.9, 0.3, 0.3],\n",
       "  'question_id': 131160002},\n",
       " {'image_id': 524377,\n",
       "  'labels': [1934, 425],\n",
       "  'scores': [0.3, 0.3],\n",
       "  'question_id': 524377000},\n",
       " {'image_id': 524377,\n",
       "  'labels': [1403],\n",
       "  'scores': [1],\n",
       "  'question_id': 524377001},\n",
       " {'image_id': 524377,\n",
       "  'labels': [2195, 3023],\n",
       "  'scores': [1, 0.3],\n",
       "  'question_id': 524377002},\n",
       " {'image_id': 524377,\n",
       "  'labels': [425],\n",
       "  'scores': [1],\n",
       "  'question_id': 524377003},\n",
       " {'image_id': 524377,\n",
       "  'labels': [158],\n",
       "  'scores': [1],\n",
       "  'question_id': 524377004},\n",
       " {'image_id': 524377,\n",
       "  'labels': [19, 1861, 1915, 1084, 1208],\n",
       "  'scores': [0.3, 0.3, 0.3, 0.3, 0.3],\n",
       "  'question_id': 524377005},\n",
       " {'image_id': 524377,\n",
       "  'labels': [459, 611, 314],\n",
       "  'scores': [1, 0.6, 0.3],\n",
       "  'question_id': 524377006},\n",
       " {'image_id': 524377,\n",
       "  'labels': [1403],\n",
       "  'scores': [1],\n",
       "  'question_id': 524377007},\n",
       " {'image_id': 524377,\n",
       "  'labels': [1943, 1553, 534],\n",
       "  'scores': [1, 0.3, 0.3],\n",
       "  'question_id': 524377008},\n",
       " {'image_id': 524377,\n",
       "  'labels': [158, 1861, 625],\n",
       "  'scores': [1, 0.3, 0.3],\n",
       "  'question_id': 524377009},\n",
       " {'image_id': 524377,\n",
       "  'labels': [966, 2357, 518, 3091],\n",
       "  'scores': [0.3, 0.3, 0.9, 0.9],\n",
       "  'question_id': 524377010},\n",
       " {'image_id': 524377,\n",
       "  'labels': [1670, 966, 2346, 3091],\n",
       "  'scores': [0.3, 0.3, 0.6, 0.9],\n",
       "  'question_id': 524377011},\n",
       " {'image_id': 524377,\n",
       "  'labels': [1943, 2580, 106, 534, 1245],\n",
       "  'scores': [1, 0.3, 0.3, 0.9, 0.3],\n",
       "  'question_id': 524377012},\n",
       " {'image_id': 524377,\n",
       "  'labels': [1943],\n",
       "  'scores': [0.3],\n",
       "  'question_id': 524377013},\n",
       " {'image_id': 524377,\n",
       "  'labels': [518, 2346, 3091],\n",
       "  'scores': [0.3, 0.3, 1],\n",
       "  'question_id': 524377014},\n",
       " {'image_id': 524377,\n",
       "  'labels': [1403],\n",
       "  'scores': [1],\n",
       "  'question_id': 524377015},\n",
       " {'image_id': 524377,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [0.6, 1],\n",
       "  'question_id': 524377016},\n",
       " {'image_id': 524377,\n",
       "  'labels': [1433, 1076, 885, 261, 294],\n",
       "  'scores': [0.3, 1, 0.3, 0.3, 0.3],\n",
       "  'question_id': 524377017},\n",
       " {'image_id': 524377,\n",
       "  'labels': [2146, 2580],\n",
       "  'scores': [0.3, 0.3],\n",
       "  'question_id': 524377018},\n",
       " {'image_id': 524377,\n",
       "  'labels': [2195],\n",
       "  'scores': [1],\n",
       "  'question_id': 524377019},\n",
       " {'image_id': 524377,\n",
       "  'labels': [1943, 1245, 1951, 158, 2580, 1470, 534],\n",
       "  'scores': [0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.9],\n",
       "  'question_id': 524377020},\n",
       " {'image_id': 524377,\n",
       "  'labels': [3006],\n",
       "  'scores': [1],\n",
       "  'question_id': 524377021},\n",
       " {'image_id': 524377,\n",
       "  'labels': [444, 3031],\n",
       "  'scores': [1, 0.3],\n",
       "  'question_id': 524377022},\n",
       " {'image_id': 524377,\n",
       "  'labels': [1943, 1983, 534, 2796],\n",
       "  'scores': [1, 0.3, 0.6, 0.3],\n",
       "  'question_id': 524377023},\n",
       " {'image_id': 524377,\n",
       "  'labels': [2195],\n",
       "  'scores': [1],\n",
       "  'question_id': 524377024},\n",
       " {'image_id': 524377,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [0.3, 1],\n",
       "  'question_id': 524377025},\n",
       " {'image_id': 524377,\n",
       "  'labels': [19, 1354],\n",
       "  'scores': [0.3, 1],\n",
       "  'question_id': 524377026},\n",
       " {'image_id': 524377,\n",
       "  'labels': [2195],\n",
       "  'scores': [1],\n",
       "  'question_id': 524377027},\n",
       " {'image_id': 524377,\n",
       "  'labels': [1470, 1134, 3023],\n",
       "  'scores': [0.6, 0.6, 0.3],\n",
       "  'question_id': 524377028},\n",
       " {'image_id': 524377,\n",
       "  'labels': [523, 1218],\n",
       "  'scores': [0.6, 0.6],\n",
       "  'question_id': 524377029},\n",
       " {'image_id': 524377,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [1, 0.6],\n",
       "  'question_id': 524377030},\n",
       " {'image_id': 524377,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [0.9, 1],\n",
       "  'question_id': 524377031},\n",
       " {'image_id': 524377,\n",
       "  'labels': [1943, 2580, 106, 534],\n",
       "  'scores': [0.3, 1, 0.3, 0.9],\n",
       "  'question_id': 524377032},\n",
       " {'image_id': 524377,\n",
       "  'labels': [2861, 1487, 1951],\n",
       "  'scores': [1, 0.3, 0.3],\n",
       "  'question_id': 524377033},\n",
       " {'image_id': 524377,\n",
       "  'labels': [1861, 1403, 158, 2346, 3023],\n",
       "  'scores': [0.3, 0.3, 1, 0.3, 0.3],\n",
       "  'question_id': 524377034},\n",
       " {'image_id': 524377,\n",
       "  'labels': [158, 1861, 625],\n",
       "  'scores': [1, 1, 0.3],\n",
       "  'question_id': 524377035},\n",
       " {'image_id': 524377,\n",
       "  'labels': [1861, 158, 2346, 518, 3091, 1545],\n",
       "  'scores': [0.3, 1, 0.3, 0.3, 0.3, 0.3],\n",
       "  'question_id': 524377036},\n",
       " {'image_id': 524377,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [0.3, 1],\n",
       "  'question_id': 524377037},\n",
       " {'image_id': 524377,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [1, 1],\n",
       "  'question_id': 524377038},\n",
       " {'image_id': 524377,\n",
       "  'labels': [1403],\n",
       "  'scores': [1],\n",
       "  'question_id': 524377039},\n",
       " {'image_id': 524377,\n",
       "  'labels': [158, 1403, 1387, 1001, 2933],\n",
       "  'scores': [0.3, 0.3, 0.3, 0.3, 1],\n",
       "  'question_id': 524377040},\n",
       " {'image_id': 524377,\n",
       "  'labels': [1403],\n",
       "  'scores': [1],\n",
       "  'question_id': 524377041},\n",
       " {'image_id': 524377,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [1, 0.6],\n",
       "  'question_id': 524377042},\n",
       " {'image_id': 524377,\n",
       "  'labels': [1403],\n",
       "  'scores': [1],\n",
       "  'question_id': 524377043},\n",
       " {'image_id': 524377,\n",
       "  'labels': [425],\n",
       "  'scores': [1],\n",
       "  'question_id': 524377044},\n",
       " {'image_id': 524377,\n",
       "  'labels': [425],\n",
       "  'scores': [1],\n",
       "  'question_id': 524377045},\n",
       " {'image_id': 524377,\n",
       "  'labels': [518, 796, 3091],\n",
       "  'scores': [0.9, 0.3, 1],\n",
       "  'question_id': 524377046},\n",
       " {'image_id': 524377,\n",
       "  'labels': [2146, 949, 518],\n",
       "  'scores': [0.3, 0.3, 0.3],\n",
       "  'question_id': 524377047},\n",
       " {'image_id': 524377,\n",
       "  'labels': [1403],\n",
       "  'scores': [1],\n",
       "  'question_id': 524377048},\n",
       " {'image_id': 524377,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [1, 1],\n",
       "  'question_id': 524377049},\n",
       " {'image_id': 524377,\n",
       "  'labels': [1943, 421, 534, 2580, 419],\n",
       "  'scores': [1, 0.3, 0.3, 0.3, 0.9],\n",
       "  'question_id': 524377050},\n",
       " {'image_id': 524377,\n",
       "  'labels': [2195, 2621, 841],\n",
       "  'scores': [1, 0.3, 0.3],\n",
       "  'question_id': 524377051},\n",
       " {'image_id': 524377,\n",
       "  'labels': [1943, 2580, 534],\n",
       "  'scores': [0.9, 0.6, 0.9],\n",
       "  'question_id': 524377052},\n",
       " {'image_id': 524377,\n",
       "  'labels': [701, 1333, 2861],\n",
       "  'scores': [1, 0.3, 0.6],\n",
       "  'question_id': 524377053},\n",
       " {'image_id': 524377,\n",
       "  'labels': [158, 2346, 1084],\n",
       "  'scores': [1, 0.3, 0.3],\n",
       "  'question_id': 524377054},\n",
       " {'image_id': 393306,\n",
       "  'labels': [1403],\n",
       "  'scores': [1],\n",
       "  'question_id': 393306000},\n",
       " {'image_id': 393306,\n",
       "  'labels': [2613, 2883],\n",
       "  'scores': [1, 0.6],\n",
       "  'question_id': 393306001},\n",
       " {'image_id': 393306,\n",
       "  'labels': [2993, 2613],\n",
       "  'scores': [1, 0.3],\n",
       "  'question_id': 393306002},\n",
       " {'image_id': 393306,\n",
       "  'labels': [2387, 2785],\n",
       "  'scores': [0.3, 1],\n",
       "  'question_id': 393306003},\n",
       " {'image_id': 262159,\n",
       "  'labels': [1403],\n",
       "  'scores': [1],\n",
       "  'question_id': 262159000},\n",
       " {'image_id': 262159,\n",
       "  'labels': [425],\n",
       "  'scores': [1],\n",
       "  'question_id': 262159001},\n",
       " {'image_id': 262159,\n",
       "  'labels': [841],\n",
       "  'scores': [1],\n",
       "  'question_id': 262159002},\n",
       " {'image_id': 262159,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [1, 1],\n",
       "  'question_id': 262159003},\n",
       " {'image_id': 262159,\n",
       "  'labels': [1190, 1191, 3006, 990, 759],\n",
       "  'scores': [0.3, 0.3, 0.9, 0.3, 1],\n",
       "  'question_id': 262159004},\n",
       " {'image_id': 262159,\n",
       "  'labels': [1403],\n",
       "  'scores': [1],\n",
       "  'question_id': 262159005},\n",
       " {'image_id': 262159,\n",
       "  'labels': [3006, 990, 759],\n",
       "  'scores': [0.3, 0.3, 1],\n",
       "  'question_id': 262159006},\n",
       " {'image_id': 262159,\n",
       "  'labels': [1491, 1191, 759],\n",
       "  'scores': [0.3, 0.3, 1],\n",
       "  'question_id': 262159007},\n",
       " {'image_id': 262159,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [0.9, 1],\n",
       "  'question_id': 262159008},\n",
       " {'image_id': 262159,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [1, 0.3],\n",
       "  'question_id': 262159009},\n",
       " {'image_id': 262159,\n",
       "  'labels': [990, 759],\n",
       "  'scores': [0.3, 1],\n",
       "  'question_id': 262159010},\n",
       " {'image_id': 262159,\n",
       "  'labels': [2674, 1027, 2104, 2210],\n",
       "  'scores': [0.3, 0.6, 0.3, 0.6],\n",
       "  'question_id': 262159011},\n",
       " {'image_id': 262159,\n",
       "  'labels': [425],\n",
       "  'scores': [1],\n",
       "  'question_id': 262159012},\n",
       " {'image_id': 92,\n",
       "  'labels': [1989, 1994, 2195, 2621, 841, 311, 703, 2063],\n",
       "  'scores': [0.3, 0.3, 0.3, 0.3, 0.3, 0.9, 0.3, 0.3],\n",
       "  'question_id': 92000},\n",
       " {'image_id': 92, 'labels': [425], 'scores': [1], 'question_id': 92001},\n",
       " {'image_id': 92,\n",
       "  'labels': [2195, 2621],\n",
       "  'scores': [1, 0.3],\n",
       "  'question_id': 92002},\n",
       " {'image_id': 94,\n",
       "  'labels': [745, 1403, 713, 2274, 1643, 1726],\n",
       "  'scores': [0.3, 0.3, 0.3, 0.3, 0.3, 0.9],\n",
       "  'question_id': 94000},\n",
       " {'image_id': 94, 'labels': [], 'scores': [], 'question_id': 94001},\n",
       " {'image_id': 94, 'labels': [841], 'scores': [1], 'question_id': 94002},\n",
       " {'image_id': 94,\n",
       "  'labels': [1768, 1784, 2952],\n",
       "  'scores': [1, 0.3, 0.3],\n",
       "  'question_id': 94003},\n",
       " {'image_id': 94,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [1, 0.6],\n",
       "  'question_id': 94004},\n",
       " {'image_id': 393311,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [0.3, 1],\n",
       "  'question_id': 393311000},\n",
       " {'image_id': 393311,\n",
       "  'labels': [949],\n",
       "  'scores': [0.6],\n",
       "  'question_id': 393311001},\n",
       " {'image_id': 393311,\n",
       "  'labels': [602, 1422, 2250],\n",
       "  'scores': [0.6, 0.6, 0.6],\n",
       "  'question_id': 393311002},\n",
       " {'image_id': 393311,\n",
       "  'labels': [1764, 1862, 377],\n",
       "  'scores': [1, 0.3, 0.3],\n",
       "  'question_id': 393311003},\n",
       " {'image_id': 393311, 'labels': [], 'scores': [], 'question_id': 393311004},\n",
       " {'image_id': 393311, 'labels': [], 'scores': [], 'question_id': 393311005},\n",
       " {'image_id': 393311, 'labels': [], 'scores': [], 'question_id': 393311006},\n",
       " {'image_id': 393311,\n",
       "  'labels': [1764, 2459, 1448],\n",
       "  'scores': [0.6, 0.3, 0.3],\n",
       "  'question_id': 393311007},\n",
       " {'image_id': 393311,\n",
       "  'labels': [199, 2468],\n",
       "  'scores': [0.9, 1],\n",
       "  'question_id': 393311008},\n",
       " {'image_id': 524386,\n",
       "  'labels': [425],\n",
       "  'scores': [1],\n",
       "  'question_id': 524386000},\n",
       " {'image_id': 524386,\n",
       "  'labels': [1265, 2325, 1177, 2237, 3026, 1495],\n",
       "  'scores': [0.3, 0.6, 0.3, 0.3, 0.3, 0.3],\n",
       "  'question_id': 524386001},\n",
       " {'image_id': 524386,\n",
       "  'labels': [1403],\n",
       "  'scores': [1],\n",
       "  'question_id': 524386002},\n",
       " {'image_id': 524386,\n",
       "  'labels': [1403],\n",
       "  'scores': [1],\n",
       "  'question_id': 524386003},\n",
       " {'image_id': 524386,\n",
       "  'labels': [2621, 841],\n",
       "  'scores': [0.3, 1],\n",
       "  'question_id': 524386004},\n",
       " {'image_id': 524386,\n",
       "  'labels': [3057, 3017, 3059, 653],\n",
       "  'scores': [0.3, 1, 0.3, 0.3],\n",
       "  'question_id': 524386005},\n",
       " {'image_id': 524386,\n",
       "  'labels': [2562, 1108, 2541],\n",
       "  'scores': [0.6, 1, 0.3],\n",
       "  'question_id': 524386006},\n",
       " {'image_id': 524386,\n",
       "  'labels': [2621, 841],\n",
       "  'scores': [0.6, 1],\n",
       "  'question_id': 524386007},\n",
       " {'image_id': 524386,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [1, 1],\n",
       "  'question_id': 524386008},\n",
       " {'image_id': 524386,\n",
       "  'labels': [1970, 2391],\n",
       "  'scores': [0.3, 0.3],\n",
       "  'question_id': 524386009},\n",
       " {'image_id': 524386,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [0.3, 1],\n",
       "  'question_id': 524386010},\n",
       " {'image_id': 524386,\n",
       "  'labels': [1239],\n",
       "  'scores': [1],\n",
       "  'question_id': 524386011},\n",
       " {'image_id': 524386,\n",
       "  'labels': [1744, 2391, 1299],\n",
       "  'scores': [0.3, 0.3, 0.3],\n",
       "  'question_id': 524386012},\n",
       " {'image_id': 524386,\n",
       "  'labels': [2195],\n",
       "  'scores': [1],\n",
       "  'question_id': 524386013},\n",
       " {'image_id': 524386,\n",
       "  'labels': [1880, 3090],\n",
       "  'scores': [1, 0.3],\n",
       "  'question_id': 524386014},\n",
       " {'image_id': 524386,\n",
       "  'labels': [2621, 1239],\n",
       "  'scores': [1, 1],\n",
       "  'question_id': 524386015},\n",
       " {'image_id': 131172,\n",
       "  'labels': [2195, 841],\n",
       "  'scores': [1, 0.3],\n",
       "  'question_id': 131172000},\n",
       " {'image_id': 131172,\n",
       "  'labels': [2443, 2985],\n",
       "  'scores': [1, 0.6],\n",
       "  'question_id': 131172001},\n",
       " {'image_id': 131172,\n",
       "  'labels': [411, 1227],\n",
       "  'scores': [0.3, 1],\n",
       "  'question_id': 131172002},\n",
       " {'image_id': 131172,\n",
       "  'labels': [490, 2032, 707],\n",
       "  'scores': [0.3, 1, 0.3],\n",
       "  'question_id': 131172003},\n",
       " {'image_id': 393317,\n",
       "  'labels': [1429],\n",
       "  'scores': [0.6],\n",
       "  'question_id': 393317000},\n",
       " {'image_id': 393317,\n",
       "  'labels': [1049, 907, 1364, 2596],\n",
       "  'scores': [0.3, 1, 0.9, 0.3],\n",
       "  'question_id': 393317001},\n",
       " {'image_id': 393317,\n",
       "  'labels': [425],\n",
       "  'scores': [1],\n",
       "  'question_id': 393317002},\n",
       " {'image_id': 393317,\n",
       "  'labels': [2274],\n",
       "  'scores': [1],\n",
       "  'question_id': 393317003},\n",
       " {'image_id': 393317,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [0.9, 1],\n",
       "  'question_id': 393317004},\n",
       " {'image_id': 393317,\n",
       "  'labels': [503],\n",
       "  'scores': [1],\n",
       "  'question_id': 393317005},\n",
       " {'image_id': 393317,\n",
       "  'labels': [2596, 406, 1364, 3112, 907],\n",
       "  'scores': [0.3, 0.6, 0.3, 0.3, 1],\n",
       "  'question_id': 393317006},\n",
       " {'image_id': 393317,\n",
       "  'labels': [841],\n",
       "  'scores': [1],\n",
       "  'question_id': 393317007},\n",
       " {'image_id': 393317,\n",
       "  'labels': [1353],\n",
       "  'scores': [1],\n",
       "  'question_id': 393317008},\n",
       " {'image_id': 393317,\n",
       "  'labels': [425],\n",
       "  'scores': [1],\n",
       "  'question_id': 393317009},\n",
       " {'image_id': 393317,\n",
       "  'labels': [990],\n",
       "  'scores': [1],\n",
       "  'question_id': 393317010},\n",
       " {'image_id': 393317,\n",
       "  'labels': [2305, 3109, 1566],\n",
       "  'scores': [1, 1, 0.6],\n",
       "  'question_id': 393317011},\n",
       " {'image_id': 393317,\n",
       "  'labels': [306, 2435, 469, 433, 2904],\n",
       "  'scores': [0.3, 0.6, 0.3, 1, 0.3],\n",
       "  'question_id': 393317012},\n",
       " {'image_id': 393317,\n",
       "  'labels': [425],\n",
       "  'scores': [1],\n",
       "  'question_id': 393317013},\n",
       " {'image_id': 393317,\n",
       "  'labels': [2195],\n",
       "  'scores': [1],\n",
       "  'question_id': 393317014},\n",
       " {'image_id': 131174,\n",
       "  'labels': [3031, 1239],\n",
       "  'scores': [1, 0.9],\n",
       "  'question_id': 131174000},\n",
       " {'image_id': 131174,\n",
       "  'labels': [2195],\n",
       "  'scores': [1],\n",
       "  'question_id': 131174001},\n",
       " {'image_id': 131174,\n",
       "  'labels': [425],\n",
       "  'scores': [1],\n",
       "  'question_id': 131174002},\n",
       " {'image_id': 546151, 'labels': [], 'scores': [], 'question_id': 546151000},\n",
       " {'image_id': 546151,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [1, 0.3],\n",
       "  'question_id': 546151001},\n",
       " {'image_id': 546151,\n",
       "  'labels': [2195, 2621],\n",
       "  'scores': [1, 1],\n",
       "  'question_id': 546151002},\n",
       " {'image_id': 21826,\n",
       "  'labels': [2862, 1198, 1021, 2154],\n",
       "  'scores': [0.3, 1, 0.3, 0.9],\n",
       "  'question_id': 21826000},\n",
       " {'image_id': 21826, 'labels': [841], 'scores': [1], 'question_id': 21826001},\n",
       " {'image_id': 21826, 'labels': [1561], 'scores': [1], 'question_id': 21826002},\n",
       " {'image_id': 109,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [1, 1],\n",
       "  'question_id': 109000},\n",
       " {'image_id': 109,\n",
       "  'labels': [2195, 841],\n",
       "  'scores': [1, 0.3],\n",
       "  'question_id': 109001},\n",
       " {'image_id': 109,\n",
       "  'labels': [2621, 3031, 1239],\n",
       "  'scores': [0.6, 0.9, 1],\n",
       "  'question_id': 109002},\n",
       " {'image_id': 109,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [0.9, 1],\n",
       "  'question_id': 109003},\n",
       " {'image_id': 109,\n",
       "  'labels': [846, 1521, 1716, 2428, 2838],\n",
       "  'scores': [0.9, 0.3, 0.3, 1, 0.3],\n",
       "  'question_id': 109004},\n",
       " {'image_id': 109, 'labels': [425], 'scores': [1], 'question_id': 109005},\n",
       " {'image_id': 110,\n",
       "  'labels': [411, 1880, 1892, 2594],\n",
       "  'scores': [0.3, 1, 0.6, 0.6],\n",
       "  'question_id': 110000},\n",
       " {'image_id': 110, 'labels': [425], 'scores': [1], 'question_id': 110001},\n",
       " {'image_id': 110, 'labels': [1983], 'scores': [1], 'question_id': 110002},\n",
       " {'image_id': 305853,\n",
       "  'labels': [575, 1027, 103, 619],\n",
       "  'scores': [0.3, 0.3, 0.9, 0.3],\n",
       "  'question_id': 305853000},\n",
       " {'image_id': 305853,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [1, 0.3],\n",
       "  'question_id': 305853001},\n",
       " {'image_id': 305853,\n",
       "  'labels': [1064],\n",
       "  'scores': [1],\n",
       "  'question_id': 305853002},\n",
       " {'image_id': 305853,\n",
       "  'labels': [351, 1187, 1428, 668, 63, 3059],\n",
       "  'scores': [0.3, 0.3, 0.3, 0.6, 0.3, 0.3],\n",
       "  'question_id': 305853003},\n",
       " {'image_id': 113,\n",
       "  'labels': [2621, 841],\n",
       "  'scores': [1, 0.3],\n",
       "  'question_id': 113000},\n",
       " {'image_id': 113, 'labels': [411], 'scores': [1], 'question_id': 113001},\n",
       " {'image_id': 113,\n",
       "  'labels': [2314, 2563],\n",
       "  'scores': [1, 1],\n",
       "  'question_id': 113002},\n",
       " {'image_id': 113,\n",
       "  'labels': [2859, 741, 2563, 750, 3103, 590],\n",
       "  'scores': [0.3, 0.3, 0.3, 0.3, 0.6, 0.3],\n",
       "  'question_id': 113003},\n",
       " {'image_id': 113,\n",
       "  'labels': [1557, 1184],\n",
       "  'scores': [1, 1],\n",
       "  'question_id': 113004},\n",
       " {'image_id': 113, 'labels': [425], 'scores': [1], 'question_id': 113005},\n",
       " {'image_id': 113, 'labels': [1403], 'scores': [1], 'question_id': 113006},\n",
       " {'image_id': 113,\n",
       "  'labels': [1564, 1553, 1929, 1798],\n",
       "  'scores': [0.3, 0.3, 0.3, 0.3],\n",
       "  'question_id': 113007},\n",
       " {'image_id': 262260,\n",
       "  'labels': [2145, 668, 675, 1043],\n",
       "  'scores': [0.3, 0.3, 0.3, 0.3],\n",
       "  'question_id': 262260000},\n",
       " {'image_id': 262260,\n",
       "  'labels': [311, 1618],\n",
       "  'scores': [0.3, 1],\n",
       "  'question_id': 262260001},\n",
       " {'image_id': 262260,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [1, 0.9],\n",
       "  'question_id': 262260002},\n",
       " {'image_id': 262261,\n",
       "  'labels': [484],\n",
       "  'scores': [1],\n",
       "  'question_id': 262261000},\n",
       " {'image_id': 262261,\n",
       "  'labels': [1677, 605, 416, 2329],\n",
       "  'scores': [1, 0.3, 0.9, 0.6],\n",
       "  'question_id': 262261001},\n",
       " {'image_id': 262261,\n",
       "  'labels': [425],\n",
       "  'scores': [1],\n",
       "  'question_id': 262261002},\n",
       " {'image_id': 131190,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [1, 0.9],\n",
       "  'question_id': 131190000},\n",
       " {'image_id': 131190,\n",
       "  'labels': [1403],\n",
       "  'scores': [1],\n",
       "  'question_id': 131190001},\n",
       " {'image_id': 131190,\n",
       "  'labels': [425],\n",
       "  'scores': [1],\n",
       "  'question_id': 131190002},\n",
       " {'image_id': 131190,\n",
       "  'labels': [1333],\n",
       "  'scores': [1],\n",
       "  'question_id': 131190003},\n",
       " {'image_id': 131190,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [1, 1],\n",
       "  'question_id': 131190004},\n",
       " {'image_id': 131190,\n",
       "  'labels': [1405, 735, 2132, 1207, 2368, 990],\n",
       "  'scores': [0.6, 0.3, 0.3, 0.3, 0.3, 0.6],\n",
       "  'question_id': 131190005},\n",
       " {'image_id': 131190,\n",
       "  'labels': [1403],\n",
       "  'scores': [1],\n",
       "  'question_id': 131190006},\n",
       " {'image_id': 131190,\n",
       "  'labels': [425],\n",
       "  'scores': [1],\n",
       "  'question_id': 131190007},\n",
       " {'image_id': 131190,\n",
       "  'labels': [704, 1649, 3010, 399, 2739, 3006],\n",
       "  'scores': [0.6, 0.3, 0.9, 0.3, 0.3, 0.3],\n",
       "  'question_id': 131190008},\n",
       " {'image_id': 131190,\n",
       "  'labels': [2489, 1204, 3006, 2064, 1333],\n",
       "  'scores': [0.3, 0.3, 0.3, 0.3, 1],\n",
       "  'question_id': 131190009},\n",
       " {'image_id': 131190,\n",
       "  'labels': [2195],\n",
       "  'scores': [1],\n",
       "  'question_id': 131190010},\n",
       " {'image_id': 131190,\n",
       "  'labels': [98, 1076, 1927, 2679],\n",
       "  'scores': [0.3, 0.3, 0.3, 0.3],\n",
       "  'question_id': 131190011},\n",
       " {'image_id': 131190,\n",
       "  'labels': [2211, 2018, 1208, 860],\n",
       "  'scores': [0.3, 1, 0.6, 0.3],\n",
       "  'question_id': 131190012},\n",
       " {'image_id': 131190,\n",
       "  'labels': [2195],\n",
       "  'scores': [1],\n",
       "  'question_id': 131190013},\n",
       " {'image_id': 131190,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [1, 1],\n",
       "  'question_id': 131190014},\n",
       " {'image_id': 131190,\n",
       "  'labels': [425, 187, 1403],\n",
       "  'scores': [0.3, 0.3, 1],\n",
       "  'question_id': 131190015},\n",
       " {'image_id': 131190,\n",
       "  'labels': [123, 94, 674, 2595, 2274],\n",
       "  'scores': [0.3, 0.6, 0.6, 0.3, 0.6],\n",
       "  'question_id': 131190016},\n",
       " {'image_id': 131190,\n",
       "  'labels': [1403],\n",
       "  'scores': [1],\n",
       "  'question_id': 131190017},\n",
       " {'image_id': 131190,\n",
       "  'labels': [3006, 2697],\n",
       "  'scores': [1, 0.3],\n",
       "  'question_id': 131190018},\n",
       " {'image_id': 131190,\n",
       "  'labels': [3054, 2639, 1095],\n",
       "  'scores': [0.3, 0.3, 1],\n",
       "  'question_id': 131190019},\n",
       " {'image_id': 131190,\n",
       "  'labels': [2264, 2638, 575, 660, 2858],\n",
       "  'scores': [0.3, 1, 0.3, 0.9, 0.3],\n",
       "  'question_id': 131190020},\n",
       " {'image_id': 131190,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [1, 1],\n",
       "  'question_id': 131190021},\n",
       " {'image_id': 131190,\n",
       "  'labels': [444],\n",
       "  'scores': [1],\n",
       "  'question_id': 131190022},\n",
       " {'image_id': 131190,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [0.9, 1],\n",
       "  'question_id': 131190023},\n",
       " {'image_id': 131190,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [0.6, 1],\n",
       "  'question_id': 131190024},\n",
       " {'image_id': 131190,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [0.6, 1],\n",
       "  'question_id': 131190025},\n",
       " {'image_id': 131190,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [1, 0.9],\n",
       "  'question_id': 131190026},\n",
       " {'image_id': 131190,\n",
       "  'labels': [1403],\n",
       "  'scores': [1],\n",
       "  'question_id': 131190027},\n",
       " {'image_id': 131190,\n",
       "  'labels': [3031, 1239, 311, 1618],\n",
       "  'scores': [1, 0.6, 0.3, 0.9],\n",
       "  'question_id': 131190028},\n",
       " {'image_id': 131190,\n",
       "  'labels': [3031, 1239, 1618],\n",
       "  'scores': [0.6, 1, 1],\n",
       "  'question_id': 131190029},\n",
       " {'image_id': 131190,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [1, 1],\n",
       "  'question_id': 131190030},\n",
       " {'image_id': 131197,\n",
       "  'labels': [2177],\n",
       "  'scores': [0.6],\n",
       "  'question_id': 131197000},\n",
       " {'image_id': 131197, 'labels': [27], 'scores': [1], 'question_id': 131197001},\n",
       " {'image_id': 131197,\n",
       "  'labels': [821, 2140, 27, 2274],\n",
       "  'scores': [0.6, 0.3, 1, 0.3],\n",
       "  'question_id': 131197002},\n",
       " {'image_id': 131197,\n",
       "  'labels': [841],\n",
       "  'scores': [1],\n",
       "  'question_id': 131197003},\n",
       " {'image_id': 131197,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [1, 1],\n",
       "  'question_id': 131197004},\n",
       " {'image_id': 127,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [1, 0.3],\n",
       "  'question_id': 127000},\n",
       " {'image_id': 127, 'labels': [3006], 'scores': [1], 'question_id': 127001},\n",
       " {'image_id': 127, 'labels': [484], 'scores': [0.6], 'question_id': 127002},\n",
       " {'image_id': 262273,\n",
       "  'labels': [759, 2208],\n",
       "  'scores': [1, 0.3],\n",
       "  'question_id': 262273000},\n",
       " {'image_id': 262273,\n",
       "  'labels': [425],\n",
       "  'scores': [1],\n",
       "  'question_id': 262273001},\n",
       " {'image_id': 262273,\n",
       "  'labels': [707, 1429, 1008, 2806],\n",
       "  'scores': [0.3, 0.3, 1, 0.3],\n",
       "  'question_id': 262273002},\n",
       " {'image_id': 262273,\n",
       "  'labels': [1227, 1713],\n",
       "  'scores': [1, 0.3],\n",
       "  'question_id': 262273003},\n",
       " {'image_id': 262273,\n",
       "  'labels': [696, 2868, 425],\n",
       "  'scores': [1, 0.9, 0.3],\n",
       "  'question_id': 262273004},\n",
       " {'image_id': 262273,\n",
       "  'labels': [2195],\n",
       "  'scores': [1],\n",
       "  'question_id': 262273005},\n",
       " {'image_id': 262273,\n",
       "  'labels': [1403],\n",
       "  'scores': [1],\n",
       "  'question_id': 262273006},\n",
       " {'image_id': 262273,\n",
       "  'labels': [1138, 1227],\n",
       "  'scores': [0.3, 1],\n",
       "  'question_id': 262273007},\n",
       " {'image_id': 262273,\n",
       "  'labels': [2195],\n",
       "  'scores': [1],\n",
       "  'question_id': 262273008},\n",
       " {'image_id': 524420,\n",
       "  'labels': [1227],\n",
       "  'scores': [1],\n",
       "  'question_id': 524420000},\n",
       " {'image_id': 524420,\n",
       "  'labels': [425],\n",
       "  'scores': [1],\n",
       "  'question_id': 524420001},\n",
       " {'image_id': 524420,\n",
       "  'labels': [425],\n",
       "  'scores': [1],\n",
       "  'question_id': 524420002},\n",
       " {'image_id': 524420,\n",
       "  'labels': [425],\n",
       "  'scores': [1],\n",
       "  'question_id': 524420003},\n",
       " {'image_id': 524420,\n",
       "  'labels': [1954],\n",
       "  'scores': [1],\n",
       "  'question_id': 524420004},\n",
       " {'image_id': 436929,\n",
       "  'labels': [36, 280, 1395, 2984, 808, 2274],\n",
       "  'scores': [0.3, 0.6, 1, 0.3, 0.3, 0.3],\n",
       "  'question_id': 436929000},\n",
       " {'image_id': 436929,\n",
       "  'labels': [1403],\n",
       "  'scores': [1],\n",
       "  'question_id': 436929001},\n",
       " {'image_id': 436929,\n",
       "  'labels': [2621, 841],\n",
       "  'scores': [1, 0.3],\n",
       "  'question_id': 436929002},\n",
       " {'image_id': 436929,\n",
       "  'labels': [425, 2621, 1403],\n",
       "  'scores': [1, 0.3, 0.3],\n",
       "  'question_id': 436929003},\n",
       " {'image_id': 436929,\n",
       "  'labels': [1403],\n",
       "  'scores': [1],\n",
       "  'question_id': 436929004},\n",
       " {'image_id': 436929,\n",
       "  'labels': [425],\n",
       "  'scores': [1],\n",
       "  'question_id': 436929005},\n",
       " {'image_id': 436929,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [1, 1],\n",
       "  'question_id': 436929006},\n",
       " {'image_id': 131208,\n",
       "  'labels': [1874, 2640, 425],\n",
       "  'scores': [0.3, 0.3, 0.3],\n",
       "  'question_id': 131208000},\n",
       " {'image_id': 131208,\n",
       "  'labels': [425],\n",
       "  'scores': [1],\n",
       "  'question_id': 131208001},\n",
       " {'image_id': 131208,\n",
       "  'labels': [1204, 1491, 1333],\n",
       "  'scores': [0.3, 0.3, 1],\n",
       "  'question_id': 131208002},\n",
       " {'image_id': 284012,\n",
       "  'labels': [2069],\n",
       "  'scores': [1],\n",
       "  'question_id': 284012000},\n",
       " {'image_id': 284012,\n",
       "  'labels': [425],\n",
       "  'scores': [1],\n",
       "  'question_id': 284012001},\n",
       " {'image_id': 284012, 'labels': [], 'scores': [], 'question_id': 284012002},\n",
       " {'image_id': 284012,\n",
       "  'labels': [1433, 788, 1366, 933],\n",
       "  'scores': [0.9, 0.3, 0.3, 0.6],\n",
       "  'question_id': 284012003},\n",
       " {'image_id': 284012,\n",
       "  'labels': [1390, 3031, 1239, 1618],\n",
       "  'scores': [0.3, 1, 0.6, 0.3],\n",
       "  'question_id': 284012004},\n",
       " {'image_id': 284012,\n",
       "  'labels': [2638, 190],\n",
       "  'scores': [0.6, 0.6],\n",
       "  'question_id': 284012005},\n",
       " {'image_id': 284012,\n",
       "  'labels': [1880, 3006],\n",
       "  'scores': [1, 0.3],\n",
       "  'question_id': 284012006},\n",
       " {'image_id': 138, 'labels': [841], 'scores': [1], 'question_id': 138000},\n",
       " {'image_id': 138,\n",
       "  'labels': [945, 146, 148, 1846],\n",
       "  'scores': [0.3, 0.3, 1, 0.3],\n",
       "  'question_id': 138001},\n",
       " {'image_id': 138,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [0.6, 1],\n",
       "  'question_id': 138002},\n",
       " {'image_id': 262283,\n",
       "  'labels': [1013, 1204],\n",
       "  'scores': [1, 0.6],\n",
       "  'question_id': 262283000},\n",
       " {'image_id': 262283,\n",
       "  'labels': [425],\n",
       "  'scores': [1],\n",
       "  'question_id': 262283001},\n",
       " {'image_id': 262283, 'labels': [], 'scores': [], 'question_id': 262283002},\n",
       " {'image_id': 262283,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [1, 1],\n",
       "  'question_id': 262283003},\n",
       " {'image_id': 524428,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [1, 1],\n",
       "  'question_id': 524428000},\n",
       " {'image_id': 524428,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [0.9, 1],\n",
       "  'question_id': 524428001},\n",
       " {'image_id': 524428,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [1, 1],\n",
       "  'question_id': 524428002},\n",
       " {'image_id': 524428,\n",
       "  'labels': [1880, 3006],\n",
       "  'scores': [1, 0.3],\n",
       "  'question_id': 524428003},\n",
       " {'image_id': 262285,\n",
       "  'labels': [1989, 1990, 2769, 1992, 311, 703, 2063],\n",
       "  'scores': [0.3, 0.6, 0.3, 0.6, 0.6, 0.3, 0.3],\n",
       "  'question_id': 262285000},\n",
       " {'image_id': 262285,\n",
       "  'labels': [492],\n",
       "  'scores': [1],\n",
       "  'question_id': 262285001},\n",
       " {'image_id': 262285,\n",
       "  'labels': [1418, 17, 783, 1403],\n",
       "  'scores': [0.3, 0.3, 0.3, 1],\n",
       "  'question_id': 262285002},\n",
       " {'image_id': 262285,\n",
       "  'labels': [1403],\n",
       "  'scores': [1],\n",
       "  'question_id': 262285003},\n",
       " {'image_id': 262285,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [1, 1],\n",
       "  'question_id': 262285004},\n",
       " {'image_id': 142,\n",
       "  'labels': [1831, 960],\n",
       "  'scores': [1, 0.6],\n",
       "  'question_id': 142000},\n",
       " {'image_id': 142,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [1, 1],\n",
       "  'question_id': 142001},\n",
       " {'image_id': 142,\n",
       "  'labels': [411, 337],\n",
       "  'scores': [1, 0.6],\n",
       "  'question_id': 142002},\n",
       " {'image_id': 131215,\n",
       "  'labels': [1403],\n",
       "  'scores': [1],\n",
       "  'question_id': 131215000},\n",
       " {'image_id': 131215,\n",
       "  'labels': [425],\n",
       "  'scores': [1],\n",
       "  'question_id': 131215001},\n",
       " {'image_id': 131215,\n",
       "  'labels': [425],\n",
       "  'scores': [1],\n",
       "  'question_id': 131215002},\n",
       " {'image_id': 131215,\n",
       "  'labels': [606, 2711, 2449],\n",
       "  'scores': [1, 0.3, 0.6],\n",
       "  'question_id': 131215003},\n",
       " {'image_id': 131215,\n",
       "  'labels': [1302, 82, 563, 456],\n",
       "  'scores': [0.3, 0.3, 1, 0.3],\n",
       "  'question_id': 131215004},\n",
       " {'image_id': 144,\n",
       "  'labels': [2483, 1477, 2681, 1549, 2321],\n",
       "  'scores': [0.3, 0.3, 1, 0.3, 0.3],\n",
       "  'question_id': 144000},\n",
       " {'image_id': 144,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [1, 0.3],\n",
       "  'question_id': 144001},\n",
       " {'image_id': 144,\n",
       "  'labels': [991, 218],\n",
       "  'scores': [1, 0.3],\n",
       "  'question_id': 144002},\n",
       " {'image_id': 393362,\n",
       "  'labels': [425],\n",
       "  'scores': [1],\n",
       "  'question_id': 393362000},\n",
       " {'image_id': 393362,\n",
       "  'labels': [425],\n",
       "  'scores': [1],\n",
       "  'question_id': 393362001},\n",
       " {'image_id': 393362,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [1, 0.9],\n",
       "  'question_id': 393362002},\n",
       " {'image_id': 149, 'labels': [425], 'scores': [1], 'question_id': 149000},\n",
       " {'image_id': 149,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [0.9, 1],\n",
       "  'question_id': 149001},\n",
       " {'image_id': 149,\n",
       "  'labels': [2594, 1333],\n",
       "  'scores': [0.9, 1],\n",
       "  'question_id': 149002},\n",
       " {'image_id': 149, 'labels': [425], 'scores': [1], 'question_id': 149003},\n",
       " {'image_id': 149,\n",
       "  'labels': [444, 1403, 2785],\n",
       "  'scores': [1, 0.3, 0.3],\n",
       "  'question_id': 149004},\n",
       " {'image_id': 149,\n",
       "  'labels': [1537, 680, 436],\n",
       "  'scores': [0.6, 1, 0.6],\n",
       "  'question_id': 149005},\n",
       " {'image_id': 471373,\n",
       "  'labels': [1403],\n",
       "  'scores': [1],\n",
       "  'question_id': 471373000},\n",
       " {'image_id': 471373,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [0.9, 1],\n",
       "  'question_id': 471373001},\n",
       " {'image_id': 471373,\n",
       "  'labels': [1403],\n",
       "  'scores': [1],\n",
       "  'question_id': 471373002},\n",
       " {'image_id': 471373,\n",
       "  'labels': [425],\n",
       "  'scores': [1],\n",
       "  'question_id': 471373003},\n",
       " {'image_id': 471373,\n",
       "  'labels': [689],\n",
       "  'scores': [1],\n",
       "  'question_id': 471373004},\n",
       " {'image_id': 109986,\n",
       "  'labels': [1333],\n",
       "  'scores': [1],\n",
       "  'question_id': 109986000},\n",
       " {'image_id': 109986,\n",
       "  'labels': [2594, 1333],\n",
       "  'scores': [0.3, 1],\n",
       "  'question_id': 109986001},\n",
       " {'image_id': 109986,\n",
       "  'labels': [1333],\n",
       "  'scores': [1],\n",
       "  'question_id': 109986002},\n",
       " {'image_id': 131225, 'labels': [], 'scores': [], 'question_id': 131225000},\n",
       " {'image_id': 131225,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [0.3, 1],\n",
       "  'question_id': 131225001},\n",
       " {'image_id': 131225,\n",
       "  'labels': [411, 1427],\n",
       "  'scores': [0.3, 0.6],\n",
       "  'question_id': 131225002},\n",
       " {'image_id': 131225,\n",
       "  'labels': [735, 1403],\n",
       "  'scores': [0.3, 1],\n",
       "  'question_id': 131225003},\n",
       " {'image_id': 131225,\n",
       "  'labels': [1427, 1498],\n",
       "  'scores': [1, 0.6],\n",
       "  'question_id': 131225004},\n",
       " {'image_id': 131225,\n",
       "  'labels': [425],\n",
       "  'scores': [1],\n",
       "  'question_id': 131225005},\n",
       " {'image_id': 154,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [0.6, 1],\n",
       "  'question_id': 154000},\n",
       " {'image_id': 154,\n",
       "  'labels': [2195, 2621, 841],\n",
       "  'scores': [0.9, 1, 0.3],\n",
       "  'question_id': 154001},\n",
       " {'image_id': 154, 'labels': [2195], 'scores': [1], 'question_id': 154002},\n",
       " {'image_id': 154,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [0.6, 1],\n",
       "  'question_id': 154003},\n",
       " {'image_id': 154, 'labels': [2195], 'scores': [1], 'question_id': 154004},\n",
       " {'image_id': 154,\n",
       "  'labels': [2383, 2387, 383, 66],\n",
       "  'scores': [0.6, 1, 0.3, 0.3],\n",
       "  'question_id': 154005},\n",
       " {'image_id': 154, 'labels': [425], 'scores': [1], 'question_id': 154006},\n",
       " {'image_id': 154,\n",
       "  'labels': [1594, 1954],\n",
       "  'scores': [0.6, 1],\n",
       "  'question_id': 154007},\n",
       " {'image_id': 154,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [0.6, 1],\n",
       "  'question_id': 154008},\n",
       " {'image_id': 154, 'labels': [2621], 'scores': [1], 'question_id': 154009},\n",
       " {'image_id': 154, 'labels': [1403], 'scores': [1], 'question_id': 154010},\n",
       " {'image_id': 154,\n",
       "  'labels': [550, 783, 1418],\n",
       "  'scores': [0.3, 1, 0.6],\n",
       "  'question_id': 154011},\n",
       " {'image_id': 154, 'labels': [2621], 'scores': [1], 'question_id': 154012},\n",
       " {'image_id': 262299,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [0.3, 1],\n",
       "  'question_id': 262299000},\n",
       " {'image_id': 262299,\n",
       "  'labels': [759],\n",
       "  'scores': [1],\n",
       "  'question_id': 262299001},\n",
       " {'image_id': 262299,\n",
       "  'labels': [759],\n",
       "  'scores': [1],\n",
       "  'question_id': 262299002},\n",
       " {'image_id': 393242,\n",
       "  'labels': [2195, 2621, 841],\n",
       "  'scores': [1, 0.3, 0.3],\n",
       "  'question_id': 393242000},\n",
       " {'image_id': 393242,\n",
       "  'labels': [3031],\n",
       "  'scores': [1],\n",
       "  'question_id': 393242001},\n",
       " {'image_id': 393242,\n",
       "  'labels': [1403],\n",
       "  'scores': [1],\n",
       "  'question_id': 393242002},\n",
       " {'image_id': 393375,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [0.3, 1],\n",
       "  'question_id': 393375000},\n",
       " {'image_id': 393375,\n",
       "  'labels': [19, 2396],\n",
       "  'scores': [1, 1],\n",
       "  'question_id': 393375001},\n",
       " {'image_id': 393375,\n",
       "  'labels': [1824],\n",
       "  'scores': [1],\n",
       "  'question_id': 393375002},\n",
       " {'image_id': 393375, 'labels': [], 'scores': [], 'question_id': 393375003},\n",
       " {'image_id': 393379,\n",
       "  'labels': [2649],\n",
       "  'scores': [0.3],\n",
       "  'question_id': 393379000},\n",
       " {'image_id': 393379,\n",
       "  'labels': [2529],\n",
       "  'scores': [1],\n",
       "  'question_id': 393379001},\n",
       " {'image_id': 393379,\n",
       "  'labels': [1403],\n",
       "  'scores': [0.9],\n",
       "  'question_id': 393379002},\n",
       " {'image_id': 262308,\n",
       "  'labels': [411, 3110, 2505, 1250, 755, 3006],\n",
       "  'scores': [0.3, 0.6, 0.3, 0.3, 0.3, 0.3],\n",
       "  'question_id': 262308000},\n",
       " {'image_id': 262308,\n",
       "  'labels': [1403],\n",
       "  'scores': [1],\n",
       "  'question_id': 262308001},\n",
       " {'image_id': 262308,\n",
       "  'labels': [425],\n",
       "  'scores': [1],\n",
       "  'question_id': 262308002},\n",
       " {'image_id': 262308,\n",
       "  'labels': [1080, 1944, 2751],\n",
       "  'scores': [1, 0.3, 0.3],\n",
       "  'question_id': 262308003},\n",
       " {'image_id': 262308,\n",
       "  'labels': [3110, 3006, 1414],\n",
       "  'scores': [1, 0.3, 0.6],\n",
       "  'question_id': 262308004},\n",
       " {'image_id': 165, 'labels': [2903], 'scores': [0.6], 'question_id': 165000},\n",
       " {'image_id': 165, 'labels': [425], 'scores': [1], 'question_id': 165001},\n",
       " {'image_id': 165, 'labels': [425], 'scores': [1], 'question_id': 165002},\n",
       " {'image_id': 415089,\n",
       "  'labels': [2621, 841],\n",
       "  'scores': [1, 0.9],\n",
       "  'question_id': 415089000},\n",
       " {'image_id': 415089,\n",
       "  'labels': [2195, 444, 2621, 841],\n",
       "  'scores': [1, 0.3, 0.9, 0.3],\n",
       "  'question_id': 415089001},\n",
       " {'image_id': 415089,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [1, 1],\n",
       "  'question_id': 415089002},\n",
       " {'image_id': 415089,\n",
       "  'labels': [2811, 275],\n",
       "  'scores': [0.3, 1],\n",
       "  'question_id': 415089003},\n",
       " {'image_id': 415089,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [0.6, 1],\n",
       "  'question_id': 415089004},\n",
       " {'image_id': 393384,\n",
       "  'labels': [2056, 2608, 1805, 1725, 2838],\n",
       "  'scores': [0.3, 1, 0.3, 0.3, 0.3],\n",
       "  'question_id': 393384000},\n",
       " {'image_id': 393384,\n",
       "  'labels': [444, 2621, 841, 1239, 1618],\n",
       "  'scores': [0.3, 1, 0.9, 0.3, 0.3],\n",
       "  'question_id': 393384001},\n",
       " {'image_id': 393384,\n",
       "  'labels': [1403],\n",
       "  'scores': [1],\n",
       "  'question_id': 393384002},\n",
       " {'image_id': 393386,\n",
       "  'labels': [3031, 1239],\n",
       "  'scores': [1, 0.6],\n",
       "  'question_id': 393386000},\n",
       " {'image_id': 393386,\n",
       "  'labels': [2594, 1227],\n",
       "  'scores': [0.3, 1],\n",
       "  'question_id': 393386001},\n",
       " {'image_id': 393386,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [0.3, 1],\n",
       "  'question_id': 393386002},\n",
       " {'image_id': 131245,\n",
       "  'labels': [1820, 1001],\n",
       "  'scores': [1, 0.6],\n",
       "  'question_id': 131245000},\n",
       " {'image_id': 131245,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [0.3, 1],\n",
       "  'question_id': 131245001},\n",
       " {'image_id': 131245,\n",
       "  'labels': [595],\n",
       "  'scores': [1],\n",
       "  'question_id': 131245002},\n",
       " {'image_id': 137918,\n",
       "  'labels': [425],\n",
       "  'scores': [1],\n",
       "  'question_id': 137918000},\n",
       " {'image_id': 137918,\n",
       "  'labels': [2621],\n",
       "  'scores': [1],\n",
       "  'question_id': 137918001},\n",
       " {'image_id': 137918,\n",
       "  'labels': [3026, 1309],\n",
       "  'scores': [0.6, 1],\n",
       "  'question_id': 137918002},\n",
       " {'image_id': 393394, 'labels': [36], 'scores': [1], 'question_id': 393394000},\n",
       " {'image_id': 393394,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [1, 0.6],\n",
       "  'question_id': 393394001},\n",
       " {'image_id': 393394,\n",
       "  'labels': [254, 1678, 2287, 1309, 3026],\n",
       "  'scores': [0.3, 0.3, 0.9, 0.3, 0.3],\n",
       "  'question_id': 393394002},\n",
       " {'image_id': 393394,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [1, 0.3],\n",
       "  'question_id': 393394003},\n",
       " {'image_id': 438196,\n",
       "  'labels': [425],\n",
       "  'scores': [1],\n",
       "  'question_id': 438196000},\n",
       " {'image_id': 438196,\n",
       "  'labels': [425],\n",
       "  'scores': [1],\n",
       "  'question_id': 438196001},\n",
       " {'image_id': 438196,\n",
       "  'labels': [1598, 2172, 2174, 2269, 2170, 1805],\n",
       "  'scores': [0.3, 0.3, 0.6, 0.3, 0.3, 0.6],\n",
       "  'question_id': 438196002},\n",
       " {'image_id': 393396,\n",
       "  'labels': [425],\n",
       "  'scores': [1],\n",
       "  'question_id': 393396000},\n",
       " {'image_id': 393396,\n",
       "  'labels': [2531],\n",
       "  'scores': [1],\n",
       "  'question_id': 393396001},\n",
       " {'image_id': 393396,\n",
       "  'labels': [425],\n",
       "  'scores': [1],\n",
       "  'question_id': 393396002},\n",
       " {'image_id': 393396,\n",
       "  'labels': [1880, 2594, 1227, 1491, 1333],\n",
       "  'scores': [0.9, 0.6, 0.3, 0.3, 0.3],\n",
       "  'question_id': 393396003},\n",
       " {'image_id': 393396,\n",
       "  'labels': [1508],\n",
       "  'scores': [1],\n",
       "  'question_id': 393396004},\n",
       " {'image_id': 393396,\n",
       "  'labels': [1403],\n",
       "  'scores': [1],\n",
       "  'question_id': 393396005},\n",
       " {'image_id': 393396,\n",
       "  'labels': [1403],\n",
       "  'scores': [1],\n",
       "  'question_id': 393396006},\n",
       " {'image_id': 524470,\n",
       "  'labels': [425],\n",
       "  'scores': [1],\n",
       "  'question_id': 524470000},\n",
       " {'image_id': 524470,\n",
       "  'labels': [425],\n",
       "  'scores': [1],\n",
       "  'question_id': 524470001},\n",
       " {'image_id': 524470,\n",
       "  'labels': [1403],\n",
       "  'scores': [1],\n",
       "  'question_id': 524470002},\n",
       " {'image_id': 524471,\n",
       "  'labels': [301, 1084, 353, 2593, 2005],\n",
       "  'scores': [0.3, 0.3, 0.6, 0.3, 0.3],\n",
       "  'question_id': 524471000},\n",
       " {'image_id': 524471,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [1, 0.3],\n",
       "  'question_id': 524471001},\n",
       " {'image_id': 524471,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [1, 0.6],\n",
       "  'question_id': 524471002},\n",
       " {'image_id': 524471,\n",
       "  'labels': [1208, 1649, 3010, 1713],\n",
       "  'scores': [1, 0.3, 0.3, 0.3],\n",
       "  'question_id': 524471003},\n",
       " {'image_id': 524471,\n",
       "  'labels': [425, 750, 1403],\n",
       "  'scores': [0.3, 0.3, 1],\n",
       "  'question_id': 524471004},\n",
       " {'image_id': 524471,\n",
       "  'labels': [2195, 2621, 841, 3031, 1239],\n",
       "  'scores': [0.3, 0.9, 0.3, 0.3, 1],\n",
       "  'question_id': 524471005},\n",
       " {'image_id': 524471,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [0.9, 1],\n",
       "  'question_id': 524471006},\n",
       " {'image_id': 524471,\n",
       "  'labels': [425],\n",
       "  'scores': [1],\n",
       "  'question_id': 524471007},\n",
       " {'image_id': 262329,\n",
       "  'labels': [1204, 2542],\n",
       "  'scores': [1, 0.3],\n",
       "  'question_id': 262329000},\n",
       " {'image_id': 262329,\n",
       "  'labels': [1623, 2472, 1979],\n",
       "  'scores': [0.3, 0.3, 1],\n",
       "  'question_id': 262329001},\n",
       " {'image_id': 262329,\n",
       "  'labels': [2858, 2595, 3010, 2455, 1643],\n",
       "  'scores': [0.6, 0.3, 0.3, 0.3, 0.3],\n",
       "  'question_id': 262329002},\n",
       " {'image_id': 393403,\n",
       "  'labels': [2195, 841],\n",
       "  'scores': [1, 1],\n",
       "  'question_id': 393403000},\n",
       " {'image_id': 393403,\n",
       "  'labels': [425],\n",
       "  'scores': [1],\n",
       "  'question_id': 393403001},\n",
       " {'image_id': 393403,\n",
       "  'labels': [1403],\n",
       "  'scores': [1],\n",
       "  'question_id': 393403002},\n",
       " {'image_id': 393403,\n",
       "  'labels': [2489, 113, 1047],\n",
       "  'scores': [0.3, 0.6, 0.9],\n",
       "  'question_id': 393403003},\n",
       " {'image_id': 393403, 'labels': [], 'scores': [], 'question_id': 393403004},\n",
       " {'image_id': 393403,\n",
       "  'labels': [1353, 2494],\n",
       "  'scores': [0.6, 0.9],\n",
       "  'question_id': 393403005},\n",
       " {'image_id': 393403,\n",
       "  'labels': [1403],\n",
       "  'scores': [1],\n",
       "  'question_id': 393403006},\n",
       " {'image_id': 393403,\n",
       "  'labels': [841],\n",
       "  'scores': [1],\n",
       "  'question_id': 393403007},\n",
       " {'image_id': 524476,\n",
       "  'labels': [425],\n",
       "  'scores': [1],\n",
       "  'question_id': 524476000},\n",
       " {'image_id': 524476,\n",
       "  'labels': [775],\n",
       "  'scores': [1],\n",
       "  'question_id': 524476001},\n",
       " {'image_id': 524476,\n",
       "  'labels': [2330, 84, 1930],\n",
       "  'scores': [1, 0.3, 0.3],\n",
       "  'question_id': 524476002},\n",
       " {'image_id': 283700,\n",
       "  'labels': [2745, 2405, 2073],\n",
       "  'scores': [0.6, 1, 0.3],\n",
       "  'question_id': 283700000},\n",
       " {'image_id': 283700,\n",
       "  'labels': [1988, 2769, 3031, 311, 1618, 2063, 187],\n",
       "  'scores': [0.6, 0.3, 0.3, 0.3, 0.3, 0.6, 0.3],\n",
       "  'question_id': 283700001},\n",
       " {'image_id': 283700,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [0.9, 1],\n",
       "  'question_id': 283700002},\n",
       " {'image_id': 262336,\n",
       "  'labels': [425],\n",
       "  'scores': [1],\n",
       "  'question_id': 262336000},\n",
       " {'image_id': 262336,\n",
       "  'labels': [1403],\n",
       "  'scores': [1],\n",
       "  'question_id': 262336001},\n",
       " {'image_id': 262336,\n",
       "  'labels': [411, 1403],\n",
       "  'scores': [0.3, 1],\n",
       "  'question_id': 262336002},\n",
       " {'image_id': 194, 'labels': [3006], 'scores': [1], 'question_id': 194000},\n",
       " {'image_id': 194,\n",
       "  'labels': [806, 781, 1944],\n",
       "  'scores': [0.9, 0.9, 0.3],\n",
       "  'question_id': 194001},\n",
       " {'image_id': 194, 'labels': [425], 'scores': [1], 'question_id': 194002},\n",
       " {'image_id': 257513,\n",
       "  'labels': [1577, 1132, 445, 221],\n",
       "  'scores': [0.6, 0.3, 0.3, 1],\n",
       "  'question_id': 257513000},\n",
       " {'image_id': 257513,\n",
       "  'labels': [425, 3010],\n",
       "  'scores': [1, 0.3],\n",
       "  'question_id': 257513001},\n",
       " {'image_id': 257513,\n",
       "  'labels': [425],\n",
       "  'scores': [1],\n",
       "  'question_id': 257513002},\n",
       " {'image_id': 257513,\n",
       "  'labels': [2621, 841],\n",
       "  'scores': [1, 1],\n",
       "  'question_id': 257513003},\n",
       " {'image_id': 257513,\n",
       "  'labels': [2947],\n",
       "  'scores': [1],\n",
       "  'question_id': 257513004},\n",
       " {'image_id': 393412,\n",
       "  'labels': [425],\n",
       "  'scores': [1],\n",
       "  'question_id': 393412000},\n",
       " {'image_id': 393412,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [0.3, 1],\n",
       "  'question_id': 393412001},\n",
       " {'image_id': 393412,\n",
       "  'labels': [1491, 2052],\n",
       "  'scores': [1, 0.3],\n",
       "  'question_id': 393412002},\n",
       " {'image_id': 524486,\n",
       "  'labels': [3023],\n",
       "  'scores': [1],\n",
       "  'question_id': 524486000},\n",
       " {'image_id': 524486,\n",
       "  'labels': [2827, 3026, 425],\n",
       "  'scores': [0.3, 0.3, 0.3],\n",
       "  'question_id': 524486001},\n",
       " {'image_id': 524486,\n",
       "  'labels': [1854, 373, 872],\n",
       "  'scores': [0.3, 0.6, 0.3],\n",
       "  'question_id': 524486002},\n",
       " {'image_id': 458785,\n",
       "  'labels': [1403],\n",
       "  'scores': [0.3],\n",
       "  'question_id': 458785000},\n",
       " {'image_id': 458785,\n",
       "  'labels': [3059, 2385, 2472, 505, 1624, 2435, 148],\n",
       "  'scores': [0.3, 0.3, 0.9, 0.3, 0.3, 0.3, 0.3],\n",
       "  'question_id': 458785001},\n",
       " {'image_id': 458785,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [0.6, 1],\n",
       "  'question_id': 458785002},\n",
       " {'image_id': 201, 'labels': [425], 'scores': [1], 'question_id': 201000},\n",
       " {'image_id': 201,\n",
       "  'labels': [3031, 1618],\n",
       "  'scores': [1, 0.3],\n",
       "  'question_id': 201001},\n",
       " {'image_id': 201, 'labels': [2917], 'scores': [0.3], 'question_id': 201002},\n",
       " {'image_id': 393418, 'labels': [54], 'scores': [1], 'question_id': 393418000},\n",
       " {'image_id': 393418,\n",
       "  'labels': [226],\n",
       "  'scores': [1],\n",
       "  'question_id': 393418001},\n",
       " {'image_id': 393418,\n",
       "  'labels': [5, 157],\n",
       "  'scores': [1, 0.3],\n",
       "  'question_id': 393418002},\n",
       " {'image_id': 393419,\n",
       "  'labels': [2228, 266],\n",
       "  'scores': [0.3, 1],\n",
       "  'question_id': 393419000},\n",
       " {'image_id': 393419,\n",
       "  'labels': [1227, 3006, 2324],\n",
       "  'scores': [0.3, 0.3, 1],\n",
       "  'question_id': 393419001},\n",
       " {'image_id': 393419, 'labels': [], 'scores': [], 'question_id': 393419002},\n",
       " {'image_id': 393419,\n",
       "  'labels': [2387, 2785],\n",
       "  'scores': [0.6, 1],\n",
       "  'question_id': 393419003},\n",
       " {'image_id': 393419,\n",
       "  'labels': [2117, 2305, 3109],\n",
       "  'scores': [0.6, 0.3, 0.6],\n",
       "  'question_id': 393419004},\n",
       " {'image_id': 131277,\n",
       "  'labels': [1403],\n",
       "  'scores': [1],\n",
       "  'question_id': 131277000},\n",
       " {'image_id': 131277,\n",
       "  'labels': [425],\n",
       "  'scores': [1],\n",
       "  'question_id': 131277001},\n",
       " {'image_id': 131277,\n",
       "  'labels': [1403],\n",
       "  'scores': [1],\n",
       "  'question_id': 131277002},\n",
       " {'image_id': 131277,\n",
       "  'labels': [425],\n",
       "  'scores': [1],\n",
       "  'question_id': 131277003},\n",
       " {'image_id': 131277,\n",
       "  'labels': [1403],\n",
       "  'scores': [1],\n",
       "  'question_id': 131277004},\n",
       " {'image_id': 393422,\n",
       "  'labels': [425],\n",
       "  'scores': [1],\n",
       "  'question_id': 393422000},\n",
       " {'image_id': 393422,\n",
       "  'labels': [1403],\n",
       "  'scores': [1],\n",
       "  'question_id': 393422001},\n",
       " {'image_id': 393422,\n",
       "  'labels': [935],\n",
       "  'scores': [1],\n",
       "  'question_id': 393422002},\n",
       " {'image_id': 393422,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [1, 0.3],\n",
       "  'question_id': 393422003},\n",
       " {'image_id': 131279,\n",
       "  'labels': [2671, 2387, 1403, 1141, 425, 2785],\n",
       "  'scores': [0.3, 0.3, 0.3, 0.9, 0.3, 0.3],\n",
       "  'question_id': 131279000},\n",
       " {'image_id': 131279,\n",
       "  'labels': [466, 1015, 2079, 1598, 1805, 1908],\n",
       "  'scores': [0.3, 0.3, 0.3, 0.6, 0.3, 0.6],\n",
       "  'question_id': 131279001},\n",
       " {'image_id': 131279,\n",
       "  'labels': [1403],\n",
       "  'scores': [1],\n",
       "  'question_id': 131279002},\n",
       " {'image_id': 131279,\n",
       "  'labels': [425, 187, 1403],\n",
       "  'scores': [1, 0.3, 0.9],\n",
       "  'question_id': 131279003},\n",
       " {'image_id': 131279,\n",
       "  'labels': [2621, 841],\n",
       "  'scores': [0.3, 1],\n",
       "  'question_id': 131279004},\n",
       " {'image_id': 131279,\n",
       "  'labels': [1403],\n",
       "  'scores': [1],\n",
       "  'question_id': 131279005},\n",
       " {'image_id': 131279,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [0.6, 1],\n",
       "  'question_id': 131279006},\n",
       " {'image_id': 131279,\n",
       "  'labels': [411],\n",
       "  'scores': [1],\n",
       "  'question_id': 131279007},\n",
       " {'image_id': 131279,\n",
       "  'labels': [2081, 2810, 2456, 1174, 564],\n",
       "  'scores': [0.6, 0.3, 0.3, 0.3, 1],\n",
       "  'question_id': 131279008},\n",
       " {'image_id': 131279,\n",
       "  'labels': [411],\n",
       "  'scores': [1],\n",
       "  'question_id': 131279009},\n",
       " {'image_id': 131279,\n",
       "  'labels': [1403],\n",
       "  'scores': [1],\n",
       "  'question_id': 131279010},\n",
       " {'image_id': 131279, 'labels': [75], 'scores': [1], 'question_id': 131279011},\n",
       " {'image_id': 448671,\n",
       "  'labels': [2730, 259, 2786, 1309],\n",
       "  'scores': [0.3, 0.3, 0.3, 0.9],\n",
       "  'question_id': 448671000},\n",
       " {'image_id': 448671,\n",
       "  'labels': [2976, 425],\n",
       "  'scores': [1, 0.3],\n",
       "  'question_id': 448671001},\n",
       " {'image_id': 448671,\n",
       "  'labels': [1403],\n",
       "  'scores': [1],\n",
       "  'question_id': 448671002},\n",
       " {'image_id': 393428,\n",
       "  'labels': [158],\n",
       "  'scores': [1],\n",
       "  'question_id': 393428000},\n",
       " {'image_id': 393428,\n",
       "  'labels': [2594, 3090, 1892],\n",
       "  'scores': [1, 0.6, 0.3],\n",
       "  'question_id': 393428001},\n",
       " {'image_id': 393428,\n",
       "  'labels': [2730, 1177, 1309, 3026, 2785],\n",
       "  'scores': [0.3, 0.3, 0.9, 0.9, 0.3],\n",
       "  'question_id': 393428002},\n",
       " {'image_id': 393428,\n",
       "  'labels': [2195, 2274, 187],\n",
       "  'scores': [0.6, 0.3, 0.3],\n",
       "  'question_id': 393428003},\n",
       " {'image_id': 554301,\n",
       "  'labels': [554, 2440, 956, 733],\n",
       "  'scores': [0.6, 0.3, 0.3, 1],\n",
       "  'question_id': 554301000},\n",
       " {'image_id': 554301,\n",
       "  'labels': [841, 3031, 311, 1618],\n",
       "  'scores': [0.3, 0.3, 0.3, 1],\n",
       "  'question_id': 554301001},\n",
       " {'image_id': 554301,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [1, 0.3],\n",
       "  'question_id': 554301002},\n",
       " {'image_id': 262359,\n",
       "  'labels': [425],\n",
       "  'scores': [1],\n",
       "  'question_id': 262359000},\n",
       " {'image_id': 262359,\n",
       "  'labels': [1040, 2520, 589],\n",
       "  'scores': [0.3, 0.9, 0.6],\n",
       "  'question_id': 262359001},\n",
       " {'image_id': 262359,\n",
       "  'labels': [515],\n",
       "  'scores': [1],\n",
       "  'question_id': 262359002},\n",
       " {'image_id': 262359,\n",
       "  'labels': [775],\n",
       "  'scores': [1],\n",
       "  'question_id': 262359003},\n",
       " {'image_id': 262359,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [1, 0.6],\n",
       "  'question_id': 262359004},\n",
       " {'image_id': 262359,\n",
       "  'labels': [1403],\n",
       "  'scores': [1],\n",
       "  'question_id': 262359005},\n",
       " {'image_id': 262359,\n",
       "  'labels': [2621, 841, 1994],\n",
       "  'scores': [0.3, 1, 0.3],\n",
       "  'question_id': 262359006},\n",
       " {'image_id': 262359,\n",
       "  'labels': [1403],\n",
       "  'scores': [1],\n",
       "  'question_id': 262359007},\n",
       " {'image_id': 262359,\n",
       "  'labels': [1557, 1188, 515],\n",
       "  'scores': [0.6, 0.6, 1],\n",
       "  'question_id': 262359008},\n",
       " {'image_id': 393432,\n",
       "  'labels': [1770],\n",
       "  'scores': [1],\n",
       "  'question_id': 393432000},\n",
       " {'image_id': 393432,\n",
       "  'labels': [728, 1132],\n",
       "  'scores': [1, 1],\n",
       "  'question_id': 393432001},\n",
       " {'image_id': 393432,\n",
       "  'labels': [425],\n",
       "  'scores': [1],\n",
       "  'question_id': 393432002},\n",
       " {'image_id': 393432,\n",
       "  'labels': [411, 1880, 990, 1227],\n",
       "  'scores': [1, 0.3, 1, 0.3],\n",
       "  'question_id': 393432003},\n",
       " {'image_id': 36, 'labels': [425], 'scores': [1], 'question_id': 36000},\n",
       " {'image_id': 36, 'labels': [1204], 'scores': [1], 'question_id': 36001},\n",
       " {'image_id': 36, 'labels': [668], 'scores': [0.6], 'question_id': 36002},\n",
       " {'image_id': 524508,\n",
       "  'labels': [2621],\n",
       "  'scores': [1],\n",
       "  'question_id': 524508000},\n",
       " {'image_id': 524508,\n",
       "  'labels': [2621],\n",
       "  'scores': [1],\n",
       "  'question_id': 524508001},\n",
       " {'image_id': 524508,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [1, 0.3],\n",
       "  'question_id': 524508002},\n",
       " {'image_id': 524508,\n",
       "  'labels': [2984, 425, 1403],\n",
       "  'scores': [0.3, 1, 0.3],\n",
       "  'question_id': 524508003},\n",
       " {'image_id': 474858,\n",
       "  'labels': [89, 1725, 1751],\n",
       "  'scores': [1, 0.6, 0.3],\n",
       "  'question_id': 474858000},\n",
       " {'image_id': 474858,\n",
       "  'labels': [1403],\n",
       "  'scores': [1],\n",
       "  'question_id': 474858001},\n",
       " {'image_id': 474858,\n",
       "  'labels': [3006, 1227, 3090, 893],\n",
       "  'scores': [1, 0.3, 0.3, 0.3],\n",
       "  'question_id': 474858002},\n",
       " {'image_id': 474858,\n",
       "  'labels': [1962, 689, 604, 2984],\n",
       "  'scores': [0.3, 0.6, 1, 0.3],\n",
       "  'question_id': 474858003},\n",
       " {'image_id': 474858,\n",
       "  'labels': [2170, 2269, 1912, 2273, 2354, 1025, 2188],\n",
       "  'scores': [0.3, 0.3, 0.3, 0.3, 0.3, 0.6, 0.6],\n",
       "  'question_id': 474858004},\n",
       " {'image_id': 474858,\n",
       "  'labels': [425, 750, 1403],\n",
       "  'scores': [1, 0.3, 0.3],\n",
       "  'question_id': 474858005},\n",
       " {'image_id': 474858,\n",
       "  'labels': [1403],\n",
       "  'scores': [1],\n",
       "  'question_id': 474858006},\n",
       " {'image_id': 474858,\n",
       "  'labels': [89, 1725],\n",
       "  'scores': [1, 1],\n",
       "  'question_id': 474858007},\n",
       " {'image_id': 474858,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [0.9, 1],\n",
       "  'question_id': 474858008},\n",
       " {'image_id': 474858,\n",
       "  'labels': [631, 89, 2425, 689],\n",
       "  'scores': [0.3, 0.3, 0.6, 1],\n",
       "  'question_id': 474858009},\n",
       " {'image_id': 474858,\n",
       "  'labels': [2873],\n",
       "  'scores': [1],\n",
       "  'question_id': 474858010},\n",
       " {'image_id': 474858,\n",
       "  'labels': [2014, 603, 735, 82, 999],\n",
       "  'scores': [0.3, 0.3, 0.3, 0.3, 0.3],\n",
       "  'question_id': 474858011},\n",
       " {'image_id': 474858,\n",
       "  'labels': [425],\n",
       "  'scores': [1],\n",
       "  'question_id': 474858012},\n",
       " {'image_id': 474858,\n",
       "  'labels': [425],\n",
       "  'scores': [1],\n",
       "  'question_id': 474858013},\n",
       " {'image_id': 474858,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [1, 1],\n",
       "  'question_id': 474858014},\n",
       " {'image_id': 474858,\n",
       "  'labels': [1403],\n",
       "  'scores': [1],\n",
       "  'question_id': 474858015},\n",
       " {'image_id': 474858,\n",
       "  'labels': [425],\n",
       "  'scores': [1],\n",
       "  'question_id': 474858016},\n",
       " {'image_id': 474858,\n",
       "  'labels': [1403],\n",
       "  'scores': [1],\n",
       "  'question_id': 474858017},\n",
       " {'image_id': 474858,\n",
       "  'labels': [931, 387, 444, 1403, 2195, 1725, 1968],\n",
       "  'scores': [0.3, 0.3, 0.3, 0.9, 0.3, 0.3, 0.3],\n",
       "  'question_id': 474858018},\n",
       " {'image_id': 474858,\n",
       "  'labels': [2880, 1403, 2705, 462],\n",
       "  'scores': [0.3, 0.6, 0.3, 0.3],\n",
       "  'question_id': 474858019},\n",
       " {'image_id': 474858,\n",
       "  'labels': [425],\n",
       "  'scores': [1],\n",
       "  'question_id': 474858020},\n",
       " {'image_id': 474858,\n",
       "  'labels': [681, 1607, 3069, 2511, 3006],\n",
       "  'scores': [0.3, 0.3, 0.9, 0.3, 0.3],\n",
       "  'question_id': 474858021},\n",
       " {'image_id': 474858,\n",
       "  'labels': [931, 51, 2321, 1783],\n",
       "  'scores': [0.6, 0.6, 0.3, 0.6],\n",
       "  'question_id': 474858022},\n",
       " {'image_id': 474858,\n",
       "  'labels': [2456],\n",
       "  'scores': [1],\n",
       "  'question_id': 474858023},\n",
       " {'image_id': 474858,\n",
       "  'labels': [387],\n",
       "  'scores': [1],\n",
       "  'question_id': 474858024},\n",
       " {'image_id': 474858,\n",
       "  'labels': [1227],\n",
       "  'scores': [1],\n",
       "  'question_id': 474858025},\n",
       " {'image_id': 474858,\n",
       "  'labels': [2241, 2489, 3006],\n",
       "  'scores': [0.3, 0.6, 1],\n",
       "  'question_id': 474858026},\n",
       " {'image_id': 393438,\n",
       "  'labels': [2195, 1239],\n",
       "  'scores': [1, 0.3],\n",
       "  'question_id': 393438000},\n",
       " {'image_id': 393438, 'labels': [], 'scores': [], 'question_id': 393438001},\n",
       " {'image_id': 393438,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [0.3, 1],\n",
       "  'question_id': 393438002},\n",
       " {'image_id': 165859,\n",
       "  'labels': [1491, 1333],\n",
       "  'scores': [0.6, 1],\n",
       "  'question_id': 165859000},\n",
       " {'image_id': 165859,\n",
       "  'labels': [425],\n",
       "  'scores': [1],\n",
       "  'question_id': 165859001},\n",
       " {'image_id': 165859,\n",
       "  'labels': [299, 1095],\n",
       "  'scores': [1, 0.3],\n",
       "  'question_id': 165859002},\n",
       " {'image_id': 39288,\n",
       "  'labels': [526, 2305, 2104],\n",
       "  'scores': [0.9, 1, 0.3],\n",
       "  'question_id': 39288000},\n",
       " {'image_id': 39288,\n",
       "  'labels': [1808, 1831, 960],\n",
       "  'scores': [1, 1, 0.3],\n",
       "  'question_id': 39288001},\n",
       " {'image_id': 39288,\n",
       "  'labels': [1756],\n",
       "  'scores': [0.3],\n",
       "  'question_id': 39288002},\n",
       " {'image_id': 393442,\n",
       "  'labels': [1491, 1333],\n",
       "  'scores': [1, 0.9],\n",
       "  'question_id': 393442000},\n",
       " {'image_id': 393442,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [1, 0.3],\n",
       "  'question_id': 393442001},\n",
       " {'image_id': 393442,\n",
       "  'labels': [2195, 444, 2621, 841],\n",
       "  'scores': [0.6, 0.3, 1, 0.3],\n",
       "  'question_id': 393442002},\n",
       " {'image_id': 131299,\n",
       "  'labels': [1768, 1265],\n",
       "  'scores': [0.9, 0.9],\n",
       "  'question_id': 131299000},\n",
       " {'image_id': 131299,\n",
       "  'labels': [425],\n",
       "  'scores': [1],\n",
       "  'question_id': 131299001},\n",
       " {'image_id': 131299,\n",
       "  'labels': [2621, 1239, 1618],\n",
       "  'scores': [0.3, 1, 0.6],\n",
       "  'question_id': 131299002},\n",
       " {'image_id': 131300,\n",
       "  'labels': [1983, 2529, 2511, 2365],\n",
       "  'scores': [1, 0.3, 0.3, 0.3],\n",
       "  'question_id': 131300000},\n",
       " {'image_id': 131300,\n",
       "  'labels': [1403],\n",
       "  'scores': [1],\n",
       "  'question_id': 131300001},\n",
       " {'image_id': 131300,\n",
       "  'labels': [1403],\n",
       "  'scores': [1],\n",
       "  'question_id': 131300002},\n",
       " {'image_id': 131300,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [1, 0.6],\n",
       "  'question_id': 131300003},\n",
       " {'image_id': 131300,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [1, 1],\n",
       "  'question_id': 131300004},\n",
       " {'image_id': 393445,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [1, 0.3],\n",
       "  'question_id': 393445000},\n",
       " {'image_id': 393445,\n",
       "  'labels': [3006],\n",
       "  'scores': [1],\n",
       "  'question_id': 393445001},\n",
       " {'image_id': 393445,\n",
       "  'labels': [1414],\n",
       "  'scores': [1],\n",
       "  'question_id': 393445002},\n",
       " {'image_id': 524518,\n",
       "  'labels': [2665, 3006, 445],\n",
       "  'scores': [0.9, 0.3, 1],\n",
       "  'question_id': 524518000},\n",
       " {'image_id': 524518,\n",
       "  'labels': [425],\n",
       "  'scores': [1],\n",
       "  'question_id': 524518001},\n",
       " {'image_id': 524518,\n",
       "  'labels': [157, 1553, 6],\n",
       "  'scores': [0.3, 0.3, 0.3],\n",
       "  'question_id': 524518002},\n",
       " {'image_id': 524518,\n",
       "  'labels': [425],\n",
       "  'scores': [1],\n",
       "  'question_id': 524518003},\n",
       " {'image_id': 524518,\n",
       "  'labels': [589, 2520],\n",
       "  'scores': [0.9, 0.9],\n",
       "  'question_id': 524518004},\n",
       " {'image_id': 524518,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [0.3, 1],\n",
       "  'question_id': 524518005},\n",
       " {'image_id': 524520,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [0.9, 1],\n",
       "  'question_id': 524520000},\n",
       " {'image_id': 524520,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [0.3, 1],\n",
       "  'question_id': 524520001},\n",
       " {'image_id': 524520,\n",
       "  'labels': [935],\n",
       "  'scores': [0.6],\n",
       "  'question_id': 524520002},\n",
       " {'image_id': 524520,\n",
       "  'labels': [1076, 261],\n",
       "  'scores': [1, 0.3],\n",
       "  'question_id': 524520003},\n",
       " {'image_id': 524520,\n",
       "  'labels': [2387, 935, 1333],\n",
       "  'scores': [0.3, 0.3, 1],\n",
       "  'question_id': 524520004},\n",
       " {'image_id': 524522,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [0.3, 1],\n",
       "  'question_id': 524522000},\n",
       " {'image_id': 524522,\n",
       "  'labels': [1988],\n",
       "  'scores': [1],\n",
       "  'question_id': 524522001},\n",
       " {'image_id': 524522,\n",
       "  'labels': [3059, 3047, 2585, 735, 3067, 2677],\n",
       "  'scores': [0.3, 0.3, 0.3, 0.3, 0.3, 0.6],\n",
       "  'question_id': 524522002},\n",
       " {'image_id': 524522,\n",
       "  'labels': [444, 841],\n",
       "  'scores': [0.3, 1],\n",
       "  'question_id': 524522003},\n",
       " {'image_id': 524525,\n",
       "  'labels': [3006],\n",
       "  'scores': [1],\n",
       "  'question_id': 524525000},\n",
       " {'image_id': 524525,\n",
       "  'labels': [2621, 841],\n",
       "  'scores': [1, 0.3],\n",
       "  'question_id': 524525001},\n",
       " {'image_id': 524525,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [1, 0.3],\n",
       "  'question_id': 524525002},\n",
       " {'image_id': 131312,\n",
       "  'labels': [1553, 2836, 2168],\n",
       "  'scores': [0.3, 0.3, 0.3],\n",
       "  'question_id': 131312000},\n",
       " {'image_id': 131312,\n",
       "  'labels': [1403],\n",
       "  'scores': [1],\n",
       "  'question_id': 131312001},\n",
       " {'image_id': 131312,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [1, 0.3],\n",
       "  'question_id': 131312002},\n",
       " {'image_id': 131312,\n",
       "  'labels': [325],\n",
       "  'scores': [1],\n",
       "  'question_id': 131312003},\n",
       " {'image_id': 131315,\n",
       "  'labels': [1403],\n",
       "  'scores': [1],\n",
       "  'question_id': 131315000},\n",
       " {'image_id': 131315,\n",
       "  'labels': [1551, 1595, 2324, 2239],\n",
       "  'scores': [0.9, 0.6, 0.3, 0.3],\n",
       "  'question_id': 131315001},\n",
       " {'image_id': 131315,\n",
       "  'labels': [1403],\n",
       "  'scores': [1],\n",
       "  'question_id': 131315002},\n",
       " {'image_id': 262389,\n",
       "  'labels': [425],\n",
       "  'scores': [1],\n",
       "  'question_id': 262389000},\n",
       " {'image_id': 262389,\n",
       "  'labels': [927, 2941],\n",
       "  'scores': [1, 0.6],\n",
       "  'question_id': 262389001},\n",
       " {'image_id': 262389,\n",
       "  'labels': [2941],\n",
       "  'scores': [1],\n",
       "  'question_id': 262389002},\n",
       " {'image_id': 247,\n",
       "  'labels': [2234, 2075, 337],\n",
       "  'scores': [0.3, 0.3, 0.3],\n",
       "  'question_id': 247000},\n",
       " {'image_id': 247,\n",
       "  'labels': [835, 648, 1968],\n",
       "  'scores': [0.3, 0.3, 0.9],\n",
       "  'question_id': 247001},\n",
       " {'image_id': 247,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [1, 1],\n",
       "  'question_id': 247002},\n",
       " {'image_id': 393464,\n",
       "  'labels': [1403],\n",
       "  'scores': [1],\n",
       "  'question_id': 393464000},\n",
       " {'image_id': 393464,\n",
       "  'labels': [3031],\n",
       "  'scores': [1],\n",
       "  'question_id': 393464001},\n",
       " {'image_id': 393464,\n",
       "  'labels': [425],\n",
       "  'scores': [1],\n",
       "  'question_id': 393464002},\n",
       " {'image_id': 262393,\n",
       "  'labels': [444, 841],\n",
       "  'scores': [0.6, 1],\n",
       "  'question_id': 262393000},\n",
       " {'image_id': 262393,\n",
       "  'labels': [1842, 2525, 2960, 68],\n",
       "  'scores': [0.3, 0.9, 1, 0.3],\n",
       "  'question_id': 262393001},\n",
       " {'image_id': 262393,\n",
       "  'labels': [425, 841, 1403],\n",
       "  'scores': [0.6, 0.3, 1],\n",
       "  'question_id': 262393002},\n",
       " {'image_id': 262393,\n",
       "  'labels': [841],\n",
       "  'scores': [1],\n",
       "  'question_id': 262393003},\n",
       " {'image_id': 250,\n",
       "  'labels': [2093, 20, 2131, 2174, 2312],\n",
       "  'scores': [0.3, 0.3, 0.3, 1, 0.3],\n",
       "  'question_id': 250000},\n",
       " {'image_id': 250, 'labels': [1403], 'scores': [1], 'question_id': 250001},\n",
       " {'image_id': 250, 'labels': [], 'scores': [], 'question_id': 250002},\n",
       " {'image_id': 131323,\n",
       "  'labels': [425, 841, 1403],\n",
       "  'scores': [1, 0.3, 0.3],\n",
       "  'question_id': 131323000},\n",
       " {'image_id': 131323,\n",
       "  'labels': [1403],\n",
       "  'scores': [1],\n",
       "  'question_id': 131323001},\n",
       " {'image_id': 131323,\n",
       "  'labels': [2515, 2643],\n",
       "  'scores': [0.3, 1],\n",
       "  'question_id': 131323002},\n",
       " {'image_id': 262399, 'labels': [], 'scores': [], 'question_id': 262399000},\n",
       " {'image_id': 262399,\n",
       "  'labels': [158, 36, 1126, 464],\n",
       "  'scores': [0.3, 0.9, 0.6, 0.3],\n",
       "  'question_id': 262399001},\n",
       " {'image_id': 262399,\n",
       "  'labels': [1333],\n",
       "  'scores': [1],\n",
       "  'question_id': 262399002},\n",
       " {'image_id': 131330,\n",
       "  'labels': [425],\n",
       "  'scores': [1],\n",
       "  'question_id': 131330000},\n",
       " {'image_id': 131330,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [1, 0.3],\n",
       "  'question_id': 131330001},\n",
       " {'image_id': 131330,\n",
       "  'labels': [742],\n",
       "  'scores': [0.6],\n",
       "  'question_id': 131330002},\n",
       " {'image_id': 524547,\n",
       "  'labels': [2526, 2142, 684],\n",
       "  'scores': [0.3, 0.3, 0.9],\n",
       "  'question_id': 524547000},\n",
       " {'image_id': 524547,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [1, 0.3],\n",
       "  'question_id': 524547001},\n",
       " {'image_id': 524547,\n",
       "  'labels': [366],\n",
       "  'scores': [0.6],\n",
       "  'question_id': 524547002},\n",
       " {'image_id': 260, 'labels': [411], 'scores': [1], 'question_id': 260000},\n",
       " {'image_id': 260,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [1, 0.9],\n",
       "  'question_id': 260001},\n",
       " {'image_id': 260,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [1, 0.3],\n",
       "  'question_id': 260002},\n",
       " {'image_id': 524551,\n",
       "  'labels': [425],\n",
       "  'scores': [1],\n",
       "  'question_id': 524551000},\n",
       " {'image_id': 524551,\n",
       "  'labels': [931, 684, 1561],\n",
       "  'scores': [0.3, 1, 0.9],\n",
       "  'question_id': 524551001},\n",
       " {'image_id': 524551,\n",
       "  'labels': [1923, 684, 2142, 1561],\n",
       "  'scores': [0.3, 1, 0.3, 0.3],\n",
       "  'question_id': 524551002},\n",
       " {'image_id': 524551, 'labels': [], 'scores': [], 'question_id': 524551003},\n",
       " {'image_id': 393480,\n",
       "  'labels': [1403, 1299, 1141],\n",
       "  'scores': [0.9, 0.6, 0.6],\n",
       "  'question_id': 393480000},\n",
       " {'image_id': 393480,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [1, 0.3],\n",
       "  'question_id': 393480001},\n",
       " {'image_id': 393480,\n",
       "  'labels': [425],\n",
       "  'scores': [1],\n",
       "  'question_id': 393480002},\n",
       " {'image_id': 393480,\n",
       "  'labels': [1207, 462],\n",
       "  'scores': [1, 0.3],\n",
       "  'question_id': 393480003},\n",
       " {'image_id': 393480,\n",
       "  'labels': [2154, 858],\n",
       "  'scores': [1, 0.3],\n",
       "  'question_id': 393480004},\n",
       " {'image_id': 131339,\n",
       "  'labels': [2241, 1333],\n",
       "  'scores': [0.3, 1],\n",
       "  'question_id': 131339000},\n",
       " {'image_id': 131339,\n",
       "  'labels': [1449, 1693, 893],\n",
       "  'scores': [1, 1, 0.3],\n",
       "  'question_id': 131339001},\n",
       " {'image_id': 131339,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [1, 1],\n",
       "  'question_id': 131339002},\n",
       " {'image_id': 131339,\n",
       "  'labels': [425],\n",
       "  'scores': [1],\n",
       "  'question_id': 131339003},\n",
       " {'image_id': 131339,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [1, 1],\n",
       "  'question_id': 131339004},\n",
       " {'image_id': 131339,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [0.3, 1],\n",
       "  'question_id': 131339005},\n",
       " {'image_id': 131339,\n",
       "  'labels': [2195],\n",
       "  'scores': [1],\n",
       "  'question_id': 131339006},\n",
       " {'image_id': 131339,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [1, 1],\n",
       "  'question_id': 131339007},\n",
       " {'image_id': 131339,\n",
       "  'labels': [285, 1128, 1693, 893, 1449, 90, 177],\n",
       "  'scores': [0.9, 0.3, 0.3, 0.3, 0.6, 0.3, 0.3],\n",
       "  'question_id': 131339008},\n",
       " {'image_id': 524557,\n",
       "  'labels': [680],\n",
       "  'scores': [1],\n",
       "  'question_id': 524557000},\n",
       " {'image_id': 524557,\n",
       "  'labels': [3006, 2697, 759],\n",
       "  'scores': [1, 0.3, 1],\n",
       "  'question_id': 524557001},\n",
       " {'image_id': 524557,\n",
       "  'labels': [868, 702, 2377, 2210, 2785],\n",
       "  'scores': [0.3, 0.3, 0.3, 0.3, 0.9],\n",
       "  'question_id': 524557002},\n",
       " {'image_id': 524557,\n",
       "  'labels': [841, 3031, 1618],\n",
       "  'scores': [0.3, 1, 1],\n",
       "  'question_id': 524557003},\n",
       " {'image_id': 524557,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [0.3, 1],\n",
       "  'question_id': 524557004},\n",
       " {'image_id': 524557,\n",
       "  'labels': [1403],\n",
       "  'scores': [1],\n",
       "  'question_id': 524557005},\n",
       " {'image_id': 131342,\n",
       "  'labels': [444],\n",
       "  'scores': [1],\n",
       "  'question_id': 131342000},\n",
       " {'image_id': 131342,\n",
       "  'labels': [425],\n",
       "  'scores': [1],\n",
       "  'question_id': 131342001},\n",
       " {'image_id': 131342,\n",
       "  'labels': [425],\n",
       "  'scores': [0.3],\n",
       "  'question_id': 131342002},\n",
       " {'image_id': 131342,\n",
       "  'labels': [772],\n",
       "  'scores': [1],\n",
       "  'question_id': 131342003},\n",
       " {'image_id': 131342,\n",
       "  'labels': [2211, 2739],\n",
       "  'scores': [0.6, 1],\n",
       "  'question_id': 131342004},\n",
       " {'image_id': 262415,\n",
       "  'labels': [2419, 2157, 886],\n",
       "  'scores': [0.3, 0.3, 0.6],\n",
       "  'question_id': 262415000},\n",
       " {'image_id': 262415,\n",
       "  'labels': [759],\n",
       "  'scores': [1],\n",
       "  'question_id': 262415001},\n",
       " {'image_id': 262415,\n",
       "  'labels': [1353, 134, 155, 2838],\n",
       "  'scores': [1, 0.3, 0.9, 0.3],\n",
       "  'question_id': 262415002},\n",
       " {'image_id': 262415,\n",
       "  'labels': [7, 2844],\n",
       "  'scores': [0.9, 1],\n",
       "  'question_id': 262415003},\n",
       " {'image_id': 393488,\n",
       "  'labels': [1076],\n",
       "  'scores': [1],\n",
       "  'question_id': 393488000},\n",
       " {'image_id': 393488,\n",
       "  'labels': [425],\n",
       "  'scores': [1],\n",
       "  'question_id': 393488001},\n",
       " {'image_id': 393488,\n",
       "  'labels': [3101, 2570, 625, 1387],\n",
       "  'scores': [0.6, 0.3, 0.3, 1],\n",
       "  'question_id': 393488002},\n",
       " {'image_id': 393488,\n",
       "  'labels': [425],\n",
       "  'scores': [1],\n",
       "  'question_id': 393488003},\n",
       " {'image_id': 393489,\n",
       "  'labels': [707, 200, 1231],\n",
       "  'scores': [1, 1, 0.3],\n",
       "  'question_id': 393489000},\n",
       " {'image_id': 393489,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [1, 1],\n",
       "  'question_id': 393489001},\n",
       " {'image_id': 393489,\n",
       "  'labels': [1496, 707, 1196],\n",
       "  'scores': [0.3, 0.3, 0.3],\n",
       "  'question_id': 393489002},\n",
       " {'image_id': 393489,\n",
       "  'labels': [1880, 775],\n",
       "  'scores': [1, 1],\n",
       "  'question_id': 393489003},\n",
       " {'image_id': 393489,\n",
       "  'labels': [1403],\n",
       "  'scores': [1],\n",
       "  'question_id': 393489004},\n",
       " {'image_id': 393489,\n",
       "  'labels': [3115],\n",
       "  'scores': [1],\n",
       "  'question_id': 393489005},\n",
       " {'image_id': 393489,\n",
       "  'labels': [2195, 444, 841, 1239],\n",
       "  'scores': [1, 0.3, 0.3, 0.6],\n",
       "  'question_id': 393489006},\n",
       " {'image_id': 393489,\n",
       "  'labels': [707, 200],\n",
       "  'scores': [1, 1],\n",
       "  'question_id': 393489007},\n",
       " {'image_id': 393489,\n",
       "  'labels': [2388, 2661, 2076, 3004, 775],\n",
       "  'scores': [0.3, 0.3, 0.3, 0.3, 1],\n",
       "  'question_id': 393489008},\n",
       " {'image_id': 393489, 'labels': [], 'scores': [], 'question_id': 393489009},\n",
       " {'image_id': 393489,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [0.6, 1],\n",
       "  'question_id': 393489010},\n",
       " {'image_id': 393489,\n",
       "  'labels': [1614, 707, 2274],\n",
       "  'scores': [0.3, 0.9, 0.3],\n",
       "  'question_id': 393489011},\n",
       " {'image_id': 393489,\n",
       "  'labels': [1403],\n",
       "  'scores': [1],\n",
       "  'question_id': 393489012},\n",
       " {'image_id': 393489,\n",
       "  'labels': [2387, 2785],\n",
       "  'scores': [0.3, 1],\n",
       "  'question_id': 393489013},\n",
       " {'image_id': 393489,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [0.3, 1],\n",
       "  'question_id': 393489014},\n",
       " {'image_id': 393489,\n",
       "  'labels': [1403],\n",
       "  'scores': [1],\n",
       "  'question_id': 393489015},\n",
       " {'image_id': 393489,\n",
       "  'labels': [2195],\n",
       "  'scores': [1],\n",
       "  'question_id': 393489016},\n",
       " {'image_id': 393489,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [0.3, 1],\n",
       "  'question_id': 393489017},\n",
       " {'image_id': 393489,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [1, 1],\n",
       "  'question_id': 393489018},\n",
       " {'image_id': 393489, 'labels': [], 'scores': [], 'question_id': 393489019},\n",
       " {'image_id': 393489,\n",
       "  'labels': [2647],\n",
       "  'scores': [0.3],\n",
       "  'question_id': 393489020},\n",
       " {'image_id': 393489,\n",
       "  'labels': [707, 200],\n",
       "  'scores': [0.6, 1],\n",
       "  'question_id': 393489021},\n",
       " {'image_id': 393489,\n",
       "  'labels': [707],\n",
       "  'scores': [1],\n",
       "  'question_id': 393489022},\n",
       " {'image_id': 336077,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [1, 0.9],\n",
       "  'question_id': 336077000},\n",
       " {'image_id': 336077,\n",
       "  'labels': [425, 1423],\n",
       "  'scores': [1, 0.3],\n",
       "  'question_id': 336077001},\n",
       " {'image_id': 336077,\n",
       "  'labels': [425],\n",
       "  'scores': [1],\n",
       "  'question_id': 336077002},\n",
       " {'image_id': 336077,\n",
       "  'labels': [425],\n",
       "  'scores': [1],\n",
       "  'question_id': 336077003},\n",
       " {'image_id': 546179,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [0.6, 1],\n",
       "  'question_id': 546179000},\n",
       " {'image_id': 546179,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [0.6, 1],\n",
       "  'question_id': 546179001},\n",
       " {'image_id': 546179,\n",
       "  'labels': [2418, 1540, 781, 103, 1077],\n",
       "  'scores': [0.3, 0.9, 0.3, 0.3, 0.9],\n",
       "  'question_id': 546179002},\n",
       " {'image_id': 546179,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [0.3, 1],\n",
       "  'question_id': 546179003},\n",
       " {'image_id': 546179,\n",
       "  'labels': [3006],\n",
       "  'scores': [1],\n",
       "  'question_id': 546179004},\n",
       " {'image_id': 546179,\n",
       "  'labels': [425],\n",
       "  'scores': [1],\n",
       "  'question_id': 546179005},\n",
       " {'image_id': 546179,\n",
       "  'labels': [2969, 1299, 1077, 1232],\n",
       "  'scores': [0.3, 0.3, 0.3, 0.3],\n",
       "  'question_id': 546179006},\n",
       " {'image_id': 546179,\n",
       "  'labels': [1403],\n",
       "  'scores': [1],\n",
       "  'question_id': 546179007},\n",
       " {'image_id': 9, 'labels': [841], 'scores': [1], 'question_id': 9000},\n",
       " {'image_id': 9, 'labels': [2542], 'scores': [0.9], 'question_id': 9001},\n",
       " {'image_id': 9, 'labels': [2529], 'scores': [1], 'question_id': 9002},\n",
       " {'image_id': 393493,\n",
       "  'labels': [425],\n",
       "  'scores': [1],\n",
       "  'question_id': 393493000},\n",
       " {'image_id': 393493,\n",
       "  'labels': [2195, 841],\n",
       "  'scores': [1, 1],\n",
       "  'question_id': 393493001},\n",
       " {'image_id': 393493,\n",
       "  'labels': [425],\n",
       "  'scores': [1],\n",
       "  'question_id': 393493002},\n",
       " {'image_id': 131351,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [0.3, 1],\n",
       "  'question_id': 131351000},\n",
       " {'image_id': 131351,\n",
       "  'labels': [2195, 2621, 841],\n",
       "  'scores': [1, 0.3, 0.6],\n",
       "  'question_id': 131351001},\n",
       " {'image_id': 131351,\n",
       "  'labels': [1208, 2019],\n",
       "  'scores': [1, 0.3],\n",
       "  'question_id': 131351002},\n",
       " {'image_id': 131351,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [1, 1],\n",
       "  'question_id': 131351003},\n",
       " {'image_id': 131351,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [0.3, 1],\n",
       "  'question_id': 131351004},\n",
       " {'image_id': 131351,\n",
       "  'labels': [2661, 3006],\n",
       "  'scores': [1, 0.9],\n",
       "  'question_id': 131351005},\n",
       " {'image_id': 131351,\n",
       "  'labels': [1403],\n",
       "  'scores': [1],\n",
       "  'question_id': 131351006},\n",
       " {'image_id': 131351,\n",
       "  'labels': [735],\n",
       "  'scores': [0.3],\n",
       "  'question_id': 131351007},\n",
       " {'image_id': 131351,\n",
       "  'labels': [1403],\n",
       "  'scores': [1],\n",
       "  'question_id': 131351008},\n",
       " {'image_id': 131351, 'labels': [], 'scores': [], 'question_id': 131351009},\n",
       " {'image_id': 131351,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [0.9, 1],\n",
       "  'question_id': 131351010},\n",
       " {'image_id': 131352,\n",
       "  'labels': [1250, 384, 416, 2155],\n",
       "  'scores': [0.3, 0.3, 0.9, 0.3],\n",
       "  'question_id': 131352000},\n",
       " {'image_id': 131352,\n",
       "  'labels': [2241, 3006, 1333],\n",
       "  'scores': [0.3, 0.9, 0.9],\n",
       "  'question_id': 131352001},\n",
       " {'image_id': 131352,\n",
       "  'labels': [2522],\n",
       "  'scores': [1],\n",
       "  'question_id': 131352002},\n",
       " {'image_id': 524572,\n",
       "  'labels': [2210],\n",
       "  'scores': [0.3],\n",
       "  'question_id': 524572000},\n",
       " {'image_id': 524572,\n",
       "  'labels': [781, 349, 2387, 927],\n",
       "  'scores': [0.3, 0.3, 0.3, 1],\n",
       "  'question_id': 524572001},\n",
       " {'image_id': 524572,\n",
       "  'labels': [1542, 425, 1403],\n",
       "  'scores': [0.3, 0.9, 1],\n",
       "  'question_id': 524572002},\n",
       " {'image_id': 112497,\n",
       "  'labels': [1040],\n",
       "  'scores': [1],\n",
       "  'question_id': 112497000},\n",
       " {'image_id': 112497,\n",
       "  'labels': [1388, 772],\n",
       "  'scores': [1, 0.3],\n",
       "  'question_id': 112497001},\n",
       " {'image_id': 112497,\n",
       "  'labels': [1726],\n",
       "  'scores': [1],\n",
       "  'question_id': 112497002},\n",
       " {'image_id': 393503,\n",
       "  'labels': [411, 1598, 3006, 2324],\n",
       "  'scores': [0.3, 0.3, 0.9, 0.6],\n",
       "  'question_id': 393503000},\n",
       " {'image_id': 393503,\n",
       "  'labels': [1403],\n",
       "  'scores': [1],\n",
       "  'question_id': 393503001},\n",
       " {'image_id': 393503,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [1, 1],\n",
       "  'question_id': 393503002},\n",
       " {'image_id': 393503,\n",
       "  'labels': [1930, 1001],\n",
       "  'scores': [0.3, 1],\n",
       "  'question_id': 393503003},\n",
       " {'image_id': 393508,\n",
       "  'labels': [226],\n",
       "  'scores': [1],\n",
       "  'question_id': 393508000},\n",
       " {'image_id': 393508,\n",
       "  'labels': [3010],\n",
       "  'scores': [1],\n",
       "  'question_id': 393508001},\n",
       " {'image_id': 393508,\n",
       "  'labels': [2187, 5],\n",
       "  'scores': [0.9, 1],\n",
       "  'question_id': 393508002},\n",
       " {'image_id': 414639,\n",
       "  'labels': [563, 1181, 2471],\n",
       "  'scores': [0.3, 0.3, 0.3],\n",
       "  'question_id': 414639000},\n",
       " {'image_id': 414639,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [1, 0.9],\n",
       "  'question_id': 414639001},\n",
       " {'image_id': 414639,\n",
       "  'labels': [2588, 1840],\n",
       "  'scores': [0.6, 1],\n",
       "  'question_id': 414639002},\n",
       " {'image_id': 131366,\n",
       "  'labels': [841, 1239],\n",
       "  'scores': [0.3, 1],\n",
       "  'question_id': 131366000},\n",
       " {'image_id': 131366,\n",
       "  'labels': [733, 2267, 1484],\n",
       "  'scores': [0.3, 1, 1],\n",
       "  'question_id': 131366001},\n",
       " {'image_id': 131366,\n",
       "  'labels': [2267, 1484],\n",
       "  'scores': [1, 1],\n",
       "  'question_id': 131366002},\n",
       " {'image_id': 131366,\n",
       "  'labels': [2063, 1239, 311, 1618],\n",
       "  'scores': [1, 0.6, 0.3, 0.6],\n",
       "  'question_id': 131366003},\n",
       " {'image_id': 131366,\n",
       "  'labels': [1239],\n",
       "  'scores': [1],\n",
       "  'question_id': 131366004},\n",
       " {'image_id': 131366,\n",
       "  'labels': [2274, 2306, 1455, 2519],\n",
       "  'scores': [0.9, 0.6, 1, 0.3],\n",
       "  'question_id': 131366005},\n",
       " {'image_id': 131366,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [1, 0.3],\n",
       "  'question_id': 131366006},\n",
       " {'image_id': 131366,\n",
       "  'labels': [436],\n",
       "  'scores': [1],\n",
       "  'question_id': 131366007},\n",
       " {'image_id': 131366,\n",
       "  'labels': [3068, 1781],\n",
       "  'scores': [0.6, 0.3],\n",
       "  'question_id': 131366008},\n",
       " {'image_id': 131366,\n",
       "  'labels': [1239],\n",
       "  'scores': [1],\n",
       "  'question_id': 131366009},\n",
       " {'image_id': 131366,\n",
       "  'labels': [1441, 436, 444, 2387],\n",
       "  'scores': [0.3, 0.3, 0.9, 0.3],\n",
       "  'question_id': 131366010},\n",
       " {'image_id': 131366,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [1, 0.3],\n",
       "  'question_id': 131366011},\n",
       " {'image_id': 131366,\n",
       "  'labels': [425],\n",
       "  'scores': [1],\n",
       "  'question_id': 131366012},\n",
       " {'image_id': 131366,\n",
       "  'labels': [1403],\n",
       "  'scores': [1],\n",
       "  'question_id': 131366013},\n",
       " {'image_id': 131366,\n",
       "  'labels': [1022, 105, 436, 2604],\n",
       "  'scores': [0.9, 0.6, 0.9, 0.6],\n",
       "  'question_id': 131366014},\n",
       " {'image_id': 131366,\n",
       "  'labels': [524, 2212, 2984, 444, 1771, 177],\n",
       "  'scores': [0.3, 0.3, 0.3, 0.3, 0.3, 0.3],\n",
       "  'question_id': 131366015},\n",
       " {'image_id': 131366,\n",
       "  'labels': [2274, 1553],\n",
       "  'scores': [1, 0.3],\n",
       "  'question_id': 131366016},\n",
       " {'image_id': 131366,\n",
       "  'labels': [1403],\n",
       "  'scores': [1],\n",
       "  'question_id': 131366017},\n",
       " {'image_id': 131366,\n",
       "  'labels': [425],\n",
       "  'scores': [1],\n",
       "  'question_id': 131366018},\n",
       " {'image_id': 131366,\n",
       "  'labels': [425],\n",
       "  'scores': [1],\n",
       "  'question_id': 131366019},\n",
       " {'image_id': 131366,\n",
       "  'labels': [1239],\n",
       "  'scores': [1],\n",
       "  'question_id': 131366020},\n",
       " {'image_id': 131366,\n",
       "  'labels': [444],\n",
       "  'scores': [1],\n",
       "  'question_id': 131366021},\n",
       " {'image_id': 131366,\n",
       "  'labels': [2063, 1239, 1618],\n",
       "  'scores': [1, 0.6, 0.3],\n",
       "  'question_id': 131366022},\n",
       " {'image_id': 131366,\n",
       "  'labels': [1866],\n",
       "  'scores': [0.9],\n",
       "  'question_id': 131366023},\n",
       " {'image_id': 131366,\n",
       "  'labels': [436, 2324],\n",
       "  'scores': [0.3, 1],\n",
       "  'question_id': 131366024},\n",
       " {'image_id': 131366,\n",
       "  'labels': [1403],\n",
       "  'scores': [1],\n",
       "  'question_id': 131366025},\n",
       " {'image_id': 131366,\n",
       "  'labels': [436],\n",
       "  'scores': [1],\n",
       "  'question_id': 131366026},\n",
       " {'image_id': 131366,\n",
       "  'labels': [554, 733, 2267],\n",
       "  'scores': [0.3, 0.3, 1],\n",
       "  'question_id': 131366027},\n",
       " {'image_id': 131366,\n",
       "  'labels': [2063],\n",
       "  'scores': [1],\n",
       "  'question_id': 131366028},\n",
       " {'image_id': 131366,\n",
       "  'labels': [554, 2267, 1484],\n",
       "  'scores': [0.3, 0.9, 0.6],\n",
       "  'question_id': 131366029},\n",
       " {'image_id': 131366,\n",
       "  'labels': [425],\n",
       "  'scores': [1],\n",
       "  'question_id': 131366030},\n",
       " {'image_id': 131366,\n",
       "  'labels': [1787, 1141, 1403],\n",
       "  'scores': [0.3, 0.6, 0.6],\n",
       "  'question_id': 131366031},\n",
       " {'image_id': 497565,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [1, 1],\n",
       "  'question_id': 497565000},\n",
       " {'image_id': 497565,\n",
       "  'labels': [1227],\n",
       "  'scores': [1],\n",
       "  'question_id': 497565001},\n",
       " {'image_id': 497565,\n",
       "  'labels': [425],\n",
       "  'scores': [1],\n",
       "  'question_id': 497565002},\n",
       " {'image_id': 101431,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [1, 0.3],\n",
       "  'question_id': 101431000},\n",
       " {'image_id': 101431,\n",
       "  'labels': [1491, 411, 1333],\n",
       "  'scores': [1, 0.3, 0.3],\n",
       "  'question_id': 101431001},\n",
       " {'image_id': 101431,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [1, 0.9],\n",
       "  'question_id': 101431002},\n",
       " {'image_id': 262442,\n",
       "  'labels': [2093, 1015, 2091, 2172, 2174, 2134, 444, 1805, 2131],\n",
       "  'scores': [0.6, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3],\n",
       "  'question_id': 262442000},\n",
       " {'image_id': 262442,\n",
       "  'labels': [425],\n",
       "  'scores': [1],\n",
       "  'question_id': 262442001},\n",
       " {'image_id': 262442, 'labels': [], 'scores': [], 'question_id': 262442002},\n",
       " {'image_id': 262442,\n",
       "  'labels': [2387, 383, 2785],\n",
       "  'scores': [1, 0.3, 0.3],\n",
       "  'question_id': 262442003},\n",
       " {'image_id': 21895,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [1, 1],\n",
       "  'question_id': 21895000},\n",
       " {'image_id': 21895, 'labels': [425], 'scores': [1], 'question_id': 21895001},\n",
       " {'image_id': 21895,\n",
       "  'labels': [1551, 830, 2239],\n",
       "  'scores': [0.6, 1, 1],\n",
       "  'question_id': 21895002},\n",
       " {'image_id': 131373,\n",
       "  'labels': [1725, 604],\n",
       "  'scores': [1, 0.3],\n",
       "  'question_id': 131373000},\n",
       " {'image_id': 131373,\n",
       "  'labels': [425, 1403],\n",
       "  'scores': [1, 1],\n",
       "  'question_id': 131373001},\n",
       " {'image_id': 131373,\n",
       "  'labels': [315],\n",
       "  'scores': [1],\n",
       "  'question_id': 131373002},\n",
       " {'image_id': 131373,\n",
       "  'labels': [315],\n",
       "  'scores': [1],\n",
       "  'question_id': 131373003},\n",
       " {'image_id': 131374,\n",
       "  'labels': [2621, 1239],\n",
       "  'scores': [1, 0.9],\n",
       "  'question_id': 131374000},\n",
       " {'image_id': 131374,\n",
       "  'labels': [2621, 3031, 1239],\n",
       "  'scores': [1, 0.6, 0.9],\n",
       "  'question_id': 131374001},\n",
       " {'image_id': 131374,\n",
       "  'labels': [912, 301],\n",
       "  'scores': [0.6, 1],\n",
       "  'question_id': 131374002},\n",
       " {'image_id': 131374,\n",
       "  'labels': [2621, 1239, 311],\n",
       "  'scores': [1, 1, 0.3],\n",
       "  'question_id': 131374003},\n",
       " {'image_id': 109277,\n",
       "  'labels': [2111, 1227, 2807],\n",
       "  'scores': [0.9, 0.9, 0.9],\n",
       "  'question_id': 109277000},\n",
       " {'image_id': 109277,\n",
       "  'labels': [411, 1504],\n",
       "  'scores': [1, 0.3],\n",
       "  'question_id': 109277001},\n",
       " {'image_id': 109277,\n",
       "  'labels': [1403],\n",
       "  'scores': [1],\n",
       "  'question_id': 109277002},\n",
       " {'image_id': 131376,\n",
       "  'labels': [2594, 1227],\n",
       "  'scores': [0.3, 1],\n",
       "  'question_id': 131376000},\n",
       " {'image_id': 131376,\n",
       "  'labels': [1227, 1333],\n",
       "  'scores': [1, 1],\n",
       "  'question_id': 131376001},\n",
       " {'image_id': 131376,\n",
       "  'labels': [3107, 1693],\n",
       "  'scores': [0.9, 1],\n",
       "  'question_id': 131376002},\n",
       " {'image_id': 131376,\n",
       "  'labels': [1403],\n",
       "  'scores': [1],\n",
       "  'question_id': 131376003},\n",
       " {'image_id': 131376,\n",
       "  'labels': [1403],\n",
       "  'scores': [1],\n",
       "  'question_id': 131376004},\n",
       " {'image_id': 131376,\n",
       "  'labels': [435, 2705, 545, 1310],\n",
       "  'scores': [0.9, 0.3, 0.6, 0.9],\n",
       "  'question_id': 131376005},\n",
       " {'image_id': 131376,\n",
       "  'labels': [2324, 3006, 1851, 2697],\n",
       "  'scores': [0.6, 0.9, 0.3, 0.9],\n",
       "  'question_id': 131376006},\n",
       " ...]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = cPickle.load(open('datasets/VQA/cache/VQA_test_23_cleaned.pkl', \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "val = cPickle.load(open('datasets/VQA/cache/VQA_minval_23_cleaned.pkl', \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = cPickle.load(open('datasets/VQA/cache/VQA_trainval_23_cleaned.pkl', \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(542104, 3000, 447793)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train), len(val), len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'image_id': 1,\n",
       " 'question': 'What is the fence made of?',\n",
       " 'question_id': 1000,\n",
       " 'q_token': tensor([ 101, 2054, 2003, 1996, 8638, 2081, 1997, 1029,  102,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0]),\n",
       " 'q_input_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 'q_segment_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question_id': 573843005,\n",
       " 'image_id': 573843,\n",
       " 'question': 'Are there clouds?',\n",
       " 'answer': {'labels': tensor([ 425, 1403]),\n",
       "  'scores': tensor([1.0000, 0.3000])},\n",
       " 'q_token': tensor([ 101, 2024, 2045, 8044, 1029,  102,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0]),\n",
       " 'q_input_mask': tensor([1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 'q_segment_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/30/2020 11:24:11 - INFO - pytorch_transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/aloui/.cache/torch/pytorch_transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
      "07/30/2020 11:24:11 - INFO - vilbert.task_utils -   Loading VQA Dataset with batch size 30\n",
      "07/30/2020 11:24:11 - INFO - vilbert.datasets.vqa_dataset -   Loading from datasets/VQA/cache/VQA_test_23_cleaned.pkl\n"
     ]
    }
   ],
   "source": [
    "ds = LoadDatasetEval(args, task_cfg, args.tasks.split(\"-\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "b'1' is not in list",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-283a58d898c7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'TASK1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/aloui/vilbert-multi-task/vilbert/datasets/vqa_dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    273\u001b[0m         \u001b[0mimage_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mentry\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"image_id\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m         \u001b[0mquestion_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mentry\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"question_id\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 275\u001b[0;31m         \u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_boxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mboxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_image_features_reader\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mimage_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    276\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m         \u001b[0mmix_num_boxes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_boxes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_max_region_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/aloui/vilbert-multi-task/vilbert/datasets/_image_features_reader.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, image_id)\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0mimage_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_image_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m             \u001b[0;31m# Load features during first epoch, all not loaded together as it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: b'1' is not in list"
     ]
    }
   ],
   "source": [
    "for d in ds[-2]['TASK1']:\n",
    "    print(type(d))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans2label = cPickle.load(open('datasets/VQA/cache/trainval_ans2label.pkl', \"rb\"))\n",
    "label2ans = cPickle.load(open('datasets/VQA/cache/trainval_label2ans.pkl', \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'': 0,\n",
       " 'raining': 1523,\n",
       " 'pedestrian crossing': 1841,\n",
       " 'hats': 1361,\n",
       " 'bear': 2914,\n",
       " 'swirls': 2244,\n",
       " 'yellow': 759,\n",
       " 'protest': 2979,\n",
       " 'woods': 1,\n",
       " 'sleep': 2936,\n",
       " 'trash can': 2,\n",
       " 'hanging': 3,\n",
       " 'onions': 3091,\n",
       " 'zig zag': 2543,\n",
       " 'lace': 3033,\n",
       " 'trolley': 1362,\n",
       " 'feeding': 2937,\n",
       " 'chinese': 2245,\n",
       " 'electricity': 760,\n",
       " 'swan': 2351,\n",
       " 'cocker spaniel': 570,\n",
       " 'bike': 1716,\n",
       " 'under': 396,\n",
       " 'dog show': 1363,\n",
       " 'flip flops': 1903,\n",
       " 'wreath': 981,\n",
       " 'by window': 188,\n",
       " 'deli': 761,\n",
       " 'blanket': 982,\n",
       " 'dell': 762,\n",
       " \"women's\": 983,\n",
       " 'home plate': 984,\n",
       " 'fireplace': 2940,\n",
       " 'icing': 1564,\n",
       " 'blue and pink': 1159,\n",
       " 'school': 571,\n",
       " 'baking': 1905,\n",
       " 'snowflakes': 1160,\n",
       " 'parrot': 2941,\n",
       " 'wooden': 4,\n",
       " 'formica': 2137,\n",
       " 'ups': 1161,\n",
       " 'triumph': 1718,\n",
       " 'clothes': 1162,\n",
       " \"can't see\": 1906,\n",
       " 'bicycle': 2138,\n",
       " 'bus driver': 1538,\n",
       " 'tired': 2345,\n",
       " 'phones': 2544,\n",
       " 'railing': 2343,\n",
       " 'feathers': 572,\n",
       " 'japanese': 2743,\n",
       " 'frosted': 408,\n",
       " 'chef': 1719,\n",
       " 'second': 2348,\n",
       " 'street': 1364,\n",
       " 'chairs': 1709,\n",
       " 'air': 1747,\n",
       " 'panda': 190,\n",
       " 'on counter': 2203,\n",
       " 'blue': 411,\n",
       " 'rope': 1842,\n",
       " 'straight ahead': 2139,\n",
       " 'at camera': 2077,\n",
       " 'cooking': 5,\n",
       " 'tow truck': 2745,\n",
       " 'hazy': 1907,\n",
       " 'lights': 2747,\n",
       " 'above': 986,\n",
       " 'sideways': 1978,\n",
       " 'new': 1163,\n",
       " 'net': 1164,\n",
       " 'disney': 1365,\n",
       " 'helmets': 390,\n",
       " 'pancakes': 2748,\n",
       " 'wakeboard': 391,\n",
       " 'men': 392,\n",
       " 'hundreds': 1366,\n",
       " 'on train': 2749,\n",
       " 'remote control': 1166,\n",
       " 'china': 6,\n",
       " 'parking lot': 2608,\n",
       " 'behind woman': 764,\n",
       " '100': 1908,\n",
       " 'ski slope': 192,\n",
       " '106': 1910,\n",
       " 'mozzarella': 420,\n",
       " 'dry': 1911,\n",
       " 'kids': 7,\n",
       " 'luggage': 574,\n",
       " 'leaves': 575,\n",
       " 'qantas': 663,\n",
       " 'smoke': 987,\n",
       " 'military': 765,\n",
       " 'joshua': 393,\n",
       " 'bike rack': 8,\n",
       " 'straw': 2140,\n",
       " 'strap': 426,\n",
       " 'sliced': 394,\n",
       " 'jackets': 395,\n",
       " 'on phone': 9,\n",
       " 'landscape': 2750,\n",
       " 'star wars': 2943,\n",
       " 'plow': 193,\n",
       " 'headband': 1981,\n",
       " 'army': 2751,\n",
       " 'alligator': 1721,\n",
       " 'sweater': 194,\n",
       " 'coins': 195,\n",
       " 'suit': 1659,\n",
       " 'music': 10,\n",
       " 'comcast': 196,\n",
       " 'riding horses': 1525,\n",
       " 'very fast': 2752,\n",
       " 'strike': 1526,\n",
       " 'dairy': 665,\n",
       " 'blueberry': 2545,\n",
       " 'ram': 2958,\n",
       " 'fake': 1569,\n",
       " 'sony ericsson': 2753,\n",
       " 'street name': 1722,\n",
       " '99': 2352,\n",
       " 'to left': 576,\n",
       " 'warm': 1912,\n",
       " 'for fun': 397,\n",
       " 'siblings': 3034,\n",
       " 'organic': 731,\n",
       " 'me': 1367,\n",
       " '1990': 197,\n",
       " 'room': 398,\n",
       " 'work': 2546,\n",
       " 'roof': 399,\n",
       " 'black and blue': 1368,\n",
       " 'plunger': 1528,\n",
       " 'decorative': 2944,\n",
       " \"it's not\": 2355,\n",
       " 'florida': 2709,\n",
       " 'floor': 2391,\n",
       " 'india': 2547,\n",
       " 'honey': 2754,\n",
       " 'green beans': 1529,\n",
       " 'caution': 1530,\n",
       " 'veggies': 1723,\n",
       " 'woodpecker': 2945,\n",
       " 'garbage': 2495,\n",
       " 'motion': 3002,\n",
       " 'end': 1369,\n",
       " '4 feet': 2755,\n",
       " 'in suitcase': 2946,\n",
       " 'travel': 11,\n",
       " 'drying': 2356,\n",
       " 'nuts': 198,\n",
       " '6 inches': 1531,\n",
       " 'happy birthday': 1724,\n",
       " 'machine': 767,\n",
       " 'far': 3035,\n",
       " 'bricks': 2211,\n",
       " 'bunt': 1972,\n",
       " 'boats': 989,\n",
       " 'gate': 2948,\n",
       " 'chase': 2487,\n",
       " 'beach': 1725,\n",
       " 'charging': 1370,\n",
       " 'pizza': 1726,\n",
       " 'gaming': 768,\n",
       " 'briefcase': 2756,\n",
       " 'cadillac': 2757,\n",
       " 'ladder': 199,\n",
       " 'after': 1727,\n",
       " 'lab': 2548,\n",
       " 'jumping': 2142,\n",
       " 'on skateboard': 1435,\n",
       " 'cell phone': 200,\n",
       " 'vase': 1904,\n",
       " 'arch': 201,\n",
       " 'fedora': 1845,\n",
       " 'man on right': 2758,\n",
       " 'in bowl': 1371,\n",
       " 'croissant': 1372,\n",
       " 'harley': 2143,\n",
       " 'tulip': 12,\n",
       " 'checkerboard': 400,\n",
       " 'green': 990,\n",
       " 'jungle': 465,\n",
       " 'ambulance': 2550,\n",
       " '1 foot': 202,\n",
       " '1000': 1419,\n",
       " 'wing': 770,\n",
       " 'wind': 771,\n",
       " 'wine': 772,\n",
       " 'salon': 1730,\n",
       " 'toaster': 2378,\n",
       " 'office': 2551,\n",
       " 'deck': 2760,\n",
       " 'walgreens': 1731,\n",
       " 'over': 2949,\n",
       " 'baseball uniform': 773,\n",
       " 'london': 1963,\n",
       " 'oven': 2005,\n",
       " 'keyboard': 1168,\n",
       " 'plastic wrap': 2358,\n",
       " 'japan': 1732,\n",
       " 'before': 401,\n",
       " 'chihuahua': 1914,\n",
       " '4 inches': 2553,\n",
       " '2:00': 472,\n",
       " 'backpack': 2359,\n",
       " 'avocado': 1733,\n",
       " '2:05': 577,\n",
       " 'writing': 2950,\n",
       " 'new orleans': 774,\n",
       " '400': 578,\n",
       " 'savory': 1734,\n",
       " '3:15': 579,\n",
       " '3:10': 580,\n",
       " 'swans': 2996,\n",
       " 'coffee': 203,\n",
       " 'carnation': 1389,\n",
       " '1 in back': 204,\n",
       " 'white and blue': 205,\n",
       " 'safe': 206,\n",
       " 'band': 1735,\n",
       " 'mercedes benz': 1374,\n",
       " 'giraffe': 991,\n",
       " 'glazed': 402,\n",
       " 'silver': 775,\n",
       " 'bank': 1736,\n",
       " 'bread': 2554,\n",
       " 'shadows': 2145,\n",
       " '1.00': 2835,\n",
       " 'brushing teeth': 2360,\n",
       " 'rocky': 1737,\n",
       " 'potatoes': 2146,\n",
       " 'on tray': 992,\n",
       " 'wii remotes': 482,\n",
       " 'l': 207,\n",
       " 'detroit': 581,\n",
       " 'rocks': 1738,\n",
       " 'side of road': 2761,\n",
       " 'arrow': 13,\n",
       " 'crocs': 1739,\n",
       " 'bone': 1917,\n",
       " 'lying down': 993,\n",
       " 'hanger': 2951,\n",
       " 'turn right': 208,\n",
       " 'under table': 1918,\n",
       " 'spider': 2361,\n",
       " 'bowls': 776,\n",
       " 'waffle': 2147,\n",
       " 'british airways': 2879,\n",
       " 'blueberries': 2642,\n",
       " 'magnets': 2024,\n",
       " 'navy': 1919,\n",
       " 'logo': 1741,\n",
       " 'dawn': 1169,\n",
       " 'in vase': 994,\n",
       " 'enclosure': 1170,\n",
       " 'large': 1616,\n",
       " 'rv': 1534,\n",
       " 'lemons': 2034,\n",
       " 'driving': 2952,\n",
       " 'motel': 2148,\n",
       " 'cameras': 2556,\n",
       " 'diesel': 2557,\n",
       " '9:25': 3038,\n",
       " 'surprise': 1171,\n",
       " 'millions': 1421,\n",
       " 'sliding': 995,\n",
       " 'green and orange': 2953,\n",
       " '3:50': 2205,\n",
       " 'arizona': 2954,\n",
       " 'turning': 2762,\n",
       " 'barrier': 210,\n",
       " '9:20': 3039,\n",
       " 'blue and green': 2955,\n",
       " 'free': 2956,\n",
       " 'ascending': 403,\n",
       " 'small': 583,\n",
       " 'using laptop': 877,\n",
       " 'hoodie': 404,\n",
       " 'lacoste': 2907,\n",
       " 'blinders': 405,\n",
       " 'tree branch': 211,\n",
       " 'on chair': 212,\n",
       " 'shelves': 2363,\n",
       " 'atv': 2364,\n",
       " 'bears': 2711,\n",
       " 'soda': 584,\n",
       " 'moving': 3070,\n",
       " 'cleaning': 2675,\n",
       " 'behind clouds': 1172,\n",
       " 'elmo': 1535,\n",
       " 'in street': 406,\n",
       " 'veggie': 2365,\n",
       " 'on pole': 1536,\n",
       " 'lettuce': 407,\n",
       " 'chevron': 15,\n",
       " 'fire truck': 585,\n",
       " 'comforter': 1920,\n",
       " 'scissors': 2957,\n",
       " 'thick': 1742,\n",
       " 'tusks': 2611,\n",
       " 'tuna': 2380,\n",
       " 'hood': 1173,\n",
       " 'basketball': 1537,\n",
       " 'hydrant': 898,\n",
       " 'lego': 777,\n",
       " 'top': 501,\n",
       " 'girls': 1174,\n",
       " 'tow': 2150,\n",
       " 'boating': 2764,\n",
       " 'guitar hero': 778,\n",
       " 'hollywood': 1921,\n",
       " 'john': 213,\n",
       " 'dogs': 214,\n",
       " 'kiwi': 2558,\n",
       " 'urban': 503,\n",
       " 'ceiling': 1375,\n",
       " 'on grass': 215,\n",
       " 'bacon': 2346,\n",
       " 'gym': 1922,\n",
       " 'serve': 1376,\n",
       " 'blue jay': 1175,\n",
       " 'no left turn': 1176,\n",
       " 'western': 1377,\n",
       " 'cereal': 216,\n",
       " 'crosstown': 217,\n",
       " 'schnauzer': 587,\n",
       " 'distance': 1924,\n",
       " 'target': 2560,\n",
       " 'tree': 1539,\n",
       " 'french fries': 1379,\n",
       " 'shower': 1540,\n",
       " 'iron': 2561,\n",
       " 'man on left': 780,\n",
       " 'beard': 2713,\n",
       " 'persian': 2998,\n",
       " 'bridge': 846,\n",
       " 'donkey': 1380,\n",
       " 'fashion': 1381,\n",
       " 'very big': 517,\n",
       " 'giraffes': 218,\n",
       " 'boston': 2366,\n",
       " 'modern': 1925,\n",
       " 'ginger': 409,\n",
       " 'talking': 1382,\n",
       " 'shell': 2315,\n",
       " 'no grass': 3071,\n",
       " 'mint': 1926,\n",
       " 'alive': 2926,\n",
       " 'cactus': 2744,\n",
       " 'concrete': 1649,\n",
       " 'bleachers': 1541,\n",
       " 'san diego': 410,\n",
       " 'snow': 2154,\n",
       " 'in stands': 782,\n",
       " 'chest': 2767,\n",
       " '101': 1909,\n",
       " 'shelf': 2316,\n",
       " 'circles': 2562,\n",
       " 'gravy': 219,\n",
       " 'shallow': 1497,\n",
       " 'thumb': 2406,\n",
       " 'zebras': 783,\n",
       " '5 ft': 2349,\n",
       " '6 feet': 3098,\n",
       " 'victoria': 784,\n",
       " 'mario': 412,\n",
       " 'no cat': 413,\n",
       " 'germany': 220,\n",
       " 'x': 2668,\n",
       " 'm': 1929,\n",
       " 'dog': 1930,\n",
       " 'camo': 1543,\n",
       " 'pineapple': 2155,\n",
       " 'queen': 2961,\n",
       " 'birthday party': 2934,\n",
       " 'north america': 2962,\n",
       " 'chandelier': 2564,\n",
       " 'radio': 2156,\n",
       " 'asia': 2746,\n",
       " 'fork and knife': 589,\n",
       " 'recliner': 786,\n",
       " 'toast': 2565,\n",
       " 'busy': 2367,\n",
       " 'on bike': 2566,\n",
       " 'menu': 787,\n",
       " 'train tracks': 997,\n",
       " 'on right': 17,\n",
       " 'sugar': 2505,\n",
       " 'celery': 415,\n",
       " 'bush': 2368,\n",
       " 'rice': 18,\n",
       " 'goalie': 998,\n",
       " 'rectangle': 221,\n",
       " 'plate': 19,\n",
       " 'tiles': 1932,\n",
       " 'sunglasses': 1383,\n",
       " 'wide': 3007,\n",
       " 'girl on right': 2158,\n",
       " 'honda': 1544,\n",
       " 'stop': 935,\n",
       " 'dc': 999,\n",
       " 'cardinals': 1743,\n",
       " 'pocket': 141,\n",
       " 'amazon': 2160,\n",
       " 'watermelon': 416,\n",
       " 'roundabout': 1327,\n",
       " 'cushion': 2369,\n",
       " 'wedding': 590,\n",
       " '15': 1991,\n",
       " 'relish': 1545,\n",
       " 'beads': 591,\n",
       " 'bar': 2771,\n",
       " 'sailing': 1993,\n",
       " 'noon': 2435,\n",
       " 'rowing': 2964,\n",
       " '16': 1994,\n",
       " '2:15': 2569,\n",
       " 'bag': 2773,\n",
       " 'bad': 2774,\n",
       " 'grilled': 1934,\n",
       " 'steak': 2570,\n",
       " 'steam': 2571,\n",
       " '90': 2354,\n",
       " 'ears': 417,\n",
       " 'playstation': 1178,\n",
       " '10:05': 1038,\n",
       " 'human': 1944,\n",
       " 'fair': 788,\n",
       " 'liquor': 1384,\n",
       " 'lemonade': 1000,\n",
       " '10:00': 1039,\n",
       " 'each other': 2161,\n",
       " 'noodles': 2162,\n",
       " 'game controller': 2370,\n",
       " 'brazil': 2775,\n",
       " 'cat and dog': 185,\n",
       " 'glass': 2353,\n",
       " 'lots': 20,\n",
       " 'away': 223,\n",
       " 'sail': 2776,\n",
       " \"they aren't\": 1385,\n",
       " 'shaved': 2777,\n",
       " 'salt and pepper': 2371,\n",
       " 'wetsuit': 1936,\n",
       " 'mud': 592,\n",
       " 'mug': 593,\n",
       " 'olympics': 2779,\n",
       " 'finger': 594,\n",
       " 'yogurt': 1547,\n",
       " 'looking out window': 789,\n",
       " 'laying down': 1179,\n",
       " 'herding': 595,\n",
       " 'never': 1165,\n",
       " 'nature': 21,\n",
       " 'metal': 2960,\n",
       " 'lotion': 418,\n",
       " 'on top': 1937,\n",
       " 'loading': 1465,\n",
       " 'playing game': 224,\n",
       " 'skull and crossbones': 225,\n",
       " 'news': 596,\n",
       " 'behind fence': 597,\n",
       " 'kitchen': 226,\n",
       " 'accident': 2372,\n",
       " 'cow': 1001,\n",
       " 'country': 1548,\n",
       " 'yamaha': 234,\n",
       " 'on bench': 1745,\n",
       " 'players': 2968,\n",
       " 'protection': 1181,\n",
       " 'throwing frisbee': 23,\n",
       " 'give way': 843,\n",
       " 'flying kite': 1946,\n",
       " 'no hat': 2573,\n",
       " 't shirt and jeans': 599,\n",
       " 'sheepdog': 2373,\n",
       " 'legs': 779,\n",
       " 'vaio': 791,\n",
       " 'zebra and giraffe': 1587,\n",
       " '2nd': 2374,\n",
       " 'towels': 1386,\n",
       " 'blending': 2375,\n",
       " 'blonde': 24,\n",
       " 'grazing': 1549,\n",
       " 'conference': 600,\n",
       " 'lighthouse': 2376,\n",
       " 'cardboard': 1167,\n",
       " 'beef': 1387,\n",
       " 'hay': 27,\n",
       " 'chrome': 792,\n",
       " 'on couch': 2574,\n",
       " 'parsley': 419,\n",
       " '1 4': 2163,\n",
       " 'beer': 1388,\n",
       " 'grapefruit': 2492,\n",
       " 'stadium': 1550,\n",
       " 'basil': 421,\n",
       " 'private': 2386,\n",
       " 'warmth': 1746,\n",
       " 'dots': 1551,\n",
       " 'life': 793,\n",
       " 'banana peel': 1552,\n",
       " 'sprite': 2164,\n",
       " 'mushroom': 976,\n",
       " 'not sure': 1553,\n",
       " 'lift': 794,\n",
       " 'coffee table': 2165,\n",
       " 'child': 795,\n",
       " 'catch': 2970,\n",
       " 'bunny': 1748,\n",
       " 'chili': 796,\n",
       " '3 feet': 227,\n",
       " 'stuffed animals': 2449,\n",
       " 'orange and blue': 1182,\n",
       " 'tank': 1183,\n",
       " 'n': 602,\n",
       " 'lizard': 985,\n",
       " 'onion rings': 228,\n",
       " 'ski lift': 2576,\n",
       " 'life jacket': 25,\n",
       " 'stopping': 2166,\n",
       " 'above toilet': 797,\n",
       " 'balance': 2780,\n",
       " 'hot sauce': 422,\n",
       " 'cylinder': 229,\n",
       " 'cane': 423,\n",
       " 'mexico': 2781,\n",
       " 'sticker': 2577,\n",
       " 'sushi': 2782,\n",
       " 'player': 2377,\n",
       " 'tissue': 230,\n",
       " 'cone': 231,\n",
       " 'in': 1184,\n",
       " 'cook': 2187,\n",
       " 'seattle': 2783,\n",
       " 'mouse': 1939,\n",
       " 'in air': 1728,\n",
       " 'bottles': 1185,\n",
       " 'emergency': 128,\n",
       " 'nike': 603,\n",
       " 'speed limit': 1554,\n",
       " 'gray and red': 798,\n",
       " 'white and green': 1223,\n",
       " 'babies': 799,\n",
       " 'big': 2875,\n",
       " 'vegetable': 2784,\n",
       " 'plates': 1002,\n",
       " 'several': 1390,\n",
       " 'skateboards': 1652,\n",
       " 'wheel': 232,\n",
       " 'bird feeder': 800,\n",
       " 'public market center': 582,\n",
       " 'rail': 1003,\n",
       " 'rain': 1004,\n",
       " 'hand': 233,\n",
       " '9:55': 2167,\n",
       " 'garlic': 1940,\n",
       " 'soccer ball': 1391,\n",
       " 'kia': 1941,\n",
       " 'on': 2507,\n",
       " 'kid': 1942,\n",
       " 'butter': 1943,\n",
       " 'dishes': 157,\n",
       " 'condiments': 1005,\n",
       " 'ocean': 604,\n",
       " 'hispanic': 1749,\n",
       " 'washington monument': 2971,\n",
       " 'mother': 2168,\n",
       " 'hearts': 2972,\n",
       " 'pooping': 996,\n",
       " 'left': 2785,\n",
       " 'american flag': 1555,\n",
       " 'photographer': 2579,\n",
       " 'photo': 1750,\n",
       " 'laptop': 2973,\n",
       " 'goggles': 2578,\n",
       " '50 feet': 1186,\n",
       " 'yes': 425,\n",
       " 'kayaking': 2651,\n",
       " 'hills': 1006,\n",
       " 'sunflower': 1187,\n",
       " 'elm': 598,\n",
       " 'in front': 1945,\n",
       " 'cherry': 605,\n",
       " 'boot': 3125,\n",
       " 'hilly': 1007,\n",
       " 'roast beef': 801,\n",
       " 'main street': 802,\n",
       " 'board': 1751,\n",
       " 'easy': 2382,\n",
       " 'east': 2383,\n",
       " 'hat': 28,\n",
       " 'to get to other side': 29,\n",
       " 'mayo': 2580,\n",
       " 'ski pole': 1008,\n",
       " 'wii controllers': 607,\n",
       " 'boxes': 1752,\n",
       " 'boxer': 1753,\n",
       " 'descending': 608,\n",
       " 'background': 2786,\n",
       " '12:35': 30,\n",
       " '6:05': 2384,\n",
       " 'shadow': 31,\n",
       " 'catching frisbee': 2974,\n",
       " '6:00': 2385,\n",
       " '12:30': 32,\n",
       " 'coffee maker': 609,\n",
       " '59': 2169,\n",
       " 'cooler': 235,\n",
       " 'lily': 1695,\n",
       " 'grizzly': 1009,\n",
       " '56': 2172,\n",
       " 'kitesurfing': 427,\n",
       " '50': 2174,\n",
       " '53': 2175,\n",
       " '52': 2176,\n",
       " 'train car': 803,\n",
       " 'pavement': 804,\n",
       " 'mickey mouse': 1818,\n",
       " 'steps': 805,\n",
       " 'night': 236,\n",
       " 'security': 1010,\n",
       " 'cirrus': 237,\n",
       " 'antique': 1011,\n",
       " 'butterfly': 2416,\n",
       " 'right': 2387,\n",
       " 'petting': 2177,\n",
       " 'people': 806,\n",
       " \"he's not\": 1949,\n",
       " 'crown': 33,\n",
       " 'dead': 428,\n",
       " 'crows': 34,\n",
       " 'dining room': 1188,\n",
       " '2:20': 1394,\n",
       " 'tie dye': 1012,\n",
       " 'orchid': 2582,\n",
       " '10 years': 429,\n",
       " 'bottom': 35,\n",
       " 'purple': 1013,\n",
       " 'fox': 807,\n",
       " 'ham and cheese': 430,\n",
       " 'fog': 808,\n",
       " 'cnn': 2975,\n",
       " '3:30': 1396,\n",
       " 'skateboarder': 431,\n",
       " 'christmas': 1397,\n",
       " 'trunk': 2645,\n",
       " 'cord': 1398,\n",
       " 'khaki': 610,\n",
       " 'k': 1524,\n",
       " 'corn': 1399,\n",
       " '34': 2096,\n",
       " 'lamps': 2179,\n",
       " 'post': 1754,\n",
       " 'dalmatian': 2180,\n",
       " 'benches': 37,\n",
       " 'cowboy': 2181,\n",
       " 'meow': 2787,\n",
       " 'o': 2389,\n",
       " 'dinner': 611,\n",
       " 'afternoon': 433,\n",
       " 'parking garage': 880,\n",
       " 'octopus': 1755,\n",
       " 'hospital': 2141,\n",
       " 'indians': 988,\n",
       " 'toothpicks': 612,\n",
       " 'mantle': 1014,\n",
       " 'tinkerbell': 2788,\n",
       " 'selfie': 434,\n",
       " 'fern': 613,\n",
       " 'down': 435,\n",
       " 'bats': 614,\n",
       " 'old': 2388,\n",
       " 'parade': 2680,\n",
       " 'palm tree': 1590,\n",
       " 'fabric': 38,\n",
       " 'tennis': 436,\n",
       " 'sunlight': 615,\n",
       " 'virgin': 2182,\n",
       " 'donut shop': 2789,\n",
       " 'towing': 616,\n",
       " 'wax': 1756,\n",
       " 'white and yellow': 1190,\n",
       " 'over easy': 1950,\n",
       " 'kiting': 617,\n",
       " 'war': 1757,\n",
       " 'happy': 809,\n",
       " 'fork': 1040,\n",
       " 'head': 1400,\n",
       " 'medium': 1401,\n",
       " 'yellow and white': 1191,\n",
       " 'snowy': 2584,\n",
       " 'batman': 437,\n",
       " 'tigers': 810,\n",
       " 'converse': 1758,\n",
       " 'landing': 438,\n",
       " 'ford': 1192,\n",
       " 'wireless': 2583,\n",
       " 'bags': 2827,\n",
       " 'heat': 1402,\n",
       " 'bottom right': 238,\n",
       " 'cat food': 1044,\n",
       " 'sailboats': 239,\n",
       " 'turtle': 2409,\n",
       " 'dump': 3058,\n",
       " 'congratulations': 39,\n",
       " 'slope': 2395,\n",
       " 'playing soccer': 2178,\n",
       " 'inside': 1557,\n",
       " 'trash': 3032,\n",
       " '7:10': 2586,\n",
       " '2:25': 1393,\n",
       " 'lays': 811,\n",
       " 'passenger': 40,\n",
       " 'sticks': 1193,\n",
       " 'classic': 1194,\n",
       " 'umpire': 2588,\n",
       " 'cleats': 1431,\n",
       " 'hungry': 2207,\n",
       " 'diamond': 2851,\n",
       " 'on sign': 2390,\n",
       " 'pink and white': 1559,\n",
       " 'playing video game': 708,\n",
       " 'muffins': 439,\n",
       " 'ship': 1195,\n",
       " 'triangles': 42,\n",
       " 'no': 1403,\n",
       " 'ny': 1404,\n",
       " 'setting': 618,\n",
       " '7:45': 2939,\n",
       " 'holding': 2589,\n",
       " 'digital': 1196,\n",
       " 'tie': 2976,\n",
       " 'roll': 43,\n",
       " 'whipped cream': 2393,\n",
       " 'evergreen': 1405,\n",
       " 'picture': 620,\n",
       " 'thumbs up': 2590,\n",
       " '4 way': 812,\n",
       " 'handicap': 440,\n",
       " 'center': 1346,\n",
       " 'purple and white': 2183,\n",
       " 'fell': 1067,\n",
       " 'red sox': 1197,\n",
       " 'jones': 2791,\n",
       " 'tugboat': 2591,\n",
       " 'younger': 2977,\n",
       " 'wii remote': 643,\n",
       " 'phone': 707,\n",
       " 'yacht': 2184,\n",
       " 'jacket': 441,\n",
       " 'teeth': 1952,\n",
       " 'serious': 2978,\n",
       " 'backward': 1406,\n",
       " 'adult': 1913,\n",
       " 'peacock': 813,\n",
       " 'cessna': 1953,\n",
       " 'riding bikes': 442,\n",
       " 'chain': 44,\n",
       " 'playing video games': 2911,\n",
       " 'under armour': 2963,\n",
       " 'skis': 1198,\n",
       " 'focus': 2186,\n",
       " 'silverware': 240,\n",
       " 'skate': 1560,\n",
       " 'daytime': 1189,\n",
       " 'skiing': 1561,\n",
       " 'baseball field': 2605,\n",
       " 'chair': 45,\n",
       " 'toothpick': 1016,\n",
       " 'milk': 2792,\n",
       " 'long time': 622,\n",
       " 'venice': 814,\n",
       " 'grape': 1017,\n",
       " 'show': 2000,\n",
       " 'father': 443,\n",
       " 'prom': 3073,\n",
       " 'crates': 46,\n",
       " '0': 444,\n",
       " 'bicycles': 1563,\n",
       " 'brushing his teeth': 2646,\n",
       " 'ride': 2699,\n",
       " 'southwest': 1760,\n",
       " 'brown': 2594,\n",
       " 'smartphone': 2647,\n",
       " 'string': 1199,\n",
       " 'on dresser': 766,\n",
       " 'banana bread': 1761,\n",
       " 'kitten': 1762,\n",
       " 'kitchenaid': 1763,\n",
       " 'cool': 2188,\n",
       " 'dim': 2793,\n",
       " 'on wall': 1408,\n",
       " 'clouds': 681,\n",
       " 'limes': 2794,\n",
       " 'freightliner': 2249,\n",
       " 'posts': 623,\n",
       " 'gun': 241,\n",
       " 'cloudy': 624,\n",
       " 'magnet': 1200,\n",
       " 'p': 1018,\n",
       " 'horseback riding': 242,\n",
       " 'teal': 817,\n",
       " 'team': 818,\n",
       " 'sidewalk': 2596,\n",
       " 'dip': 2796,\n",
       " 'round': 445,\n",
       " 'seaweed': 3100,\n",
       " 'slow down': 243,\n",
       " 'pork': 625,\n",
       " 'heinz': 1409,\n",
       " 'htc': 2597,\n",
       " '20 ft': 3074,\n",
       " 'collage': 1565,\n",
       " 'bedroom': 2522,\n",
       " 'rectangles': 3041,\n",
       " 'sign': 1566,\n",
       " '11:45': 47,\n",
       " 'shirts': 48,\n",
       " '12:28': 1955,\n",
       " 'soldiers': 2719,\n",
       " 'harry potter': 130,\n",
       " '12:25': 1956,\n",
       " 'chicken': 3101,\n",
       " '12:20': 1957,\n",
       " 'drinks': 2981,\n",
       " 'cargo': 1764,\n",
       " 'dog food': 1092,\n",
       " 'stands': 2982,\n",
       " 'kite string': 1958,\n",
       " 'wildebeest': 1765,\n",
       " 'mall': 2454,\n",
       " 'uniform': 1766,\n",
       " 'current': 819,\n",
       " 'falling': 2398,\n",
       " 'in hand': 2819,\n",
       " 'gazebo': 1959,\n",
       " 'transportation': 1201,\n",
       " 'on man': 2983,\n",
       " 'no smoking': 820,\n",
       " 'makeup': 1960,\n",
       " 'french': 2797,\n",
       " 'water': 2984,\n",
       " '2:30': 244,\n",
       " \"don't walk\": 2399,\n",
       " '2:35': 245,\n",
       " 'frosting': 446,\n",
       " 'teacher': 246,\n",
       " 'easton': 1202,\n",
       " '3:25': 247,\n",
       " 'boy': 448,\n",
       " 'male': 2456,\n",
       " '3:20': 248,\n",
       " 'healthy': 2190,\n",
       " 'bus station': 2400,\n",
       " 'name tag': 2986,\n",
       " 'bow': 449,\n",
       " 'cinnamon': 1410,\n",
       " 'bob': 450,\n",
       " 'pillow': 249,\n",
       " 'nowhere': 2494,\n",
       " 'easyjet': 1961,\n",
       " 'petting horse': 1568,\n",
       " 'love': 821,\n",
       " 'hiking': 1020,\n",
       " 'tuxedo': 626,\n",
       " 'shark': 1411,\n",
       " 'uphill': 251,\n",
       " 'snowboard': 1021,\n",
       " 'no light': 2191,\n",
       " 'sun hat': 451,\n",
       " '1st': 1412,\n",
       " 'playing wii': 2599,\n",
       " 'pony': 2251,\n",
       " 'market': 2600,\n",
       " '30 mph': 2682,\n",
       " 'sunbathing': 822,\n",
       " 'working': 340,\n",
       " 'birthday cake': 2614,\n",
       " '10:15': 2192,\n",
       " 'wicker': 1570,\n",
       " 'angry': 1571,\n",
       " '10:10': 2193,\n",
       " 'sports': 709,\n",
       " '4th of july': 1392,\n",
       " '1 in middle': 627,\n",
       " 'wood': 3010,\n",
       " 'iphone': 2194,\n",
       " 'sunflowers': 1500,\n",
       " 'softball': 2255,\n",
       " 'angels': 2601,\n",
       " 'conductor': 2988,\n",
       " 'club': 2602,\n",
       " 'phillies': 2799,\n",
       " 'fanta': 2820,\n",
       " 'oregon': 2403,\n",
       " 'chocolate': 1414,\n",
       " 'downtown': 2800,\n",
       " 'riding': 166,\n",
       " 'blinds': 2421,\n",
       " 'fly': 2801,\n",
       " 'ibm': 1478,\n",
       " 'tokyo': 2802,\n",
       " 'heineken': 823,\n",
       " 'cap': 1769,\n",
       " 'cat': 1770,\n",
       " 'wallet': 1203,\n",
       " 'can': 1771,\n",
       " 'ferry': 2989,\n",
       " 'pickle': 628,\n",
       " 'urinals': 3044,\n",
       " 'heart': 1772,\n",
       " 'nursing': 629,\n",
       " 'mirrors': 49,\n",
       " 'taking photo': 1415,\n",
       " 'confused': 1964,\n",
       " 'soup': 2803,\n",
       " 'parachute': 50,\n",
       " 'drawer': 2804,\n",
       " 'pizza box': 452,\n",
       " 'pond': 2252,\n",
       " 'black and brown': 630,\n",
       " 'clothing': 1773,\n",
       " 'wetsuits': 1489,\n",
       " 'pink': 1204,\n",
       " 'rays': 1205,\n",
       " 'winter': 824,\n",
       " 'to catch frisbee': 1206,\n",
       " 'sailboat': 631,\n",
       " 'watching': 2321,\n",
       " 'brand': 2930,\n",
       " 'magazine': 432,\n",
       " 'pine': 1207,\n",
       " '1': 2195,\n",
       " '7:00': 1416,\n",
       " 'cardinal': 2196,\n",
       " '7:05': 1417,\n",
       " 'elephant': 825,\n",
       " 'tile': 1208,\n",
       " 'photography': 2913,\n",
       " 'under sink': 1573,\n",
       " 'laundry': 1874,\n",
       " 'mat': 1966,\n",
       " 'information': 884,\n",
       " 'flat screen': 252,\n",
       " 'on his head': 2992,\n",
       " 'man in middle': 453,\n",
       " 'ducati': 1776,\n",
       " 'produce': 253,\n",
       " 'toilet paper': 1778,\n",
       " 'vases': 254,\n",
       " 'floral': 2993,\n",
       " 'green and black': 2852,\n",
       " 'tablecloth': 454,\n",
       " 'man': 1968,\n",
       " 'classroom': 2994,\n",
       " 'surfing': 51,\n",
       " 'natural': 1574,\n",
       " 'neck': 1969,\n",
       " 'candles': 1023,\n",
       " 'wheelchair': 826,\n",
       " 'placemat': 2404,\n",
       " 'corona': 255,\n",
       " 'daisies': 2883,\n",
       " 'mango': 52,\n",
       " 'in box': 85,\n",
       " 'african': 2807,\n",
       " 'basket': 455,\n",
       " 'tall': 1970,\n",
       " '2 years': 632,\n",
       " 'bunk': 2947,\n",
       " 'blue team': 1779,\n",
       " 'cute': 1210,\n",
       " 'serving': 256,\n",
       " 'shoes': 456,\n",
       " 'haircut': 1024,\n",
       " 'years': 53,\n",
       " 'stability': 1211,\n",
       " 'pizza cutter': 1575,\n",
       " 'pitch': 1971,\n",
       " 'marshmallows': 1212,\n",
       " 'cold': 1025,\n",
       " 'still': 257,\n",
       " 'birds': 1026,\n",
       " 'police': 457,\n",
       " 'monitor': 458,\n",
       " 'curly': 2606,\n",
       " 'smoothie': 1213,\n",
       " 'bagels': 829,\n",
       " 'polka dot': 830,\n",
       " 'platform': 633,\n",
       " 'window': 1027,\n",
       " '2 men': 831,\n",
       " 'gatorade': 832,\n",
       " 'farmer': 634,\n",
       " 'main': 2809,\n",
       " 'tiara': 258,\n",
       " 'texas': 1214,\n",
       " ...}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans2label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
